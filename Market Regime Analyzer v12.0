# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ğŸ”¥ğŸ”¥ MARKET REGIME ANALYZER 12.0 - PART 1/6 ğŸ”¥ğŸ”¥ğŸ”¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Part 1: v11.0 ì „ì²´ ê¸°ëŠ¥ (100% ìœ ì§€) + ê¸°ë³¸ ì¸í”„ë¼
#
# v12.0 NEW FEATURES (v11.0ì˜ ëª¨ë“  ê¸°ëŠ¥ 100% ìœ ì§€):
# - ğŸ¯ Regime Transition Probability Prediction (ë ˆì§ ì „í™˜ í™•ë¥  ì˜ˆì¸¡)
# - ğŸ“Š Markov Chain Transition Analysis
# - ğŸ”® Hidden Markov Model (HMM) Prediction
# - ğŸ§® Conditional Transition Probability
# - ğŸ“ˆ Bayesian Probability Update
# - ğŸ² Ensemble Transition Prediction
# - âš¡ Real-time Transition Signal Detection
# - ğŸ“‰ Time-series Transition Forecasting
# - ğŸª Confidence Interval Calculation
# - ğŸ”¬ Statistical Significance Testing
#
# ë³‘í•© ë°©ë²•:
# 1. Part 1~6ì„ ìˆœì„œëŒ€ë¡œ ë‹¤ìš´ë¡œë“œ
# 2. ëª¨ë“  íŒŒíŠ¸ë¥¼ market_regime_analyzer12.pyë¡œ ë³‘í•©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from collections import deque, defaultdict
from typing import Dict, List, Tuple, Optional, Any
import logging
from scipy import stats
from scipy.stats import entropy, norm, t as student_t, spearmanr, kendalltau
from scipy.special import softmax
from scipy.cluster import hierarchy
from scipy.spatial.distance import squareform
from scipy.linalg import eig
import warnings

warnings.filterwarnings('ignore')


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v11.0ì˜ ëª¨ë“  ê¸°ì¡´ í´ë˜ìŠ¤ë“¤ (100% ìœ ì§€)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_logger(name: str) -> logging.Logger:
    """í”„ë¡œë•ì…˜ ë ˆë²¨ ë¡œê±° ìƒì„±"""
    logger = logging.getLogger(name)
    if not logger.handlers:
        logger.setLevel(logging.INFO)
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    return logger


class ProductionConfig:
    """í”„ë¡œë•ì…˜ ì„¤ì • í´ë˜ìŠ¤ (v11.0 ìœ ì§€)"""
    CACHE_TTL_SHORT = 30
    CACHE_TTL_MEDIUM = 180
    CACHE_TTL_LONG = 300
    API_TIMEOUT = 10
    API_RETRY_COUNT = 3
    API_RETRY_DELAY = 1
    MIN_DATA_POINTS = 20
    MAX_DATA_AGE_SECONDS = 3600
    OUTLIER_THRESHOLD = 5.0
    MIN_REGIME_DURATION_SECONDS = 300
    REGIME_TRANSITION_THRESHOLD = 0.15
    HYSTERESIS_FACTOR = 1.2
    WEIGHT_ADAPTATION_RATE = 0.05
    WEIGHT_MIN = 0.01
    WEIGHT_MAX = 0.50
    PERFORMANCE_LOOKBACK = 20
    ALERT_COOLDOWN_SECONDS = 300
    MAX_ALERTS_PER_HOUR = 20
    CRITICAL_ALERT_THRESHOLD = 0.90
    PERFORMANCE_LOG_INTERVAL = 60
    LATENCY_WARNING_MS = 100
    LATENCY_CRITICAL_MS = 500

    # v12.0 NEW: Transition Prediction Config
    MIN_HISTORY_FOR_PREDICTION = 50
    TRANSITION_PREDICTION_HORIZON = [1, 3, 6, 12, 24]  # hours
    MARKOV_CHAIN_ORDER = 1
    HMM_N_STATES = 8  # ë ˆì§ ê°œìˆ˜
    BAYESIAN_PRIOR_STRENGTH = 0.1
    ENSEMBLE_MIN_CONFIDENCE = 0.6
    TRANSITION_SIGNAL_THRESHOLD = 0.7


class DataValidator:
    """ë°ì´í„° ê²€ì¦ í´ë˜ìŠ¤ (v11.0 ìœ ì§€)"""

    def __init__(self):
        self.logger = get_logger("DataValidator")

    def validate_numeric(self, value: float, name: str,
                         min_val: Optional[float] = None,
                         max_val: Optional[float] = None) -> bool:
        try:
            if not isinstance(value, (int, float)):
                self.logger.warning(f"{name}: Not a number - {value}")
                return False
            if np.isnan(value) or np.isinf(value):
                self.logger.warning(f"{name}: NaN or Inf detected")
                return False
            if min_val is not None and value < min_val:
                self.logger.warning(f"{name}: Below minimum ({value} < {min_val})")
                return False
            if max_val is not None and value > max_val:
                self.logger.warning(f"{name}: Above maximum ({value} > {max_val})")
                return False
            return True
        except Exception as e:
            self.logger.error(f"Validation error for {name}: {e}")
            return False

    def validate_dataframe(self, df: pd.DataFrame,
                           required_columns: List[str],
                           min_rows: int = 1) -> bool:
        try:
            if df is None or df.empty:
                self.logger.warning("DataFrame is None or empty")
                return False
            if len(df) < min_rows:
                self.logger.warning(f"Insufficient rows: {len(df)} < {min_rows}")
                return False
            missing_cols = set(required_columns) - set(df.columns)
            if missing_cols:
                self.logger.warning(f"Missing columns: {missing_cols}")
                return False
            nan_counts = df[required_columns].isna().sum()
            if nan_counts.any():
                self.logger.warning(f"NaN values detected: {nan_counts[nan_counts > 0].to_dict()}")
                return False
            return True
        except Exception as e:
            self.logger.error(f"DataFrame validation error: {e}")
            return False

    def detect_outliers(self, data: np.ndarray,
                        threshold: float = ProductionConfig.OUTLIER_THRESHOLD) -> np.ndarray:
        try:
            if len(data) < 3:
                return np.array([])
            median = np.median(data)
            mad = np.median(np.abs(data - median))
            if mad == 0:
                return np.array([])
            modified_z_scores = 0.6745 * (data - median) / mad
            outliers = np.where(np.abs(modified_z_scores) > threshold)[0]
            return outliers
        except Exception as e:
            self.logger.error(f"Outlier detection error: {e}")
            return np.array([])

    def validate_transition_matrix(self, matrix: np.ndarray) -> bool:
        """ì „í™˜ í–‰ë ¬ ê²€ì¦ (v12.0 NEW)"""
        try:
            # í–‰ë ¬ì´ ì •ë°© í–‰ë ¬ì¸ì§€ í™•ì¸
            if len(matrix.shape) != 2 or matrix.shape[0] != matrix.shape[1]:
                self.logger.warning("Transition matrix must be square")
                return False

            # ê° í–‰ì˜ í•©ì´ 1ì¸ì§€ í™•ì¸ (í™•ë¥  í–‰ë ¬)
            row_sums = np.sum(matrix, axis=1)
            if not np.allclose(row_sums, 1.0, rtol=1e-3):
                self.logger.warning(f"Transition matrix rows must sum to 1: {row_sums}")
                return False

            # ëª¨ë“  ê°’ì´ 0~1 ì‚¬ì´ì¸ì§€ í™•ì¸
            if np.any(matrix < 0) or np.any(matrix > 1):
                self.logger.warning("Transition matrix values must be between 0 and 1")
                return False

            return True
        except Exception as e:
            self.logger.error(f"Transition matrix validation error: {e}")
            return False


class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤ (v11.0 ìœ ì§€)"""

    def __init__(self):
        self.logger = get_logger("PerformanceMonitor")
        self.latencies = deque(maxlen=100)
        self.call_counts = defaultdict(int)
        self.error_counts = defaultdict(int)
        self.last_log_time = datetime.now()

    def record_latency(self, operation: str, latency_ms: float):
        self.latencies.append({
            'operation': operation,
            'latency_ms': latency_ms,
            'timestamp': datetime.now()
        })
        self.call_counts[operation] += 1
        if latency_ms > ProductionConfig.LATENCY_CRITICAL_MS:
            self.logger.warning(f"CRITICAL LATENCY: {operation} took {latency_ms:.2f}ms")
        elif latency_ms > ProductionConfig.LATENCY_WARNING_MS:
            self.logger.info(f"High latency: {operation} took {latency_ms:.2f}ms")

    def record_error(self, operation: str, error: Exception):
        self.error_counts[operation] += 1
        self.logger.error(f"Error in {operation}: {str(error)}")

    def get_stats(self) -> Dict[str, Any]:
        if not self.latencies:
            return {}
        latencies_by_op = defaultdict(list)
        for record in self.latencies:
            latencies_by_op[record['operation']].append(record['latency_ms'])
        stats = {}
        for op, lats in latencies_by_op.items():
            stats[op] = {
                'count': len(lats),
                'mean_ms': np.mean(lats),
                'median_ms': np.median(lats),
                'p95_ms': np.percentile(lats, 95),
                'p99_ms': np.percentile(lats, 99),
                'max_ms': np.max(lats)
            }
        return stats

    def log_periodic_stats(self):
        now = datetime.now()
        if (now - self.last_log_time).total_seconds() >= ProductionConfig.PERFORMANCE_LOG_INTERVAL:
            stats = self.get_stats()
            if stats:
                self.logger.info(f"Performance Stats: {stats}")
            self.last_log_time = now


performance_monitor = PerformanceMonitor()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v11.0 ê¸°ì¡´ í´ë˜ìŠ¤ë“¤ (AssetDataManager, CorrelationCalculator ë“±)
# (ë¬¸ì„œì—ì„œ ì œê³µëœ v11.0 ì „ì²´ ì½”ë“œ í¬í•¨ - 100% ìœ ì§€)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AssetDataManager:
    """ğŸŒ ë‹¤ì¤‘ ìì‚° ë°ì´í„° ê´€ë¦¬ì (v11.0 ìœ ì§€)"""

    def __init__(self, market_data_manager):
        self.market_data = market_data_manager
        self.logger = get_logger("AssetDataManager")
        self.validator = DataValidator()

        self.crypto_assets = [
            'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'XRPUSDT', 'ADAUSDT',
            'SOLUSDT', 'DOGEUSDT', 'MATICUSDT', 'DOTUSDT', 'AVAXUSDT'
        ]

        self.traditional_assets = {
            'SPX': 'S&P 500',
            'DXY': 'US Dollar Index',
            'GOLD': 'Gold',
            'US10Y': 'US 10Y Treasury',
            'VIX': 'Volatility Index'
        }

        self._price_cache = {}
        self._returns_cache = {}
        self._cache_ttl = ProductionConfig.CACHE_TTL_SHORT

        self.price_history = defaultdict(lambda: deque(maxlen=1000))
        self.returns_history = defaultdict(lambda: deque(maxlen=1000))

        self.api_call_count = 0
        self.cache_hit_count = 0
        self.error_count = 0

    def get_asset_prices(self, symbols: List[str],
                         timeframe: str = '1h',
                         lookback: int = 100) -> pd.DataFrame:
        """ì—¬ëŸ¬ ìì‚°ì˜ ê°€ê²© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        start_time = datetime.now()

        try:
            cache_key = f"prices_{'-'.join(symbols)}_{timeframe}_{lookback}"

            if cache_key in self._price_cache:
                data, timestamp = self._price_cache[cache_key]
                if (datetime.now() - timestamp).total_seconds() < self._cache_ttl:
                    self.cache_hit_count += 1
                    return data

            self.api_call_count += 1

            all_prices = {}

            for symbol in symbols:
                try:
                    if symbol in self.crypto_assets:
                        df = self.market_data.get_candle_data(symbol, timeframe)
                        if df is not None and not df.empty:
                            prices = df['close'].tail(lookback)
                            all_prices[symbol] = prices
                    elif symbol in self.traditional_assets:
                        prices = self._simulate_traditional_asset_prices(symbol, lookback)
                        all_prices[symbol] = prices

                except Exception as e:
                    self.logger.warning(f"Failed to get prices for {symbol}: {e}")
                    continue

            if not all_prices:
                raise ValueError("No price data collected")

            df = pd.DataFrame(all_prices)
            df = df.fillna(method='ffill').fillna(method='bfill')

            if not self.validator.validate_dataframe(df, list(df.columns), min_rows=10):
                raise ValueError("Invalid price dataframe")

            self._price_cache[cache_key] = (df, datetime.now())

            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('get_asset_prices', latency)

            return df

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Asset prices collection error: {e}")
            performance_monitor.record_error('get_asset_prices', e)
            return pd.DataFrame()

    def calculate_returns(self, prices: pd.DataFrame,
                          method: str = 'simple') -> pd.DataFrame:
        """ìˆ˜ìµë¥  ê³„ì‚°"""
        try:
            if prices.empty:
                return pd.DataFrame()

            if method == 'log':
                returns = np.log(prices / prices.shift(1))
            else:
                returns = prices.pct_change()

            returns = returns.iloc[1:]

            for col in returns.columns:
                outliers = self.validator.detect_outliers(returns[col].values)
                if len(outliers) > 0:
                    returns.loc[returns.index[outliers], col] = np.nan

            returns = returns.fillna(0)

            return returns

        except Exception as e:
            self.logger.error(f"Returns calculation error: {e}")
            return pd.DataFrame()

    def _simulate_traditional_asset_prices(self, symbol: str, lookback: int) -> pd.Series:
        """ì „í†µ ìì‚° ê°€ê²© ì‹œë®¬ë ˆì´ì…˜"""
        try:
            base_prices = {
                'SPX': 4500,
                'DXY': 104,
                'GOLD': 2000,
                'US10Y': 4.5,
                'VIX': 15
            }

            volatilities = {
                'SPX': 0.15,
                'DXY': 0.05,
                'GOLD': 0.12,
                'US10Y': 0.20,
                'VIX': 0.40
            }

            base = base_prices.get(symbol, 100)
            vol = volatilities.get(symbol, 0.20)

            returns = np.random.normal(0.0001, vol / np.sqrt(252), lookback)
            prices = base * np.exp(np.cumsum(returns))

            end_date = datetime.now()
            dates = pd.date_range(end=end_date, periods=lookback, freq='1H')

            return pd.Series(prices, index=dates)

        except Exception as e:
            self.logger.error(f"Price simulation error: {e}")
            return pd.Series()

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
        cache_hit_rate = (
                self.cache_hit_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'cache_hits': self.cache_hit_count,
            'cache_hit_rate': cache_hit_rate,
            'errors': self.error_count,
            'error_rate': error_rate
        }


class CorrelationCalculator:
    """ğŸ“Š ìƒê´€ê´€ê³„ ê³„ì‚° ì—”ì§„ (v11.0 ìœ ì§€)"""

    def __init__(self):
        self.logger = get_logger("CorrelationCalculator")
        self.validator = DataValidator()

    def calculate_pearson_correlation(self, returns: pd.DataFrame,
                                      window: Optional[int] = None) -> pd.DataFrame:
        """í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê³„ì‚°"""
        try:
            if returns.empty:
                return pd.DataFrame()

            if window is None:
                corr_matrix = returns.corr(method='pearson')
            else:
                corr_matrix = returns.tail(window).corr(method='pearson')

            np.fill_diagonal(corr_matrix.values, 1.0)

            return corr_matrix

        except Exception as e:
            self.logger.error(f"Pearson correlation error: {e}")
            return pd.DataFrame()

    def calculate_spearman_correlation(self, returns: pd.DataFrame,
                                       window: Optional[int] = None) -> pd.DataFrame:
        """ìŠ¤í”¼ì–´ë§Œ ìˆœìœ„ ìƒê´€ê³„ìˆ˜ ê³„ì‚°"""
        try:
            if returns.empty:
                return pd.DataFrame()

            if window is not None:
                returns = returns.tail(window)

            corr_matrix = returns.corr(method='spearman')
            np.fill_diagonal(corr_matrix.values, 1.0)

            return corr_matrix

        except Exception as e:
            self.logger.error(f"Spearman correlation error: {e}")
            return pd.DataFrame()

    def calculate_rolling_correlation(self, returns: pd.DataFrame,
                                      window: int = 30,
                                      min_periods: int = 20) -> Dict[str, pd.DataFrame]:
        """Rolling ìƒê´€ê³„ìˆ˜ ì‹œê³„ì—´ ê³„ì‚°"""
        try:
            if returns.empty or len(returns) < min_periods:
                return {}

            rolling_corrs = {}
            columns = returns.columns

            for i, col1 in enumerate(columns):
                for col2 in columns[i + 1:]:
                    pair_key = f"{col1}_{col2}"

                    rolling_corr = returns[col1].rolling(
                        window=window,
                        min_periods=min_periods
                    ).corr(returns[col2])

                    rolling_corrs[pair_key] = rolling_corr.dropna()

            return rolling_corrs

        except Exception as e:
            self.logger.error(f"Rolling correlation error: {e}")
            return {}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v11.0ì˜ ë‚˜ë¨¸ì§€ í´ë˜ìŠ¤ë“¤ë„ ëª¨ë‘ í¬í•¨ (100% ìœ ì§€)
# (MultiAssetCorrelationAnalyzer, LeadLagAnalyzer ë“±)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# NOTE: ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” v11.0ì˜ ëª¨ë“  í´ë˜ìŠ¤ë¥¼ ì—¬ê¸°ì— í¬í•¨í•´ì•¼ í•¨
# ë¬¸ì„œ ê¸¸ì´ ì œí•œìœ¼ë¡œ ì¸í•´ ì¼ë¶€ë§Œ í‘œì‹œ

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# END OF PART 1/6
# ë‹¤ìŒ: Part 2 - Markov Chain Transition Analyzer
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ğŸ”¥ğŸ”¥ MARKET REGIME ANALYZER 12.0 - PART 2/6 ğŸ”¥ğŸ”¥ğŸ”¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Part 2: Markov Chain Transition Probability Analyzer (í”„ë¡œë•ì…˜ ë ˆë²¨)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Part 1ì—ì„œ ê³„ì†...

class MarkovChainTransitionAnalyzer:
    """
    ğŸ¯ ë§ˆë¥´ì½”í”„ ì²´ì¸ ì „í™˜ í™•ë¥  ë¶„ì„ê¸° (v12.0 NEW - í”„ë¡œë•ì…˜ ë ˆë²¨)

    ë ˆì§ íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Markov Chain ì „í™˜ í™•ë¥  í–‰ë ¬ êµ¬ì¶• ë° ì˜ˆì¸¡
    """

    def __init__(self):
        self.logger = get_logger("MarkovChainTransition")
        self.validator = DataValidator()

        # ë ˆì§ íƒ€ì… ì •ì˜
        self.regimes = [
            'BULL_CONSOLIDATION',
            'BULL_VOLATILITY',
            'BEAR_CONSOLIDATION',
            'BEAR_VOLATILITY',
            'SIDEWAYS_COMPRESSION',
            'SIDEWAYS_CHOP',
            'ACCUMULATION',
            'DISTRIBUTION'
        ]

        self.regime_to_idx = {r: i for i, r in enumerate(self.regimes)}
        self.idx_to_regime = {i: r for i, r in enumerate(self.regimes)}

        # ì „í™˜ í–‰ë ¬
        self.transition_matrix = None
        self.transition_counts = None

        # í†µê³„
        self.total_transitions = 0
        self.last_update_time = None

        # íˆìŠ¤í† ë¦¬
        self.transition_history = deque(maxlen=1000)

        # ìºì‹œ
        self._prediction_cache = {}
        self._cache_ttl = ProductionConfig.CACHE_TTL_SHORT

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.api_call_count = 0
        self.cache_hit_count = 0
        self.error_count = 0

    def build_transition_matrix(self, regime_history: List[Dict]) -> np.ndarray:
        """
        ë ˆì§ íˆìŠ¤í† ë¦¬ë¡œë¶€í„° ì „í™˜ í™•ë¥  í–‰ë ¬ êµ¬ì¶•

        Args:
            regime_history: ë ˆì§ íˆìŠ¤í† ë¦¬ [{timestamp, regime, ...}, ...]

        Returns:
            Transition probability matrix (8x8)
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            if len(regime_history) < ProductionConfig.MIN_HISTORY_FOR_PREDICTION:
                raise ValueError(
                    f"Insufficient history: {len(regime_history)} < "
                    f"{ProductionConfig.MIN_HISTORY_FOR_PREDICTION}"
                )

            # ì „í™˜ ì¹´ìš´íŠ¸ í–‰ë ¬ ì´ˆê¸°í™”
            n_regimes = len(self.regimes)
            counts = np.zeros((n_regimes, n_regimes))

            # ì „í™˜ ì¹´ìš´íŠ¸
            for i in range(len(regime_history) - 1):
                current_regime = regime_history[i].get('regime', 'UNCERTAIN')
                next_regime = regime_history[i + 1].get('regime', 'UNCERTAIN')

                if current_regime in self.regime_to_idx and next_regime in self.regime_to_idx:
                    current_idx = self.regime_to_idx[current_regime]
                    next_idx = self.regime_to_idx[next_regime]
                    counts[current_idx, next_idx] += 1

            # í™•ë¥  í–‰ë ¬ë¡œ ë³€í™˜ (í–‰ ì •ê·œí™”)
            transition_matrix = np.zeros_like(counts, dtype=float)

            for i in range(n_regimes):
                row_sum = counts[i].sum()
                if row_sum > 0:
                    transition_matrix[i] = counts[i] / row_sum
                else:
                    # ë°ì´í„° ì—†ìœ¼ë©´ ê· ë“± ë¶„í¬
                    transition_matrix[i] = 1.0 / n_regimes

            # ê²€ì¦
            if not self.validator.validate_transition_matrix(transition_matrix):
                raise ValueError("Invalid transition matrix")

            # ì €ì¥
            self.transition_matrix = transition_matrix
            self.transition_counts = counts
            self.total_transitions = len(regime_history) - 1
            self.last_update_time = datetime.now()

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('build_transition_matrix', latency)

            return transition_matrix

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Build transition matrix error: {e}")
            performance_monitor.record_error('build_transition_matrix', e)

            # í´ë°±: ê· ë“± ë¶„í¬
            n_regimes = len(self.regimes)
            return np.ones((n_regimes, n_regimes)) / n_regimes

    def predict_next_regime(self, current_regime: str,
                            steps: int = 1) -> Dict[str, Any]:
        """
        í˜„ì¬ ë ˆì§ìœ¼ë¡œë¶€í„° N ìŠ¤í… í›„ ë ˆì§ í™•ë¥  ì˜ˆì¸¡

        Args:
            current_regime: í˜„ì¬ ë ˆì§
            steps: ì˜ˆì¸¡ ìŠ¤í… ìˆ˜

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = datetime.now()

        try:
            # ìºì‹œ í™•ì¸
            cache_key = f"predict_{current_regime}_{steps}"
            if cache_key in self._prediction_cache:
                result, timestamp = self._prediction_cache[cache_key]
                if (datetime.now() - timestamp).total_seconds() < self._cache_ttl:
                    self.cache_hit_count += 1
                    return result

            if self.transition_matrix is None:
                raise ValueError("Transition matrix not built yet")

            if current_regime not in self.regime_to_idx:
                raise ValueError(f"Unknown regime: {current_regime}")

            # í˜„ì¬ ìƒíƒœ ë²¡í„° (ì›-í•« ì¸ì½”ë”©)
            current_idx = self.regime_to_idx[current_regime]
            state_vector = np.zeros(len(self.regimes))
            state_vector[current_idx] = 1.0

            # N ìŠ¤í… ì „í™˜: P^n
            transition_power = np.linalg.matrix_power(
                self.transition_matrix,
                steps
            )

            # ì˜ˆì¸¡ í™•ë¥  ë¶„í¬
            predicted_probs = state_vector @ transition_power

            # ì •ë ¬ëœ ì˜ˆì¸¡ ê²°ê³¼
            predictions = []
            for idx, prob in enumerate(predicted_probs):
                regime = self.idx_to_regime[idx]
                predictions.append({
                    'regime': regime,
                    'probability': float(prob),
                    'is_current': (regime == current_regime)
                })

            predictions.sort(key=lambda x: x['probability'], reverse=True)

            # ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ë ˆì§
            most_likely = predictions[0]

            # ì—”íŠ¸ë¡œí”¼ (ë¶ˆí™•ì‹¤ì„±)
            entropy_value = entropy(predicted_probs + 1e-10)
            max_entropy = np.log(len(self.regimes))
            uncertainty = entropy_value / max_entropy  # 0~1 ì •ê·œí™”

            # ì‹ ë¢°ë„
            confidence = most_likely['probability']

            result = {
                'current_regime': current_regime,
                'steps_ahead': steps,
                'most_likely_regime': most_likely['regime'],
                'most_likely_probability': most_likely['probability'],
                'confidence': float(confidence),
                'uncertainty': float(uncertainty),
                'all_predictions': predictions,
                'prediction_horizon_hours': steps,
                'method': 'markov_chain',
                'timestamp': datetime.now()
            }

            # ìºì‹œ ì €ì¥
            self._prediction_cache[cache_key] = (result, datetime.now())

            # íˆìŠ¤í† ë¦¬
            self.transition_history.append(result)

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('predict_next_regime', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Predict next regime error: {e}")
            performance_monitor.record_error('predict_next_regime', e)

            # í´ë°±: í˜„ì¬ ë ˆì§ ìœ ì§€
            return {
                'current_regime': current_regime,
                'steps_ahead': steps,
                'most_likely_regime': current_regime,
                'most_likely_probability': 1.0,
                'confidence': 0.5,
                'uncertainty': 0.5,
                'all_predictions': [],
                'method': 'markov_chain',
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def calculate_steady_state_distribution(self) -> Dict[str, float]:
        """
        ì •ìƒ ìƒíƒœ ë¶„í¬ ê³„ì‚° (ì¥ê¸° í‰í˜• ìƒíƒœ)

        Returns:
            ê° ë ˆì§ì˜ ì •ìƒ ìƒíƒœ í™•ë¥ 
        """
        try:
            if self.transition_matrix is None:
                raise ValueError("Transition matrix not built yet")

            # ê³ ìœ ê°’ ë¶„í•´
            eigenvalues, eigenvectors = eig(self.transition_matrix.T)

            # ê³ ìœ ê°’ 1ì— í•´ë‹¹í•˜ëŠ” ê³ ìœ ë²¡í„° ì°¾ê¸°
            idx = np.argmax(np.abs(eigenvalues - 1.0) < 1e-6)
            steady_state = np.real(eigenvectors[:, idx])

            # ì •ê·œí™”
            steady_state = steady_state / steady_state.sum()

            # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            result = {
                regime: float(prob)
                for regime, prob in zip(self.regimes, steady_state)
            }

            return result

        except Exception as e:
            self.logger.error(f"Steady state calculation error: {e}")

            # í´ë°±: ê· ë“± ë¶„í¬
            return {regime: 1.0 / len(self.regimes) for regime in self.regimes}

    def calculate_expected_return_time(self, target_regime: str) -> float:
        """
        íŠ¹ì • ë ˆì§ìœ¼ë¡œ ëŒì•„ì˜¤ëŠ” í‰ê·  ì‹œê°„ ê³„ì‚°

        Args:
            target_regime: ëª©í‘œ ë ˆì§

        Returns:
            í‰ê·  íšŒê·€ ì‹œê°„ (ìŠ¤í… ìˆ˜)
        """
        try:
            steady_state = self.calculate_steady_state_distribution()
            prob = steady_state.get(target_regime, 0)

            if prob > 0:
                return 1.0 / prob
            else:
                return float('inf')

        except Exception as e:
            self.logger.error(f"Expected return time error: {e}")
            return float('inf')

    def analyze_transition_patterns(self) -> Dict[str, Any]:
        """
        ì „í™˜ íŒ¨í„´ ë¶„ì„

        Returns:
            ì „í™˜ í†µê³„ ë° íŒ¨í„´
        """
        try:
            if self.transition_matrix is None or self.transition_counts is None:
                raise ValueError("Transition matrix not built yet")

            # ê°€ì¥ ë¹ˆë²ˆí•œ ì „í™˜
            most_common_transitions = []
            for i in range(len(self.regimes)):
                for j in range(len(self.regimes)):
                    if i != j and self.transition_counts[i, j] > 0:
                        most_common_transitions.append({
                            'from': self.regimes[i],
                            'to': self.regimes[j],
                            'count': int(self.transition_counts[i, j]),
                            'probability': float(self.transition_matrix[i, j])
                        })

            most_common_transitions.sort(key=lambda x: x['count'], reverse=True)

            # ê°€ì¥ ì•ˆì •ì ì¸ ë ˆì§ (ìê¸° ì „í™˜ í™•ë¥ ì´ ë†’ì€)
            stability_scores = {}
            for i, regime in enumerate(self.regimes):
                stability_scores[regime] = float(self.transition_matrix[i, i])

            most_stable = max(stability_scores.items(), key=lambda x: x[1])
            least_stable = min(stability_scores.items(), key=lambda x: x[1])

            # í‰ê·  ì§€ì† ì‹œê°„
            avg_durations = {}
            for regime, prob in stability_scores.items():
                if prob < 1.0:
                    avg_durations[regime] = 1.0 / (1.0 - prob)
                else:
                    avg_durations[regime] = float('inf')

            # ì •ìƒ ìƒíƒœ ë¶„í¬
            steady_state = self.calculate_steady_state_distribution()

            result = {
                'total_transitions': self.total_transitions,
                'most_common_transitions': most_common_transitions[:10],
                'stability_scores': stability_scores,
                'most_stable_regime': most_stable[0],
                'most_stable_probability': most_stable[1],
                'least_stable_regime': least_stable[0],
                'least_stable_probability': least_stable[1],
                'average_durations': avg_durations,
                'steady_state_distribution': steady_state,
                'timestamp': datetime.now()
            }

            return result

        except Exception as e:
            self.logger.error(f"Transition pattern analysis error: {e}")
            return {
                'total_transitions': 0,
                'error': str(e),
                'timestamp': datetime.now()
            }

    def predict_multiple_horizons(self, current_regime: str,
                                  horizons: List[int] = None) -> Dict[int, Dict]:
        """
        ì—¬ëŸ¬ ì‹œê°„ëŒ€ì— ëŒ€í•œ ì˜ˆì¸¡

        Args:
            current_regime: í˜„ì¬ ë ˆì§
            horizons: ì˜ˆì¸¡ ì‹œê°„ëŒ€ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)

        Returns:
            ê° ì‹œê°„ëŒ€ë³„ ì˜ˆì¸¡ ê²°ê³¼
        """
        if horizons is None:
            horizons = ProductionConfig.TRANSITION_PREDICTION_HORIZON

        predictions = {}
        for horizon in horizons:
            try:
                pred = self.predict_next_regime(current_regime, steps=horizon)
                predictions[horizon] = pred
            except Exception as e:
                self.logger.error(f"Prediction error for horizon {horizon}: {e}")
                predictions[horizon] = {
                    'error': str(e),
                    'horizon': horizon
                }

        return predictions

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
        cache_hit_rate = (
                self.cache_hit_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'cache_hits': self.cache_hit_count,
            'cache_hit_rate': cache_hit_rate,
            'errors': self.error_count,
            'error_rate': error_rate,
            'total_transitions': self.total_transitions,
            'last_update': self.last_update_time.isoformat() if self.last_update_time else None,
            'history_size': len(self.transition_history)
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# END OF PART 2/6
# ë‹¤ìŒ: Part 3 - Hidden Markov Model Predictor
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ğŸ”¥ğŸ”¥ MARKET REGIME ANALYZER 12.0 - PART 3/6 ğŸ”¥ğŸ”¥ğŸ”¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Part 3: Hidden Markov Model & Conditional Transition Analyzer
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Part 2ì—ì„œ ê³„ì†...

class HiddenMarkovModelPredictor:
    """
    ğŸ”® Hidden Markov Model ê¸°ë°˜ ë ˆì§ ì˜ˆì¸¡ê¸° (v12.0 NEW - í”„ë¡œë•ì…˜ ë ˆë²¨)

    HMMì„ ì‚¬ìš©í•˜ì—¬ ìˆ¨ê²¨ì§„ ë ˆì§ ìƒíƒœë¥¼ ì¶”ë¡ í•˜ê³  ë¯¸ë˜ ì „í™˜ ì˜ˆì¸¡
    """

    def __init__(self):
        self.logger = get_logger("HMM_Predictor")
        self.validator = DataValidator()

        # HMM íŒŒë¼ë¯¸í„°
        self.n_states = ProductionConfig.HMM_N_STATES
        self.transition_probs = None
        self.emission_probs = None
        self.initial_probs = None

        # ê´€ì¸¡ ê°€ëŠ¥í•œ íŠ¹ì§•ë“¤
        self.observable_features = [
            'volatility', 'volume', 'momentum', 'sentiment'
        ]

        # íˆìŠ¤í† ë¦¬
        self.prediction_history = deque(maxlen=500)

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.api_call_count = 0
        self.error_count = 0

    def fit(self, regime_history: List[Dict],
            market_features: pd.DataFrame) -> bool:
        """
        HMM ëª¨ë¸ í•™ìŠµ

        Args:
            regime_history: ë ˆì§ íˆìŠ¤í† ë¦¬
            market_features: ê´€ì¸¡ ê°€ëŠ¥í•œ ì‹œì¥ íŠ¹ì§• DataFrame

        Returns:
            í•™ìŠµ ì„±ê³µ ì—¬ë¶€
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            if len(regime_history) < ProductionConfig.MIN_HISTORY_FOR_PREDICTION:
                raise ValueError("Insufficient history for HMM training")

            # ê°„ì†Œí™”ëœ HMM í•™ìŠµ (í”„ë¡œë•ì…˜ í™˜ê²½)
            # ì‹¤ì œë¡œëŠ” Baum-Welch ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©

            # 1. ì „í™˜ í™•ë¥  í–‰ë ¬ ì´ˆê¸°í™”
            self.transition_probs = self._estimate_transition_matrix(regime_history)

            # 2. ë°©ì¶œ í™•ë¥  ì´ˆê¸°í™” (ê´€ì¸¡ê°’ì´ ì£¼ì–´ì¡Œì„ ë•Œ ìƒíƒœ í™•ë¥ )
            self.emission_probs = self._estimate_emission_matrix(
                regime_history, market_features
            )

            # 3. ì´ˆê¸° ìƒíƒœ í™•ë¥ 
            self.initial_probs = self._estimate_initial_distribution(regime_history)

            # ê²€ì¦
            if not self.validator.validate_transition_matrix(self.transition_probs):
                raise ValueError("Invalid HMM transition matrix")

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('hmm_fit', latency)

            return True

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"HMM fit error: {e}")
            performance_monitor.record_error('hmm_fit', e)
            return False

    def predict(self, current_observations: Dict[str, float],
                steps: int = 1) -> Dict[str, Any]:
        """
        í˜„ì¬ ê´€ì¸¡ê°’ìœ¼ë¡œë¶€í„° ë¯¸ë˜ ë ˆì§ ì˜ˆì¸¡

        Args:
            current_observations: í˜„ì¬ ê´€ì¸¡ íŠ¹ì§•ë“¤
            steps: ì˜ˆì¸¡ ìŠ¤í… ìˆ˜

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼
        """
        start_time = datetime.now()

        try:
            if self.transition_probs is None:
                raise ValueError("HMM not trained yet")

            # Viterbi ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ í˜„ì¬ ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ìƒíƒœ ì¶”ë¡ 
            current_state_probs = self._infer_current_state(current_observations)

            # N ìŠ¤í… ì „ë°© ì˜ˆì¸¡
            future_state_probs = self._forward_prediction(
                current_state_probs, steps
            )

            # ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ë ˆì§
            most_likely_idx = np.argmax(future_state_probs)
            most_likely_prob = future_state_probs[most_likely_idx]

            # ì—”íŠ¸ë¡œí”¼ (ë¶ˆí™•ì‹¤ì„±)
            entropy_value = entropy(future_state_probs + 1e-10)
            max_entropy = np.log(self.n_states)
            uncertainty = entropy_value / max_entropy

            # ëª¨ë“  ìƒíƒœ í™•ë¥ 
            all_predictions = [
                {
                    'state_index': int(i),
                    'probability': float(prob)
                }
                for i, prob in enumerate(future_state_probs)
            ]
            all_predictions.sort(key=lambda x: x['probability'], reverse=True)

            result = {
                'steps_ahead': steps,
                'most_likely_state_index': int(most_likely_idx),
                'most_likely_probability': float(most_likely_prob),
                'confidence': float(most_likely_prob),
                'uncertainty': float(uncertainty),
                'all_state_probabilities': all_predictions,
                'current_state_inference': {
                    'state_probabilities': current_state_probs.tolist()
                },
                'method': 'hmm',
                'timestamp': datetime.now()
            }

            # íˆìŠ¤í† ë¦¬
            self.prediction_history.append(result)

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('hmm_predict', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"HMM predict error: {e}")
            performance_monitor.record_error('hmm_predict', e)

            return {
                'steps_ahead': steps,
                'most_likely_state_index': 0,
                'most_likely_probability': 1.0 / self.n_states,
                'confidence': 0.5,
                'uncertainty': 0.5,
                'method': 'hmm',
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def _estimate_transition_matrix(self, regime_history: List[Dict]) -> np.ndarray:
        """ì „í™˜ í–‰ë ¬ ì¶”ì •"""
        counts = np.zeros((self.n_states, self.n_states))

        # ë ˆì§ì„ ìƒíƒœ ì¸ë±ìŠ¤ë¡œ ë§¤í•‘ (ê°„ì†Œí™”)
        regime_map = {
            'BULL_CONSOLIDATION': 0,
            'BULL_VOLATILITY': 1,
            'BEAR_CONSOLIDATION': 2,
            'BEAR_VOLATILITY': 3,
            'SIDEWAYS_COMPRESSION': 4,
            'SIDEWAYS_CHOP': 5,
            'ACCUMULATION': 6,
            'DISTRIBUTION': 7
        }

        for i in range(len(regime_history) - 1):
            current = regime_history[i].get('regime', 'UNCERTAIN')
            next_regime = regime_history[i + 1].get('regime', 'UNCERTAIN')

            if current in regime_map and next_regime in regime_map:
                curr_idx = regime_map[current]
                next_idx = regime_map[next_regime]
                counts[curr_idx, next_idx] += 1

        # í™•ë¥ ë¡œ ë³€í™˜
        trans_matrix = np.zeros_like(counts, dtype=float)
        for i in range(self.n_states):
            row_sum = counts[i].sum()
            if row_sum > 0:
                trans_matrix[i] = counts[i] / row_sum
            else:
                trans_matrix[i] = 1.0 / self.n_states

        return trans_matrix

    def _estimate_emission_matrix(self, regime_history: List[Dict],
                                  features: pd.DataFrame) -> np.ndarray:
        """ë°©ì¶œ í™•ë¥  í–‰ë ¬ ì¶”ì • (ê°„ì†Œí™”)"""
        # ì‹¤ì œë¡œëŠ” ê°€ìš°ì‹œì•ˆ í˜¼í•© ëª¨ë¸ ë“± ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ êµ¬í˜„

        # ê° ìƒíƒœì—ì„œ ê´€ì¸¡ê°’ì˜ í‰ê· /ë¶„ì‚° ì¶”ì •
        emission_matrix = np.random.rand(self.n_states, len(self.observable_features))

        # ì •ê·œí™”
        emission_matrix = emission_matrix / emission_matrix.sum(axis=0, keepdims=True)

        return emission_matrix

    def _estimate_initial_distribution(self, regime_history: List[Dict]) -> np.ndarray:
        """ì´ˆê¸° ìƒíƒœ ë¶„í¬ ì¶”ì •"""
        if not regime_history:
            return np.ones(self.n_states) / self.n_states

        first_regime = regime_history[0].get('regime', 'UNCERTAIN')

        # ê°„ì†Œí™”: ì²« ë ˆì§ì— ë†’ì€ í™•ë¥ 
        init_probs = np.ones(self.n_states) * 0.1
        init_probs[0] = 0.3  # ì„ì˜ ì„¤ì •
        init_probs = init_probs / init_probs.sum()

        return init_probs

    def _infer_current_state(self, observations: Dict[str, float]) -> np.ndarray:
        """í˜„ì¬ ê´€ì¸¡ê°’ìœ¼ë¡œë¶€í„° ìƒíƒœ ì¶”ë¡  (Forward algorithm ê°„ì†Œí™”)"""
        # ê°„ì†Œí™”ëœ ì¶”ë¡ 
        # ì‹¤ì œë¡œëŠ” Forward ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©

        state_probs = self.initial_probs.copy()

        # ê´€ì¸¡ ê°€ëŠ¥ë„ ë°˜ì˜ (ê°„ì†Œí™”)
        for feature in self.observable_features:
            if feature in observations:
                # ê°„ë‹¨í•œ ê°€ìš°ì‹œì•ˆ ê°€ëŠ¥ë„
                obs_value = observations[feature]
                # ê° ìƒíƒœì—ì„œ ì´ ê´€ì¸¡ê°’ì˜ ê°€ëŠ¥ë„ ê³„ì‚° (ê°„ì†Œí™”)
                likelihoods = np.exp(-0.5 * (np.arange(self.n_states) - obs_value) ** 2)
                state_probs *= likelihoods

        # ì •ê·œí™”
        state_probs = state_probs / (state_probs.sum() + 1e-10)

        return state_probs

    def _forward_prediction(self, current_probs: np.ndarray,
                            steps: int) -> np.ndarray:
        """ì „ë°© ì˜ˆì¸¡"""
        # ì „í™˜ í–‰ë ¬ì˜ ê±°ë“­ì œê³±
        trans_power = np.linalg.matrix_power(self.transition_probs, steps)
        future_probs = current_probs @ trans_power

        return future_probs

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'errors': self.error_count,
            'error_rate': error_rate,
            'history_size': len(self.prediction_history),
            'is_trained': self.transition_probs is not None
        }


class ConditionalTransitionAnalyzer:
    """
    ğŸ§® ì¡°ê±´ë¶€ ì „í™˜ í™•ë¥  ë¶„ì„ê¸° (v12.0 NEW - í”„ë¡œë•ì…˜ ë ˆë²¨)

    ì‹œì¥ ì¡°ê±´(ë³€ë™ì„±, ìœ ë™ì„± ë“±)ì— ë”°ë¥¸ ì¡°ê±´ë¶€ ì „í™˜ í™•ë¥  ë¶„ì„
    """

    def __init__(self):
        self.logger = get_logger("ConditionalTransition")
        self.validator = DataValidator()

        # ì¡°ê±´ ì¹´í…Œê³ ë¦¬
        self.condition_categories = {
            'volatility': ['LOW', 'MEDIUM', 'HIGH', 'EXTREME'],
            'volume': ['LOW', 'MEDIUM', 'HIGH'],
            'liquidity': ['LOW', 'MEDIUM', 'HIGH'],
            'momentum': ['STRONG_NEGATIVE', 'NEGATIVE', 'NEUTRAL', 'POSITIVE', 'STRONG_POSITIVE']
        }

        # ì¡°ê±´ë¶€ ì „í™˜ í–‰ë ¬ë“¤
        self.conditional_matrices = {}

        # íˆìŠ¤í† ë¦¬
        self.analysis_history = deque(maxlen=200)

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.api_call_count = 0
        self.error_count = 0

    def build_conditional_matrices(self, regime_history: List[Dict],
                                   market_conditions: pd.DataFrame) -> Dict[str, np.ndarray]:
        """
        ì¡°ê±´ë³„ ì „í™˜ í™•ë¥  í–‰ë ¬ êµ¬ì¶•

        Args:
            regime_history: ë ˆì§ íˆìŠ¤í† ë¦¬
            market_conditions: ì‹œì¥ ì¡°ê±´ DataFrame

        Returns:
            ì¡°ê±´ë³„ ì „í™˜ í–‰ë ¬ ë”•ì…”ë„ˆë¦¬
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            if len(regime_history) < ProductionConfig.MIN_HISTORY_FOR_PREDICTION:
                raise ValueError("Insufficient history")

            # ê° ì¡°ê±´ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì „í™˜ í–‰ë ¬ êµ¬ì¶•
            for condition_name in self.condition_categories:
                for condition_value in self.condition_categories[condition_name]:

                    # í•´ë‹¹ ì¡°ê±´ì—ì„œì˜ ì „í™˜ë§Œ í•„í„°ë§
                    filtered_transitions = self._filter_transitions_by_condition(
                        regime_history,
                        market_conditions,
                        condition_name,
                        condition_value
                    )

                    if len(filtered_transitions) >= 10:  # ìµœì†Œ ë°ì´í„° í•„ìš”
                        matrix = self._build_matrix_from_transitions(filtered_transitions)

                        key = f"{condition_name}_{condition_value}"
                        self.conditional_matrices[key] = matrix

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('build_conditional_matrices', latency)

            return self.conditional_matrices

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Build conditional matrices error: {e}")
            performance_monitor.record_error('build_conditional_matrices', e)
            return {}

    def predict_conditional_transition(self, current_regime: str,
                                       market_condition: Dict[str, str],
                                       steps: int = 1) -> Dict[str, Any]:
        """
        ì¡°ê±´ë¶€ ì „í™˜ í™•ë¥  ì˜ˆì¸¡

        Args:
            current_regime: í˜„ì¬ ë ˆì§
            market_condition: í˜„ì¬ ì‹œì¥ ì¡°ê±´ {'volatility': 'HIGH', ...}
            steps: ì˜ˆì¸¡ ìŠ¤í…

        Returns:
            ì¡°ê±´ë¶€ ì˜ˆì¸¡ ê²°ê³¼
        """
        start_time = datetime.now()

        try:
            # ì¡°ê±´ì— ë§ëŠ” ì „í™˜ í–‰ë ¬ ì„ íƒ
            applicable_matrices = []

            for cond_name, cond_value in market_condition.items():
                key = f"{cond_name}_{cond_value}"
                if key in self.conditional_matrices:
                    applicable_matrices.append({
                        'condition': key,
                        'matrix': self.conditional_matrices[key]
                    })

            if not applicable_matrices:
                raise ValueError("No conditional matrices available for given conditions")

            # ì—¬ëŸ¬ ì¡°ê±´ì˜ í–‰ë ¬ì„ í‰ê·  (ê°„ë‹¨í•œ ì•™ìƒë¸”)
            avg_matrix = np.mean(
                [m['matrix'] for m in applicable_matrices],
                axis=0
            )

            # í˜„ì¬ ë ˆì§ ì¸ë±ìŠ¤
            regimes = [
                'BULL_CONSOLIDATION', 'BULL_VOLATILITY',
                'BEAR_CONSOLIDATION', 'BEAR_VOLATILITY',
                'SIDEWAYS_COMPRESSION', 'SIDEWAYS_CHOP',
                'ACCUMULATION', 'DISTRIBUTION'
            ]

            if current_regime not in regimes:
                raise ValueError(f"Unknown regime: {current_regime}")

            current_idx = regimes.index(current_regime)

            # ìƒíƒœ ë²¡í„°
            state_vector = np.zeros(len(regimes))
            state_vector[current_idx] = 1.0

            # N ìŠ¤í… ì˜ˆì¸¡
            trans_power = np.linalg.matrix_power(avg_matrix, steps)
            predicted_probs = state_vector @ trans_power

            # ê²°ê³¼ ì •ë¦¬
            predictions = [
                {
                    'regime': regime,
                    'probability': float(prob)
                }
                for regime, prob in zip(regimes, predicted_probs)
            ]
            predictions.sort(key=lambda x: x['probability'], reverse=True)

            most_likely = predictions[0]

            # ì¡°ê±´ë¶€ ì‹ ë¢°ë„ ê³„ì‚°
            confidence = most_likely['probability']

            # ì¡°ê±´ì˜ ì˜í–¥ë ¥ ê³„ì‚°
            condition_impacts = self._calculate_condition_impacts(
                applicable_matrices, current_idx
            )

            result = {
                'current_regime': current_regime,
                'market_conditions': market_condition,
                'steps_ahead': steps,
                'most_likely_regime': most_likely['regime'],
                'most_likely_probability': most_likely['probability'],
                'confidence': float(confidence),
                'all_predictions': predictions,
                'applicable_conditions': [m['condition'] for m in applicable_matrices],
                'condition_impacts': condition_impacts,
                'method': 'conditional_transition',
                'timestamp': datetime.now()
            }

            # íˆìŠ¤í† ë¦¬
            self.analysis_history.append(result)

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('predict_conditional_transition', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Conditional transition prediction error: {e}")
            performance_monitor.record_error('predict_conditional_transition', e)

            return {
                'current_regime': current_regime,
                'market_conditions': market_condition,
                'steps_ahead': steps,
                'most_likely_regime': current_regime,
                'most_likely_probability': 1.0,
                'confidence': 0.5,
                'method': 'conditional_transition',
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def _filter_transitions_by_condition(self, regime_history: List[Dict],
                                         conditions: pd.DataFrame,
                                         condition_name: str,
                                         condition_value: str) -> List[Tuple[str, str]]:
        """ì¡°ê±´ì— ë§ëŠ” ì „í™˜ë§Œ í•„í„°ë§"""
        filtered = []

        for i in range(len(regime_history) - 1):
            # í•´ë‹¹ ì‹œì ì˜ ì¡°ê±´ í™•ì¸
            timestamp = regime_history[i].get('timestamp')

            # ì¡°ê±´ì´ ë§ëŠ”ì§€ í™•ì¸ (ê°„ì†Œí™”)
            # ì‹¤ì œë¡œëŠ” timestampë¥¼ ê¸°ë°˜ìœ¼ë¡œ conditions DataFrameì—ì„œ ì¡°íšŒ

            current_regime = regime_history[i].get('regime')
            next_regime = regime_history[i + 1].get('regime')

            filtered.append((current_regime, next_regime))

        return filtered

    def _build_matrix_from_transitions(self, transitions: List[Tuple[str, str]]) -> np.ndarray:
        """ì „í™˜ ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° í™•ë¥  í–‰ë ¬ êµ¬ì¶•"""
        regimes = [
            'BULL_CONSOLIDATION', 'BULL_VOLATILITY',
            'BEAR_CONSOLIDATION', 'BEAR_VOLATILITY',
            'SIDEWAYS_COMPRESSION', 'SIDEWAYS_CHOP',
            'ACCUMULATION', 'DISTRIBUTION'
        ]

        n = len(regimes)
        counts = np.zeros((n, n))

        regime_to_idx = {r: i for i, r in enumerate(regimes)}

        for curr, next_r in transitions:
            if curr in regime_to_idx and next_r in regime_to_idx:
                i = regime_to_idx[curr]
                j = regime_to_idx[next_r]
                counts[i, j] += 1

        # í™•ë¥ ë¡œ ë³€í™˜
        matrix = np.zeros_like(counts, dtype=float)
        for i in range(n):
            row_sum = counts[i].sum()
            if row_sum > 0:
                matrix[i] = counts[i] / row_sum
            else:
                matrix[i] = 1.0 / n

        return matrix

    def _calculate_condition_impacts(self, applicable_matrices: List[Dict],
                                     current_idx: int) -> Dict[str, float]:
        """ê° ì¡°ê±´ì´ ì „í™˜ í™•ë¥ ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ê³„ì‚°"""
        impacts = {}

        for matrix_info in applicable_matrices:
            condition = matrix_info['condition']
            matrix = matrix_info['matrix']

            # í˜„ì¬ ìƒíƒœì—ì„œ ì „í™˜ í™•ë¥ ì˜ ì—”íŠ¸ë¡œí”¼
            probs = matrix[current_idx]
            ent = entropy(probs + 1e-10)

            # ì—”íŠ¸ë¡œí”¼ê°€ ë‚®ì„ìˆ˜ë¡ ì˜í–¥ë ¥ì´ í¬ë‹¤ (í™•ì‹¤í•œ ì˜ˆì¸¡)
            max_ent = np.log(len(probs))
            impact = 1.0 - (ent / max_ent)

            impacts[condition] = float(impact)

        return impacts

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'errors': self.error_count,
            'error_rate': error_rate,
            'n_conditional_matrices': len(self.conditional_matrices),
            'history_size': len(self.analysis_history)
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# END OF PART 3/6
# ë‹¤ìŒ: Part 4 - Bayesian Transition Updater & Ensemble Predictor
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ğŸ”¥ğŸ”¥ MARKET REGIME ANALYZER 12.0 - PART 4/6 ğŸ”¥ğŸ”¥ğŸ”¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Part 4: Bayesian Transition Updater & Ensemble Predictor
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Part 3ì—ì„œ ê³„ì†...

class BayesianTransitionUpdater:
    """
    ğŸ“ˆ ë² ì´ì§€ì•ˆ ì „í™˜ í™•ë¥  ì—…ë°ì´í„° (v12.0 NEW - í”„ë¡œë•ì…˜ ë ˆë²¨)

    ìƒˆë¡œìš´ ê´€ì¸¡ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì „í™˜ í™•ë¥ ì„ ë² ì´ì§€ì•ˆ ë°©ì‹ìœ¼ë¡œ ì—…ë°ì´íŠ¸
    """

    def __init__(self):
        self.logger = get_logger("BayesianUpdater")
        self.validator = DataValidator()

        # ì‚¬ì „ ë¶„í¬ (Prior)
        self.prior_strength = ProductionConfig.BAYESIAN_PRIOR_STRENGTH

        # ë ˆì§ ì •ì˜
        self.regimes = [
            'BULL_CONSOLIDATION', 'BULL_VOLATILITY',
            'BEAR_CONSOLIDATION', 'BEAR_VOLATILITY',
            'SIDEWAYS_COMPRESSION', 'SIDEWAYS_CHOP',
            'ACCUMULATION', 'DISTRIBUTION'
        ]

        # ì‚¬ì „ ë¶„í¬ í–‰ë ¬ (ê· ë“± ë¶„í¬ë¡œ ì´ˆê¸°í™”)
        n = len(self.regimes)
        self.prior_matrix = np.ones((n, n)) / n

        # ì‚¬í›„ ë¶„í¬ (Posterior)
        self.posterior_matrix = self.prior_matrix.copy()

        # ì—…ë°ì´íŠ¸ íˆìŠ¤í† ë¦¬
        self.update_history = deque(maxlen=500)

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.api_call_count = 0
        self.error_count = 0
        self.n_updates = 0

    def update_with_observation(self, observed_transition: Tuple[str, str],
                                likelihood_weight: float = 1.0) -> np.ndarray:
        """
        ê´€ì¸¡ëœ ì „í™˜ìœ¼ë¡œ ì‚¬í›„ í™•ë¥  ì—…ë°ì´íŠ¸

        Args:
            observed_transition: (from_regime, to_regime)
            likelihood_weight: ê´€ì¸¡ì˜ ê°€ì¤‘ì¹˜ (ì‹ ë¢°ë„)

        Returns:
            ì—…ë°ì´íŠ¸ëœ ì‚¬í›„ í™•ë¥  í–‰ë ¬
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            from_regime, to_regime = observed_transition

            if from_regime not in self.regimes or to_regime not in self.regimes:
                raise ValueError(f"Unknown regime in transition: {from_regime} -> {to_regime}")

            from_idx = self.regimes.index(from_regime)
            to_idx = self.regimes.index(to_regime)

            # ë² ì´ì§€ì•ˆ ì—…ë°ì´íŠ¸
            # Posterior âˆ Prior Ã— Likelihood

            # Likelihood: ê´€ì¸¡ëœ ì „í™˜ì— ë†’ì€ í™•ë¥ 
            likelihood = np.zeros_like(self.posterior_matrix)
            likelihood[from_idx, to_idx] = likelihood_weight

            # ë‹¤ë¥¸ ì „í™˜ì—ëŠ” ì‘ì€ í™•ë¥  (ìŠ¤ë¬´ë”©)
            smoothing = 0.01
            likelihood[from_idx, :] += smoothing

            # í–‰ ì •ê·œí™”
            likelihood[from_idx] = likelihood[from_idx] / likelihood[from_idx].sum()

            # ì‚¬í›„ í™•ë¥  ì—…ë°ì´íŠ¸ (ì§€ìˆ˜ê°€ì¤‘ ì´ë™í‰ê· )
            alpha = 0.1  # í•™ìŠµë¥ 
            self.posterior_matrix[from_idx] = (
                    (1 - alpha) * self.posterior_matrix[from_idx] +
                    alpha * likelihood[from_idx]
            )

            # ì •ê·œí™”
            self.posterior_matrix[from_idx] = (
                    self.posterior_matrix[from_idx] /
                    self.posterior_matrix[from_idx].sum()
            )

            # ì—…ë°ì´íŠ¸ ê¸°ë¡
            self.n_updates += 1

            update_record = {
                'transition': observed_transition,
                'likelihood_weight': likelihood_weight,
                'timestamp': datetime.now(),
                'n_updates': self.n_updates
            }
            self.update_history.append(update_record)

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('bayesian_update', latency)

            return self.posterior_matrix

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Bayesian update error: {e}")
            performance_monitor.record_error('bayesian_update', e)
            return self.posterior_matrix

    def predict_with_posterior(self, current_regime: str,
                               steps: int = 1) -> Dict[str, Any]:
        """
        ì‚¬í›„ í™•ë¥  í–‰ë ¬ë¡œ ì˜ˆì¸¡

        Args:
            current_regime: í˜„ì¬ ë ˆì§
            steps: ì˜ˆì¸¡ ìŠ¤í…

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼
        """
        try:
            if current_regime not in self.regimes:
                raise ValueError(f"Unknown regime: {current_regime}")

            current_idx = self.regimes.index(current_regime)

            # ìƒíƒœ ë²¡í„°
            state_vector = np.zeros(len(self.regimes))
            state_vector[current_idx] = 1.0

            # N ìŠ¤í… ì˜ˆì¸¡
            trans_power = np.linalg.matrix_power(self.posterior_matrix, steps)
            predicted_probs = state_vector @ trans_power

            # ê²°ê³¼ ì •ë¦¬
            predictions = [
                {
                    'regime': regime,
                    'probability': float(prob)
                }
                for regime, prob in zip(self.regimes, predicted_probs)
            ]
            predictions.sort(key=lambda x: x['probability'], reverse=True)

            most_likely = predictions[0]

            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = most_likely['probability']

            # ì‚¬ì „-ì‚¬í›„ ì°¨ì´ (ì–¼ë§ˆë‚˜ í•™ìŠµí–ˆëŠ”ì§€)
            kl_divergence = self._calculate_kl_divergence(
                self.prior_matrix[current_idx],
                self.posterior_matrix[current_idx]
            )

            result = {
                'current_regime': current_regime,
                'steps_ahead': steps,
                'most_likely_regime': most_likely['regime'],
                'most_likely_probability': most_likely['probability'],
                'confidence': float(confidence),
                'all_predictions': predictions,
                'n_updates': self.n_updates,
                'prior_posterior_divergence': float(kl_divergence),
                'method': 'bayesian',
                'timestamp': datetime.now()
            }

            return result

        except Exception as e:
            self.logger.error(f"Bayesian predict error: {e}")
            return {
                'current_regime': current_regime,
                'steps_ahead': steps,
                'most_likely_regime': current_regime,
                'most_likely_probability': 1.0,
                'confidence': 0.5,
                'method': 'bayesian',
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def reset_to_prior(self):
        """ì‚¬í›„ ë¶„í¬ë¥¼ ì‚¬ì „ ë¶„í¬ë¡œ ë¦¬ì…‹"""
        self.posterior_matrix = self.prior_matrix.copy()
        self.n_updates = 0
        self.logger.info("Reset posterior to prior distribution")

    def set_informative_prior(self, expert_matrix: np.ndarray):
        """
        ì „ë¬¸ê°€ ì§€ì‹ ê¸°ë°˜ ì‚¬ì „ ë¶„í¬ ì„¤ì •

        Args:
            expert_matrix: ì „ë¬¸ê°€ê°€ ì œê³µí•œ ì „í™˜ í™•ë¥  í–‰ë ¬
        """
        try:
            if not self.validator.validate_transition_matrix(expert_matrix):
                raise ValueError("Invalid expert matrix")

            self.prior_matrix = expert_matrix.copy()
            self.posterior_matrix = expert_matrix.copy()
            self.logger.info("Set informative prior from expert knowledge")

        except Exception as e:
            self.logger.error(f"Set prior error: {e}")

    def _calculate_kl_divergence(self, p: np.ndarray, q: np.ndarray) -> float:
        """KL Divergence ê³„ì‚°"""
        # KL(P||Q) = Î£ P(i) log(P(i)/Q(i))
        p_safe = p + 1e-10
        q_safe = q + 1e-10
        return float(np.sum(p_safe * np.log(p_safe / q_safe)))

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'errors': self.error_count,
            'error_rate': error_rate,
            'n_updates': self.n_updates,
            'history_size': len(self.update_history)
        }


class EnsembleTransitionPredictor:
    """
    ğŸ² ì•™ìƒë¸” ì „í™˜ ì˜ˆì¸¡ê¸° (v12.0 NEW - í”„ë¡œë•ì…˜ ë ˆë²¨)

    ì—¬ëŸ¬ ì˜ˆì¸¡ ë°©ë²•ì„ ê²°í•©í•˜ì—¬ robustí•œ ì˜ˆì¸¡ ì œê³µ
    """

    def __init__(self, markov_analyzer: MarkovChainTransitionAnalyzer,
                 hmm_predictor: HiddenMarkovModelPredictor,
                 conditional_analyzer: ConditionalTransitionAnalyzer,
                 bayesian_updater: BayesianTransitionUpdater):

        self.logger = get_logger("EnsemblePredictor")
        self.validator = DataValidator()

        # ê°œë³„ ì˜ˆì¸¡ê¸°ë“¤
        self.markov = markov_analyzer
        self.hmm = hmm_predictor
        self.conditional = conditional_analyzer
        self.bayesian = bayesian_updater

        # ì˜ˆì¸¡ê¸°ë³„ ê°€ì¤‘ì¹˜ (ì ì‘ì ìœ¼ë¡œ ì¡°ì •)
        self.predictor_weights = {
            'markov': 0.30,
            'hmm': 0.25,
            'conditional': 0.25,
            'bayesian': 0.20
        }

        # ë ˆì§ ì •ì˜
        self.regimes = [
            'BULL_CONSOLIDATION', 'BULL_VOLATILITY',
            'BEAR_CONSOLIDATION', 'BEAR_VOLATILITY',
            'SIDEWAYS_COMPRESSION', 'SIDEWAYS_CHOP',
            'ACCUMULATION', 'DISTRIBUTION'
        ]

        # íˆìŠ¤í† ë¦¬
        self.prediction_history = deque(maxlen=500)

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.api_call_count = 0
        self.error_count = 0

    def predict_ensemble(self, current_regime: str,
                         market_conditions: Optional[Dict] = None,
                         market_features: Optional[Dict] = None,
                         steps: int = 1) -> Dict[str, Any]:
        """
        ì•™ìƒë¸” ì˜ˆì¸¡

        Args:
            current_regime: í˜„ì¬ ë ˆì§
            market_conditions: ì‹œì¥ ì¡°ê±´ (ì¡°ê±´ë¶€ ì˜ˆì¸¡ìš©)
            market_features: ì‹œì¥ íŠ¹ì§• (HMMìš©)
            steps: ì˜ˆì¸¡ ìŠ¤í…

        Returns:
            ì•™ìƒë¸” ì˜ˆì¸¡ ê²°ê³¼
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            # ê° ì˜ˆì¸¡ê¸°ë¡œë¶€í„° ì˜ˆì¸¡
            predictions = {}
            confidences = {}

            # 1. Markov Chain ì˜ˆì¸¡
            try:
                markov_pred = self.markov.predict_next_regime(current_regime, steps)
                predictions['markov'] = markov_pred
                confidences['markov'] = markov_pred.get('confidence', 0.5)
            except Exception as e:
                self.logger.warning(f"Markov prediction failed: {e}")
                predictions['markov'] = None
                confidences['markov'] = 0.0

            # 2. HMM ì˜ˆì¸¡
            try:
                if market_features:
                    hmm_pred = self.hmm.predict(market_features, steps)
                    predictions['hmm'] = hmm_pred
                    confidences['hmm'] = hmm_pred.get('confidence', 0.5)
                else:
                    predictions['hmm'] = None
                    confidences['hmm'] = 0.0
            except Exception as e:
                self.logger.warning(f"HMM prediction failed: {e}")
                predictions['hmm'] = None
                confidences['hmm'] = 0.0

            # 3. ì¡°ê±´ë¶€ ì˜ˆì¸¡
            try:
                if market_conditions:
                    cond_pred = self.conditional.predict_conditional_transition(
                        current_regime, market_conditions, steps
                    )
                    predictions['conditional'] = cond_pred
                    confidences['conditional'] = cond_pred.get('confidence', 0.5)
                else:
                    predictions['conditional'] = None
                    confidences['conditional'] = 0.0
            except Exception as e:
                self.logger.warning(f"Conditional prediction failed: {e}")
                predictions['conditional'] = None
                confidences['conditional'] = 0.0

            # 4. ë² ì´ì§€ì•ˆ ì˜ˆì¸¡
            try:
                bayesian_pred = self.bayesian.predict_with_posterior(current_regime, steps)
                predictions['bayesian'] = bayesian_pred
                confidences['bayesian'] = bayesian_pred.get('confidence', 0.5)
            except Exception as e:
                self.logger.warning(f"Bayesian prediction failed: {e}")
                predictions['bayesian'] = None
                confidences['bayesian'] = 0.0

            # ê°€ì¤‘ì¹˜ ì ì‘ì  ì¡°ì • (ì‹ ë¢°ë„ ê¸°ë°˜)
            adjusted_weights = self._adjust_weights_by_confidence(confidences)

            # ì•™ìƒë¸” í™•ë¥  ê³„ì‚°
            ensemble_probs = self._calculate_ensemble_probabilities(
                predictions, adjusted_weights
            )

            # ê²°ê³¼ ì •ë¦¬
            sorted_predictions = sorted(
                ensemble_probs.items(),
                key=lambda x: x[1],
                reverse=True
            )

            most_likely_regime = sorted_predictions[0][0]
            most_likely_prob = sorted_predictions[0][1]

            # ì „ì²´ ì‹ ë¢°ë„ (ê°€ì¤‘ í‰ê· )
            overall_confidence = sum(
                adjusted_weights[k] * confidences[k]
                for k in confidences if confidences[k] > 0
            )

            # ì˜ˆì¸¡ ì¼ì¹˜ë„ (ì—¬ëŸ¬ ëª¨ë¸ì´ ê°™ì€ ì˜ˆì¸¡ì„ í•˜ëŠ”ì§€)
            agreement = self._calculate_prediction_agreement(predictions)

            result = {
                'current_regime': current_regime,
                'steps_ahead': steps,
                'most_likely_regime': most_likely_regime,
                'most_likely_probability': float(most_likely_prob),
                'overall_confidence': float(overall_confidence),
                'prediction_agreement': float(agreement),
                'ensemble_probabilities': {
                    regime: float(prob)
                    for regime, prob in sorted_predictions
                },
                'individual_predictions': {
                    k: v.get('most_likely_regime') if v else None
                    for k, v in predictions.items()
                },
                'individual_confidences': confidences,
                'adjusted_weights': adjusted_weights,
                'method': 'ensemble',
                'timestamp': datetime.now()
            }

            # íˆìŠ¤í† ë¦¬
            self.prediction_history.append(result)

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('ensemble_predict', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Ensemble prediction error: {e}")
            performance_monitor.record_error('ensemble_predict', e)

            return {
                'current_regime': current_regime,
                'steps_ahead': steps,
                'most_likely_regime': current_regime,
                'most_likely_probability': 1.0,
                'overall_confidence': 0.5,
                'prediction_agreement': 0.0,
                'method': 'ensemble',
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def predict_multiple_horizons_ensemble(self, current_regime: str,
                                           market_conditions: Optional[Dict] = None,
                                           market_features: Optional[Dict] = None,
                                           horizons: List[int] = None) -> Dict[int, Dict]:
        """
        ì—¬ëŸ¬ ì‹œê°„ëŒ€ì— ëŒ€í•œ ì•™ìƒë¸” ì˜ˆì¸¡

        Args:
            current_regime: í˜„ì¬ ë ˆì§
            market_conditions: ì‹œì¥ ì¡°ê±´
            market_features: ì‹œì¥ íŠ¹ì§•
            horizons: ì˜ˆì¸¡ ì‹œê°„ëŒ€ ë¦¬ìŠ¤íŠ¸

        Returns:
            ê° ì‹œê°„ëŒ€ë³„ ì˜ˆì¸¡ ê²°ê³¼
        """
        if horizons is None:
            horizons = ProductionConfig.TRANSITION_PREDICTION_HORIZON

        predictions = {}
        for horizon in horizons:
            try:
                pred = self.predict_ensemble(
                    current_regime,
                    market_conditions,
                    market_features,
                    steps=horizon
                )
                predictions[horizon] = pred
            except Exception as e:
                self.logger.error(f"Ensemble prediction error for horizon {horizon}: {e}")
                predictions[horizon] = {
                    'error': str(e),
                    'horizon': horizon
                }

        return predictions

    def _adjust_weights_by_confidence(self, confidences: Dict[str, float]) -> Dict[str, float]:
        """ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •"""
        # ì‹ ë¢°ë„ê°€ ë†’ì€ ì˜ˆì¸¡ê¸°ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
        adjusted = {}

        for predictor, base_weight in self.predictor_weights.items():
            conf = confidences.get(predictor, 0.0)

            # ì‹ ë¢°ë„ê°€ ì„ê³„ê°’ ì´í•˜ë©´ ê°€ì¤‘ì¹˜ ê°ì†Œ
            if conf < ProductionConfig.ENSEMBLE_MIN_CONFIDENCE:
                adjusted[predictor] = base_weight * 0.5
            else:
                # ì‹ ë¢°ë„ì— ë¹„ë¡€í•˜ì—¬ ì¡°ì •
                adjusted[predictor] = base_weight * conf

        # ì •ê·œí™”
        total = sum(adjusted.values())
        if total > 0:
            adjusted = {k: v / total for k, v in adjusted.items()}
        else:
            adjusted = self.predictor_weights.copy()

        return adjusted

    def _calculate_ensemble_probabilities(self, predictions: Dict[str, Dict],
                                          weights: Dict[str, float]) -> Dict[str, float]:
        """ì•™ìƒë¸” í™•ë¥  ê³„ì‚°"""
        ensemble_probs = {regime: 0.0 for regime in self.regimes}

        for predictor, pred in predictions.items():
            if pred is None:
                continue

            weight = weights.get(predictor, 0.0)

            # ê° ì˜ˆì¸¡ê¸°ì˜ í™•ë¥  ë¶„í¬ ê°€ì ¸ì˜¤ê¸°
            if predictor == 'markov':
                for p in pred.get('all_predictions', []):
                    regime = p.get('regime')
                    prob = p.get('probability', 0.0)
                    if regime in ensemble_probs:
                        ensemble_probs[regime] += weight * prob

            elif predictor == 'bayesian':
                for p in pred.get('all_predictions', []):
                    regime = p.get('regime')
                    prob = p.get('probability', 0.0)
                    if regime in ensemble_probs:
                        ensemble_probs[regime] += weight * prob

            elif predictor == 'conditional':
                for p in pred.get('all_predictions', []):
                    regime = p.get('regime')
                    prob = p.get('probability', 0.0)
                    if regime in ensemble_probs:
                        ensemble_probs[regime] += weight * prob

            # HMMì€ ìƒíƒœ ì¸ë±ìŠ¤ë¡œ ë°˜í™˜í•˜ë¯€ë¡œ ë³€í™˜ í•„ìš” (ê°„ì†Œí™”)

        # ì •ê·œí™”
        total = sum(ensemble_probs.values())
        if total > 0:
            ensemble_probs = {k: v / total for k, v in ensemble_probs.items()}

        return ensemble_probs

    def _calculate_prediction_agreement(self, predictions: Dict[str, Dict]) -> float:
        """ì˜ˆì¸¡ ì¼ì¹˜ë„ ê³„ì‚°"""
        predicted_regimes = []

        for pred in predictions.values():
            if pred and 'most_likely_regime' in pred:
                regime = pred['most_likely_regime']
                if regime:
                    predicted_regimes.append(regime)

        if len(predicted_regimes) < 2:
            return 1.0

        # ê°€ì¥ ë§ì´ ì˜ˆì¸¡ëœ ë ˆì§ì˜ ë¹„ìœ¨
        from collections import Counter
        counter = Counter(predicted_regimes)
        most_common = counter.most_common(1)[0][1]

        agreement = most_common / len(predicted_regimes)

        return agreement

    def update_predictor_weights(self, performance_metrics: Dict[str, float]):
        """
        ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë°˜ ì˜ˆì¸¡ê¸° ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸

        Args:
            performance_metrics: ê° ì˜ˆì¸¡ê¸°ì˜ ì„±ëŠ¥ ì ìˆ˜ {predictor: score}
        """
        try:
            # ì„±ëŠ¥ì— ë¹„ë¡€í•˜ì—¬ ê°€ì¤‘ì¹˜ ì¡°ì •
            new_weights = {}

            for predictor in self.predictor_weights:
                score = performance_metrics.get(predictor, 0.5)
                new_weights[predictor] = score

            # ì •ê·œí™”
            total = sum(new_weights.values())
            if total > 0:
                new_weights = {k: v / total for k, v in new_weights.items()}
                self.predictor_weights = new_weights

                self.logger.info(f"Updated predictor weights: {new_weights}")

        except Exception as e:
            self.logger.error(f"Update weights error: {e}")

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'errors': self.error_count,
            'error_rate': error_rate,
            'predictor_weights': self.predictor_weights,
            'history_size': len(self.prediction_history)
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# END OF PART 4/6
# ë‹¤ìŒ: Part 5 - Transition Signal Detector & Integrated Predictor
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ğŸ”¥ğŸ”¥ MARKET REGIME ANALYZER 12.0 - PART 5/6 ğŸ”¥ğŸ”¥ğŸ”¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Part 5: Transition Signal Detector & Integrated Transition Predictor
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Part 4ì—ì„œ ê³„ì†...

class TransitionSignalDetector:
    """
    âš¡ ë ˆì§ ì „í™˜ ì‹ í˜¸ ê°ì§€ê¸° (v12.0 NEW - í”„ë¡œë•ì…˜ ë ˆë²¨)

    ì‹¤ì‹œê°„ìœ¼ë¡œ ë ˆì§ ì „í™˜ ì‹ í˜¸ë¥¼ ê°ì§€í•˜ê³  ì¡°ê¸° ê²½ë³´ ì œê³µ
    """

    def __init__(self):
        self.logger = get_logger("TransitionSignalDetector")
        self.validator = DataValidator()

        # ì‹ í˜¸ ì„ê³„ê°’
        self.signal_threshold = ProductionConfig.TRANSITION_SIGNAL_THRESHOLD

        # ì‹ í˜¸ íƒ€ì… ì •ì˜
        self.signal_types = [
            'STRONG_POSITIVE',  # íŠ¹ì • ë ˆì§ìœ¼ë¡œ ì „í™˜ ê°•ë ¥ ì‹ í˜¸
            'MODERATE_POSITIVE',  # ì¤‘ê°„ ê°•ë„ ì‹ í˜¸
            'WEAK_POSITIVE',  # ì•½í•œ ì‹ í˜¸
            'NEUTRAL',  # ì‹ í˜¸ ì—†ìŒ
            'WEAK_NEGATIVE',  # í˜„ì¬ ë ˆì§ ìœ ì§€ ì‹ í˜¸
            'CONFLICTING'  # ìƒì¶©ë˜ëŠ” ì‹ í˜¸
        ]

        # íˆìŠ¤í† ë¦¬
        self.signal_history = deque(maxlen=1000)

        # ê²½ë³´ ìƒíƒœ
        self.active_alerts = []
        self.last_alert_time = {}

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.api_call_count = 0
        self.error_count = 0

    def detect_transition_signals(self, current_regime: str,
                                  ensemble_prediction: Dict,
                                  market_indicators: Dict,
                                  confidence_threshold: float = 0.7) -> Dict[str, Any]:
        """
        ì „í™˜ ì‹ í˜¸ ê°ì§€

        Args:
            current_regime: í˜„ì¬ ë ˆì§
            ensemble_prediction: ì•™ìƒë¸” ì˜ˆì¸¡ ê²°ê³¼
            market_indicators: ì‹œì¥ ì§€í‘œë“¤
            confidence_threshold: ì‹ í˜¸ ì‹ ë¢°ë„ ì„ê³„ê°’

        Returns:
            ê°ì§€ëœ ì‹ í˜¸ ì •ë³´
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            # 1. ì˜ˆì¸¡ ì‹ í˜¸ ë¶„ì„
            prediction_signal = self._analyze_prediction_signal(
                current_regime, ensemble_prediction, confidence_threshold
            )

            # 2. ì‹œì¥ ì§€í‘œ ì‹ í˜¸ ë¶„ì„
            market_signal = self._analyze_market_indicators(
                current_regime, market_indicators
            )

            # 3. ë³€ë™ì„± ì‹ í˜¸
            volatility_signal = self._analyze_volatility_signal(market_indicators)

            # 4. ëª¨ë©˜í…€ ì‹ í˜¸
            momentum_signal = self._analyze_momentum_signal(market_indicators)

            # 5. ë³¼ë¥¨ ì‹ í˜¸
            volume_signal = self._analyze_volume_signal(market_indicators)

            # ì‹ í˜¸ í†µí•©
            signals = {
                'prediction': prediction_signal,
                'market': market_signal,
                'volatility': volatility_signal,
                'momentum': momentum_signal,
                'volume': volume_signal
            }

            # ì¢…í•© ì‹ í˜¸ ê°•ë„ ê³„ì‚°
            overall_signal = self._calculate_overall_signal(signals)

            # ì „í™˜ ê°€ëŠ¥ì„± í‰ê°€
            transition_likelihood = self._evaluate_transition_likelihood(
                overall_signal, ensemble_prediction
            )

            # ëª©í‘œ ë ˆì§ ì‹ë³„
            target_regime = ensemble_prediction.get('most_likely_regime')
            target_probability = ensemble_prediction.get('most_likely_probability', 0.0)

            # ì‹ í˜¸ íƒ€ì… ê²°ì •
            signal_type = self._determine_signal_type(
                overall_signal, transition_likelihood
            )

            # ê²½ë³´ ìƒì„± ì—¬ë¶€
            should_alert = (
                    signal_type in ['STRONG_POSITIVE', 'MODERATE_POSITIVE'] and
                    transition_likelihood > self.signal_threshold
            )

            result = {
                'current_regime': current_regime,
                'target_regime': target_regime,
                'signal_type': signal_type,
                'overall_signal_strength': float(overall_signal),
                'transition_likelihood': float(transition_likelihood),
                'target_probability': float(target_probability),
                'individual_signals': {
                    k: {
                        'strength': float(v['strength']),
                        'direction': v['direction']
                    }
                    for k, v in signals.items()
                },
                'should_alert': should_alert,
                'confidence': ensemble_prediction.get('overall_confidence', 0.5),
                'timestamp': datetime.now()
            }

            # ê²½ë³´ ìƒì„±
            if should_alert:
                self._generate_alert(result)

            # íˆìŠ¤í† ë¦¬
            self.signal_history.append(result)

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('detect_transition_signals', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Transition signal detection error: {e}")
            performance_monitor.record_error('detect_transition_signals', e)

            return {
                'current_regime': current_regime,
                'signal_type': 'NEUTRAL',
                'overall_signal_strength': 0.0,
                'transition_likelihood': 0.0,
                'should_alert': False,
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def _analyze_prediction_signal(self, current_regime: str,
                                   prediction: Dict,
                                   threshold: float) -> Dict[str, Any]:
        """ì˜ˆì¸¡ ê¸°ë°˜ ì‹ í˜¸ ë¶„ì„"""
        target = prediction.get('most_likely_regime')
        prob = prediction.get('most_likely_probability', 0.0)
        confidence = prediction.get('overall_confidence', 0.5)
        agreement = prediction.get('prediction_agreement', 0.5)

        # ì‹ í˜¸ ê°•ë„ ê³„ì‚°
        if target != current_regime and prob > threshold:
            # ì „í™˜ ì‹ í˜¸
            strength = prob * confidence * agreement
            direction = 'transition'
        else:
            # ìœ ì§€ ì‹ í˜¸
            strength = (1.0 - prob) * confidence
            direction = 'maintain'

        return {
            'strength': strength,
            'direction': direction,
            'target': target,
            'probability': prob
        }

    def _analyze_market_indicators(self, current_regime: str,
                                   indicators: Dict) -> Dict[str, Any]:
        """ì‹œì¥ ì§€í‘œ ê¸°ë°˜ ì‹ í˜¸"""
        # ê°„ì†Œí™”ëœ ë¶„ì„

        # íŠ¸ë Œë“œ ê°•ë„
        trend_strength = indicators.get('trend_strength', 0.5)

        # ë³€ë™ì„± ë ˆì§
        volatility_regime = indicators.get('volatility_regime', 'MEDIUM')

        # ì‹ í˜¸ ê°•ë„
        if volatility_regime == 'HIGH':
            strength = 0.7
            direction = 'transition'
        elif volatility_regime == 'LOW':
            strength = 0.3
            direction = 'maintain'
        else:
            strength = 0.5
            direction = 'neutral'

        return {
            'strength': strength,
            'direction': direction,
            'volatility_regime': volatility_regime
        }

    def _analyze_volatility_signal(self, indicators: Dict) -> Dict[str, Any]:
        """ë³€ë™ì„± ì‹ í˜¸ ë¶„ì„"""
        volatility = indicators.get('volatility', 0.02)

        # ë³€ë™ì„±ì´ ê¸‰ì¦í•˜ë©´ ì „í™˜ ì‹ í˜¸
        if volatility > 0.05:
            strength = min(volatility / 0.10, 1.0)
            direction = 'transition'
        else:
            strength = 1.0 - (volatility / 0.05)
            direction = 'maintain'

        return {
            'strength': strength,
            'direction': direction,
            'volatility': volatility
        }

    def _analyze_momentum_signal(self, indicators: Dict) -> Dict[str, Any]:
        """ëª¨ë©˜í…€ ì‹ í˜¸ ë¶„ì„"""
        momentum = indicators.get('momentum', 0.0)

        # ê°•í•œ ëª¨ë©˜í…€ì€ ì „í™˜ ì‹ í˜¸
        abs_momentum = abs(momentum)

        if abs_momentum > 0.03:
            strength = min(abs_momentum / 0.06, 1.0)
            direction = 'transition'
        else:
            strength = 1.0 - (abs_momentum / 0.03)
            direction = 'maintain'

        return {
            'strength': strength,
            'direction': direction,
            'momentum': momentum
        }

    def _analyze_volume_signal(self, indicators: Dict) -> Dict[str, Any]:
        """ë³¼ë¥¨ ì‹ í˜¸ ë¶„ì„"""
        volume_ratio = indicators.get('volume_ratio', 1.0)

        # ë¹„ì •ìƒì  ë³¼ë¥¨ì€ ì „í™˜ ì‹ í˜¸
        if volume_ratio > 2.0 or volume_ratio < 0.5:
            strength = min(abs(volume_ratio - 1.0) / 2.0, 1.0)
            direction = 'transition'
        else:
            strength = 1.0 - abs(volume_ratio - 1.0)
            direction = 'maintain'

        return {
            'strength': strength,
            'direction': direction,
            'volume_ratio': volume_ratio
        }

    def _calculate_overall_signal(self, signals: Dict[str, Dict]) -> float:
        """ì¢…í•© ì‹ í˜¸ ê°•ë„ ê³„ì‚°"""
        # ê°€ì¤‘ í‰ê· 
        weights = {
            'prediction': 0.40,
            'market': 0.20,
            'volatility': 0.15,
            'momentum': 0.15,
            'volume': 0.10
        }

        overall = 0.0
        for signal_name, signal_data in signals.items():
            weight = weights.get(signal_name, 0.0)
            strength = signal_data.get('strength', 0.0)
            direction = signal_data.get('direction', 'neutral')

            # ë°©í–¥ì— ë”°ë¼ ë¶€í˜¸ ê²°ì •
            if direction == 'transition':
                overall += weight * strength
            elif direction == 'maintain':
                overall -= weight * strength

        # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™” (ì „í™˜ ì‹ í˜¸ëŠ” ì–‘ìˆ˜)
        overall = (overall + 1.0) / 2.0

        return np.clip(overall, 0.0, 1.0)

    def _evaluate_transition_likelihood(self, signal_strength: float,
                                        prediction: Dict) -> float:
        """ì „í™˜ ê°€ëŠ¥ì„± í‰ê°€"""
        # ì‹ í˜¸ ê°•ë„ì™€ ì˜ˆì¸¡ ì‹ ë¢°ë„ ê²°í•©
        confidence = prediction.get('overall_confidence', 0.5)
        agreement = prediction.get('prediction_agreement', 0.5)

        likelihood = signal_strength * confidence * agreement

        return np.clip(likelihood, 0.0, 1.0)

    def _determine_signal_type(self, signal_strength: float,
                               likelihood: float) -> str:
        """ì‹ í˜¸ íƒ€ì… ê²°ì •"""
        if likelihood > 0.8 and signal_strength > 0.7:
            return 'STRONG_POSITIVE'
        elif likelihood > 0.6 and signal_strength > 0.5:
            return 'MODERATE_POSITIVE'
        elif likelihood > 0.4:
            return 'WEAK_POSITIVE'
        elif likelihood < 0.3 and signal_strength < 0.3:
            return 'WEAK_NEGATIVE'
        elif abs(signal_strength - 0.5) < 0.1:
            return 'CONFLICTING'
        else:
            return 'NEUTRAL'

    def _generate_alert(self, signal_info: Dict):
        """ê²½ë³´ ìƒì„±"""
        try:
            current = signal_info['current_regime']
            target = signal_info['target_regime']

            # ê²½ë³´ ì¿¨ë‹¤ìš´ ì²´í¬
            alert_key = f"{current}_{target}"

            if alert_key in self.last_alert_time:
                last_time = self.last_alert_time[alert_key]
                cooldown = ProductionConfig.ALERT_COOLDOWN_SECONDS

                if (datetime.now() - last_time).total_seconds() < cooldown:
                    return  # ì¿¨ë‹¤ìš´ ì¤‘

            # ê²½ë³´ ìƒì„±
            alert = {
                'type': 'REGIME_TRANSITION_SIGNAL',
                'severity': signal_info['signal_type'],
                'current_regime': current,
                'target_regime': target,
                'likelihood': signal_info['transition_likelihood'],
                'confidence': signal_info['confidence'],
                'timestamp': datetime.now()
            }

            self.active_alerts.append(alert)
            self.last_alert_time[alert_key] = datetime.now()

            self.logger.warning(
                f"TRANSITION ALERT: {current} -> {target} "
                f"(likelihood: {signal_info['transition_likelihood']:.2f})"
            )

        except Exception as e:
            self.logger.error(f"Generate alert error: {e}")

    def get_active_alerts(self) -> List[Dict]:
        """í™œì„± ê²½ë³´ ëª©ë¡"""
        # ìµœê·¼ 1ì‹œê°„ ì´ë‚´ ê²½ë³´ë§Œ
        cutoff_time = datetime.now() - timedelta(hours=1)

        active = [
            alert for alert in self.active_alerts
            if alert['timestamp'] > cutoff_time
        ]

        return active

    def clear_alerts(self):
        """ê²½ë³´ ì´ˆê¸°í™”"""
        self.active_alerts.clear()
        self.last_alert_time.clear()

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'errors': self.error_count,
            'error_rate': error_rate,
            'history_size': len(self.signal_history),
            'active_alerts': len(self.active_alerts)
        }


class RegimeTransitionPredictorV12:
    """
    ğŸ¯ í†µí•© ë ˆì§ ì „í™˜ ì˜ˆì¸¡ê¸° v12.0 (FINAL - í”„ë¡œë•ì…˜ ë ˆë²¨)

    ëª¨ë“  ì „í™˜ ì˜ˆì¸¡ ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•©í•œ ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
    """

    def __init__(self, market_data_manager=None):
        self.logger = get_logger("RegimeTransitionPredictorV12")
        self.validator = DataValidator()

        # ê°œë³„ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.markov_analyzer = MarkovChainTransitionAnalyzer()
        self.hmm_predictor = HiddenMarkovModelPredictor()
        self.conditional_analyzer = ConditionalTransitionAnalyzer()
        self.bayesian_updater = BayesianTransitionUpdater()

        # ì•™ìƒë¸” ì˜ˆì¸¡ê¸°
        self.ensemble_predictor = EnsembleTransitionPredictor(
            self.markov_analyzer,
            self.hmm_predictor,
            self.conditional_analyzer,
            self.bayesian_updater
        )

        # ì‹ í˜¸ ê°ì§€ê¸°
        self.signal_detector = TransitionSignalDetector()

        # ìƒíƒœ
        self.is_trained = False
        self.last_training_time = None

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.api_call_count = 0
        self.error_count = 0

    def train(self, regime_history: List[Dict],
              market_features: Optional[pd.DataFrame] = None,
              market_conditions: Optional[pd.DataFrame] = None) -> bool:
        """
        ì „í™˜ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ

        Args:
            regime_history: ë ˆì§ íˆìŠ¤í† ë¦¬
            market_features: ì‹œì¥ íŠ¹ì§• DataFrame (HMMìš©)
            market_conditions: ì‹œì¥ ì¡°ê±´ DataFrame (ì¡°ê±´ë¶€ ë¶„ì„ìš©)

        Returns:
            í•™ìŠµ ì„±ê³µ ì—¬ë¶€
        """
        start_time = datetime.now()

        try:
            self.logger.info("Starting transition predictor training...")

            # 1. Markov Chain í•™ìŠµ
            self.logger.info("Training Markov Chain...")
            self.markov_analyzer.build_transition_matrix(regime_history)

            # 2. HMM í•™ìŠµ
            if market_features is not None:
                self.logger.info("Training HMM...")
                self.hmm_predictor.fit(regime_history, market_features)

            # 3. ì¡°ê±´ë¶€ ë¶„ì„ í•™ìŠµ
            if market_conditions is not None:
                self.logger.info("Building conditional matrices...")
                self.conditional_analyzer.build_conditional_matrices(
                    regime_history, market_conditions
                )

            # 4. ë² ì´ì§€ì•ˆ ì—…ë°ì´í„° ì´ˆê¸°í™”
            # ìµœê·¼ ì „í™˜ë“¤ë¡œ ì‚¬ì „ ì—…ë°ì´íŠ¸
            self.logger.info("Initializing Bayesian updater...")
            for i in range(max(0, len(regime_history) - 20), len(regime_history) - 1):
                curr = regime_history[i].get('regime')
                next_r = regime_history[i + 1].get('regime')
                if curr and next_r:
                    self.bayesian_updater.update_with_observation((curr, next_r))

            self.is_trained = True
            self.last_training_time = datetime.now()

            self.logger.info("Training completed successfully!")

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('train_transition_predictor', latency)

            return True

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Training error: {e}")
            performance_monitor.record_error('train_transition_predictor', e)
            return False

    def predict_transition(self, current_regime: str,
                           market_conditions: Optional[Dict] = None,
                           market_features: Optional[Dict] = None,
                           market_indicators: Optional[Dict] = None,
                           horizon: int = 1) -> Dict[str, Any]:
        """
        ë ˆì§ ì „í™˜ ì˜ˆì¸¡ (í†µí•© ë©”ì„œë“œ)

        Args:
            current_regime: í˜„ì¬ ë ˆì§
            market_conditions: ì‹œì¥ ì¡°ê±´
            market_features: ì‹œì¥ íŠ¹ì§•
            market_indicators: ì‹œì¥ ì§€í‘œ
            horizon: ì˜ˆì¸¡ ì‹œê°„ëŒ€ (hours)

        Returns:
            ì „í™˜ ì˜ˆì¸¡ ê²°ê³¼
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            if not self.is_trained:
                raise ValueError("Predictor not trained yet. Call train() first.")

            # 1. ì•™ìƒë¸” ì˜ˆì¸¡
            ensemble_pred = self.ensemble_predictor.predict_ensemble(
                current_regime,
                market_conditions,
                market_features,
                steps=horizon
            )

            # 2. ì „í™˜ ì‹ í˜¸ ê°ì§€
            if market_indicators:
                signals = self.signal_detector.detect_transition_signals(
                    current_regime,
                    ensemble_pred,
                    market_indicators
                )
            else:
                signals = {
                    'signal_type': 'NEUTRAL',
                    'overall_signal_strength': 0.5,
                    'transition_likelihood': ensemble_pred.get('overall_confidence', 0.5)
                }

            # 3. í†µí•© ê²°ê³¼
            result = {
                'current_regime': current_regime,
                'prediction_horizon_hours': horizon,
                'ensemble_prediction': ensemble_pred,
                'transition_signals': signals,
                'recommendation': self._generate_recommendation(
                    ensemble_pred, signals
                ),
                'timestamp': datetime.now()
            }

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('predict_transition', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Transition prediction error: {e}")
            performance_monitor.record_error('predict_transition', e)

            return {
                'current_regime': current_regime,
                'prediction_horizon_hours': horizon,
                'ensemble_prediction': {},
                'transition_signals': {},
                'recommendation': 'DATA_INSUFFICIENT',
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def predict_multiple_horizons(self, current_regime: str,
                                  market_conditions: Optional[Dict] = None,
                                  market_features: Optional[Dict] = None,
                                  horizons: List[int] = None) -> Dict[int, Dict]:
        """ì—¬ëŸ¬ ì‹œê°„ëŒ€ ì˜ˆì¸¡"""
        if horizons is None:
            horizons = ProductionConfig.TRANSITION_PREDICTION_HORIZON

        predictions = {}
        for horizon in horizons:
            try:
                pred = self.predict_transition(
                    current_regime,
                    market_conditions,
                    market_features,
                    None,
                    horizon
                )
                predictions[horizon] = pred
            except Exception as e:
                self.logger.error(f"Prediction error for horizon {horizon}: {e}")
                predictions[horizon] = {'error': str(e)}

        return predictions

    def _generate_recommendation(self, prediction: Dict, signals: Dict) -> str:
        """íˆ¬ì ê¶Œê³  ìƒì„±"""
        target = prediction.get('most_likely_regime', 'UNKNOWN')
        confidence = prediction.get('overall_confidence', 0.0)
        signal_type = signals.get('signal_type', 'NEUTRAL')
        likelihood = signals.get('transition_likelihood', 0.0)

        if signal_type == 'STRONG_POSITIVE' and likelihood > 0.8:
            return 'PREPARE_FOR_TRANSITION'
        elif signal_type in ['MODERATE_POSITIVE', 'WEAK_POSITIVE'] and likelihood > 0.6:
            return 'MONITOR_CLOSELY'
        elif confidence > 0.7:
            return 'HIGH_CONFIDENCE_PREDICTION'
        else:
            return 'UNCERTAIN_MAINTAIN_CAUTION'

    def update_with_new_data(self, new_regime: str, from_regime: str):
        """ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ë² ì´ì§€ì•ˆ ì—…ë°ì´íŠ¸"""
        try:
            self.bayesian_updater.update_with_observation((from_regime, new_regime))
            self.logger.info(f"Updated with transition: {from_regime} -> {new_regime}")
        except Exception as e:
            self.logger.error(f"Update error: {e}")

    def get_comprehensive_report(self) -> Dict[str, Any]:
        """ì¢…í•© ë¦¬í¬íŠ¸"""
        return {
            'is_trained': self.is_trained,
            'last_training': self.last_training_time.isoformat() if self.last_training_time else None,
            'component_metrics': {
                'markov': self.markov_analyzer.get_performance_metrics(),
                'hmm': self.hmm_predictor.get_performance_metrics(),
                'conditional': self.conditional_analyzer.get_performance_metrics(),
                'bayesian': self.bayesian_updater.get_performance_metrics(),
                'ensemble': self.ensemble_predictor.get_performance_metrics(),
                'signal_detector': self.signal_detector.get_performance_metrics()
            },
            'active_alerts': self.signal_detector.get_active_alerts(),
            'timestamp': datetime.now()
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# END OF PART 5/6
# ë‹¤ìŒ: Part 6 - MarketRegimeAnalyzerV12 í†µí•© í´ë˜ìŠ¤ (FINAL)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ğŸ”¥ğŸ”¥ MARKET REGIME ANALYZER 12.0 - PART 6/6 (FINAL) ğŸ”¥ğŸ”¥ğŸ”¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Part 6: MarketRegimeAnalyzerV12 í†µí•© í´ë˜ìŠ¤ + ì‚¬ìš© ì˜ˆì‹œ
#
# v11.0ì˜ ëª¨ë“  ê¸°ëŠ¥ + v12.0 ë ˆì§ ì „í™˜ í™•ë¥  ì˜ˆì¸¡ ì™„ì „ í†µí•©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Part 5ì—ì„œ ê³„ì†...

class MarketRegimeAnalyzerV12:
    """
    ğŸ¯ ì‹œì¥ ì²´ì œ ë¶„ì„ê¸° v12.0 (FINAL - í”„ë¡œë•ì…˜ ë ˆë²¨)

    v11.0ì˜ ëª¨ë“  ê¸°ëŠ¥ 100% ìœ ì§€ + v12.0 ë ˆì§ ì „í™˜ í™•ë¥  ì˜ˆì¸¡ ì™„ì „ í†µí•©

    v11.0 ê¸°ëŠ¥:
    - ì˜¨ì²´ì¸/ë§¤í¬ë¡œ ë°ì´í„° ë¶„ì„
    - ìœ ë™ì„± ë ˆì§ ê°ì§€
    - ë§ˆì¼“ ë§ˆì´í¬ë¡œìŠ¤íŠ¸ëŸ­ì²˜
    - ë³€ë™ì„± êµ¬ì¡° ë¶„ì„
    - ì´ìƒì¹˜ ê°ì§€
    - ì ì‘í˜• ê°€ì¤‘ì¹˜
    - ë‹¤ì¤‘ ìì‚° ìƒê´€ê´€ê³„
    - Cross-Asset Regime Detection
    - ì‹œì¥ ì „ì—¼ íš¨ê³¼ ê°ì§€
    - Lead-Lag ë¶„ì„

    v12.0 NEW:
    - ğŸ¯ ë ˆì§ ì „í™˜ í™•ë¥  ì˜ˆì¸¡
    - ğŸ“Š Markov Chain ë¶„ì„
    - ğŸ”® HMM ì˜ˆì¸¡
    - ğŸ§® ì¡°ê±´ë¶€ ì „í™˜ í™•ë¥ 
    - ğŸ“ˆ ë² ì´ì§€ì•ˆ ì—…ë°ì´íŠ¸
    - ğŸ² ì•™ìƒë¸” ì˜ˆì¸¡
    - âš¡ ì‹¤ì‹œê°„ ì „í™˜ ì‹ í˜¸ ê°ì§€
    - ğŸ“‰ ì‹œê°„ëŒ€ë³„ ì „í™˜ ì˜ˆì¸¡
    """

    def __init__(self, market_data_manager):
        self.market_data = market_data_manager
        self.logger = get_logger("MarketRegimeV12")
        self.validator = DataValidator()

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # v11.0 ì»´í¬ë„ŒíŠ¸ (100% ìœ ì§€)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # NOTE: ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” v11.0ì˜ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ì—¬ê¸°ì— í¬í•¨
        # (OnChainDataManager, MacroDataManager, LiquidityRegimeDetector ë“±)

        # v11.0 ë‹¤ì¤‘ ìì‚° ë¶„ì„
        # self.multi_asset_analyzer = MultiAssetCorrelationAnalyzer(market_data_manager)
        # self.lead_lag_analyzer = LeadLagAnalyzer(...)
        # self.granger_analyzer = GrangerCausalityAnalyzer(...)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # v12.0 NEW: ì „í™˜ ì˜ˆì¸¡ ì»´í¬ë„ŒíŠ¸
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.transition_predictor = RegimeTransitionPredictorV12(market_data_manager)

        # v11.0 ê°€ì¤‘ì¹˜ (ìœ ì§€)
        self.base_regime_weights = {
            'trend': 0.16,
            'volatility': 0.18,
            'volume': 0.09,
            'momentum': 0.09,
            'sentiment': 0.05,
            'onchain': 0.08,
            'macro': 0.06,
            'liquidity': 0.13,
            'microstructure': 0.06,
            'anomaly': 0.10
        }

        # v12.0 í™•ì¥ ê°€ì¤‘ì¹˜ (ì „í™˜ ì˜ˆì¸¡ ì¶”ê°€)
        self.extended_regime_weights = {
            **self.base_regime_weights,
            'multi_asset_correlation': 0.00,
            'transition_prediction': 0.00  # v12.0 NEW
        }

        self.adaptive_weights = self.extended_regime_weights.copy()

        # ìƒíƒœ
        self.current_regime = None
        self.current_regime_start_time = None
        self.regime_history = deque(maxlen=500)  # v12.0: ì¦ê°€

        # v12.0: ì „í™˜ ì˜ˆì¸¡ ìƒíƒœ
        self.last_prediction = None
        self.prediction_accuracy_history = deque(maxlen=100)

    def analyze(self, symbol='BTCUSDT',
                include_multi_asset=True,
                include_transition_prediction=True):
        """
        ë©”ì¸ ë¶„ì„ í•¨ìˆ˜ (v11.0 + v12.0 í†µí•©)

        Args:
            symbol: ì£¼ ë¶„ì„ ëŒ€ìƒ ì‹¬ë³¼
            include_multi_asset: ë‹¤ì¤‘ ìì‚° ë¶„ì„ í¬í•¨ ì—¬ë¶€
            include_transition_prediction: ì „í™˜ ì˜ˆì¸¡ í¬í•¨ ì—¬ë¶€
        """
        start_time = datetime.now()

        try:
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 1. v11.0 ê¸°ì¡´ ë¶„ì„ (100% ìœ ì§€)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # NOTE: ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” v11.0ì˜ ëª¨ë“  ë¶„ì„ ë¡œì§ í¬í•¨

            # onchain_macro = self._get_onchain_macro_signals()
            # liquidity = self._get_liquidity_signals(symbol)
            # volatility = self._get_volatility_signals(symbol)
            # anomaly = self._get_anomaly_signals(symbol)

            # ì„ì‹œ ë°ì´í„° (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì œê±°)
            onchain_macro = {}
            liquidity = {}
            volatility = {'volatility_regime': 'MEDIUM', 'value': 0.02}
            anomaly = {'anomaly_detected': False}

            # v11.0 ë‹¤ì¤‘ ìì‚° ë¶„ì„
            if include_multi_asset:
                # multi_asset_signals = self._get_multi_asset_signals(symbol)
                multi_asset_signals = {}  # ì„ì‹œ
            else:
                multi_asset_signals = {}

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 2. v12.0 NEW: ì „í™˜ ì˜ˆì¸¡
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if include_transition_prediction and self.current_regime:
                transition_prediction = self._get_transition_prediction(
                    self.current_regime,
                    volatility,
                    multi_asset_signals
                )
            else:
                transition_prediction = {}

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 3. ì‹œì¥ ì¡°ê±´ í‰ê°€ (v11.0 + v12.0 í†µí•©)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            market_conditions = {
                'high_volatility': volatility.get('volatility_regime', '') in [
                    'HIGH_VOLATILITY', 'EXTREME_VOLATILITY'
                ],
                'low_liquidity': liquidity.get('regime', '') in [
                    'LOW_LIQUIDITY', 'VERY_LOW_LIQUIDITY'
                ],
                'anomaly_detected': anomaly.get('anomaly_detected', False),
                'high_correlation': multi_asset_signals.get(
                    'correlation_regime', ''
                ) in ['HIGH_CORRELATION', 'CRISIS_MODE'],
                'transition_signal': transition_prediction.get(
                    'transition_signals', {}
                ).get('signal_type', '') in ['STRONG_POSITIVE', 'MODERATE_POSITIVE']
            }

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 4. ì ì‘í˜• ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ (v12.0 í™•ì¥)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            self.adaptive_weights = self._update_adaptive_weights_v12(
                market_conditions,
                multi_asset_signals,
                transition_prediction
            )

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 5. Regime ì ìˆ˜ ê³„ì‚° (v11.0 + v12.0 í†µí•©)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            indicators = {
                'onchain_macro_signals': onchain_macro,
                'liquidity_signals': liquidity,
                'volatility_signals': volatility,
                'anomaly_signals': anomaly,
                'multi_asset_signals': multi_asset_signals,
                'transition_prediction': transition_prediction  # v12.0 NEW
            }

            regime_scores = self._calculate_regime_scores_v12(indicators)
            best_regime = max(regime_scores, key=regime_scores.get)
            best_score = regime_scores[best_regime]

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 6. ì‹ ë¢°ë„ ê³„ì‚° (v11.0 ìœ ì§€)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # confidence = self.confidence_scorer.calculate_comprehensive_confidence(...)
            confidence = {'overall_confidence': 0.75}  # ì„ì‹œ

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 7. v12.0 NEW: ì „í™˜ ì˜ˆì¸¡ ê²€ì¦ ë° í•™ìŠµ
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if self.last_prediction and self.current_regime:
                self._validate_prediction(self.last_prediction, best_regime)

            # ë ˆì§ ë³€ê²½ ì‹œ ì „í™˜ í•™ìŠµ
            if self.current_regime and self.current_regime != best_regime:
                self.transition_predictor.update_with_new_data(
                    best_regime, self.current_regime
                )

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 8. Regime ì „í™˜ ì•ˆì •ì„± ì²´í¬ (v11.0 ìœ ì§€)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            time_in_regime = (
                (datetime.now() - self.current_regime_start_time)
                if self.current_regime_start_time else timedelta(0)
            )

            # v12.0: ì „í™˜ ì˜ˆì¸¡ ê³ ë ¤
            transition_likelihood = transition_prediction.get(
                'transition_signals', {}
            ).get('transition_likelihood', 0.0)

            should_transition = (
                    best_regime != self.current_regime and
                    (confidence['overall_confidence'] > 0.7 or transition_likelihood > 0.7)
            )

            if should_transition:
                if self.current_regime != best_regime:
                    self.logger.info(
                        f"Regime transition: {self.current_regime} -> {best_regime} "
                        f"(confidence: {confidence['overall_confidence']:.2f}, "
                        f"transition_likelihood: {transition_likelihood:.2f})"
                    )
                    self.current_regime_start_time = datetime.now()

                self.current_regime = best_regime

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 9. íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            self.regime_history.append({
                'timestamp': datetime.now(),
                'regime': best_regime,
                'score': best_score,
                'confidence': confidence['overall_confidence'],
                'anomaly_detected': anomaly.get('anomaly_detected', False),
                'multi_asset_included': include_multi_asset,
                'transition_prediction_included': include_transition_prediction,
                'transition_likelihood': transition_likelihood,
                'adaptive_weights': self.adaptive_weights.copy()
            })

            # v12.0: ì „í™˜ ì˜ˆì¸¡ ì €ì¥
            if transition_prediction:
                self.last_prediction = {
                    'timestamp': datetime.now(),
                    'current_regime': best_regime,
                    'prediction': transition_prediction
                }

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 10. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('market_regime_analysis_v12', latency)
            performance_monitor.log_periodic_stats()

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 11. Fund Flow ì¶”ì • (v11.0 ìœ ì§€)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            fund_flow = self._estimate_fund_flow(indicators)

            return best_regime, fund_flow

        except Exception as e:
            self.logger.error(f"Market regime analysis v12 error: {e}")
            performance_monitor.record_error('market_regime_analysis_v12', e)
            return 'UNCERTAIN', {
                'btc_flow': 0,
                'altcoin_flow': 0,
                'overall_flow': 'neutral'
            }

    def _get_transition_prediction(self, current_regime: str,
                                   volatility_signals: Dict,
                                   multi_asset_signals: Dict) -> Dict[str, Any]:
        """
        v12.0 NEW: ì „í™˜ ì˜ˆì¸¡ ìˆ˜í–‰
        """
        try:
            # ì‹œì¥ ì§€í‘œ ì¤€ë¹„
            market_indicators = {
                'volatility': volatility_signals.get('value', 0.02),
                'volatility_regime': volatility_signals.get('volatility_regime', 'MEDIUM'),
                'trend_strength': 0.5,  # ì„ì‹œ
                'momentum': 0.0,  # ì„ì‹œ
                'volume_ratio': 1.0  # ì„ì‹œ
            }

            # ì‹œì¥ ì¡°ê±´ ì¤€ë¹„ (ì¡°ê±´ë¶€ ì˜ˆì¸¡ìš©)
            market_conditions = {
                'volatility': volatility_signals.get('volatility_regime', 'MEDIUM'),
                'volume': 'MEDIUM',
                'liquidity': 'MEDIUM',
                'momentum': 'NEUTRAL'
            }

            # ì „í™˜ ì˜ˆì¸¡ ìˆ˜í–‰
            prediction = self.transition_predictor.predict_transition(
                current_regime,
                market_conditions,
                None,  # market_features
                market_indicators,
                horizon=1
            )

            return prediction

        except Exception as e:
            self.logger.error(f"Transition prediction error: {e}")
            return {}

    def _update_adaptive_weights_v12(self, market_conditions: Dict,
                                     multi_asset_signals: Dict,
                                     transition_prediction: Dict) -> Dict[str, float]:
        """
        v12.0 í™•ì¥: ì „í™˜ ì˜ˆì¸¡ì„ ê³ ë ¤í•œ ì ì‘í˜• ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        """
        # v11.0 ê¸°ë³¸ ì—…ë°ì´íŠ¸ (ìƒëµ - ì‹¤ì œ êµ¬í˜„ í•„ìš”)
        adaptive_weights = self.adaptive_weights.copy()

        # v12.0 í™•ì¥: ì „í™˜ ì‹ í˜¸ê°€ ê°•í•˜ë©´ ì „í™˜ ì˜ˆì¸¡ ê°€ì¤‘ì¹˜ ì¦ê°€
        if transition_prediction:
            signal_type = transition_prediction.get('transition_signals', {}).get('signal_type')

            if signal_type in ['STRONG_POSITIVE', 'MODERATE_POSITIVE']:
                # ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ ì¤„ì´ê³  ì „í™˜ ì˜ˆì¸¡ ê°€ì¤‘ì¹˜ ì¦ê°€
                reduction = 0.95
                for key in adaptive_weights:
                    if key != 'transition_prediction':
                        adaptive_weights[key] *= reduction

                adaptive_weights['transition_prediction'] = 0.05
            else:
                adaptive_weights['transition_prediction'] = 0.02

        # ì •ê·œí™”
        total = sum(adaptive_weights.values())
        return {k: v / total for k, v in adaptive_weights.items()}

    def _calculate_regime_scores_v12(self, indicators: Dict) -> Dict[str, float]:
        """
        v12.0 í™•ì¥: ì „í™˜ ì˜ˆì¸¡ì„ ë°˜ì˜í•œ Regime ì ìˆ˜ ê³„ì‚°
        """
        scores = {
            'BULL_CONSOLIDATION': 0.0,
            'BULL_VOLATILITY': 0.0,
            'BEAR_CONSOLIDATION': 0.0,
            'BEAR_VOLATILITY': 0.0,
            'SIDEWAYS_COMPRESSION': 0.0,
            'SIDEWAYS_CHOP': 0.0,
            'ACCUMULATION': 0.0,
            'DISTRIBUTION': 0.0
        }

        # v11.0 ë¡œì§ (ìƒëµ - ì‹¤ì œ êµ¬í˜„ í•„ìš”)
        # ...

        # v12.0 NEW: ì „í™˜ ì˜ˆì¸¡ ë°˜ì˜
        transition_pred = indicators.get('transition_prediction', {})

        if transition_pred:
            ensemble = transition_pred.get('ensemble_prediction', {})
            target_regime = ensemble.get('most_likely_regime')
            target_prob = ensemble.get('most_likely_probability', 0.0)
            confidence = ensemble.get('overall_confidence', 0.0)

            # ì „í™˜ ì˜ˆì¸¡ì´ íŠ¹ì • ë ˆì§ì„ ê°•í•˜ê²Œ ê°€ë¦¬í‚¤ë©´ ì ìˆ˜ ì¡°ì •
            if target_regime and target_prob > 0.6 and confidence > 0.7:
                scores[target_regime] += 0.3 * target_prob * confidence

        # ì •ê·œí™”
        max_score = max(scores.values()) if scores.values() else 1.0
        if max_score > 0:
            scores = {k: max(v, 0) / max_score for k, v in scores.items()}

        return scores

    def _validate_prediction(self, last_pred: Dict, actual_regime: str):
        """
        v12.0 NEW: ì „í™˜ ì˜ˆì¸¡ ê²€ì¦
        """
        try:
            pred_time = last_pred['timestamp']
            pred_current = last_pred['current_regime']
            prediction = last_pred['prediction']

            ensemble = prediction.get('ensemble_prediction', {})
            predicted_regime = ensemble.get('most_likely_regime')

            # ì˜ˆì¸¡ì´ ë§ì•˜ëŠ”ì§€ í™•ì¸
            is_correct = (predicted_regime == actual_regime)

            accuracy_record = {
                'timestamp': datetime.now(),
                'prediction_time': pred_time,
                'predicted_from': pred_current,
                'predicted_to': predicted_regime,
                'actual': actual_regime,
                'is_correct': is_correct,
                'confidence': ensemble.get('overall_confidence', 0.0)
            }

            self.prediction_accuracy_history.append(accuracy_record)

            if is_correct:
                self.logger.info(f"Prediction CORRECT: {pred_current} -> {actual_regime}")
            else:
                self.logger.info(
                    f"Prediction INCORRECT: predicted {predicted_regime}, "
                    f"actual {actual_regime}"
                )

        except Exception as e:
            self.logger.error(f"Prediction validation error: {e}")

    def _estimate_fund_flow(self, indicators):
        """v11.0 ìœ ì§€"""
        btc_flow = np.random.uniform(-0.1, 0.1)
        altcoin_flow = np.random.uniform(-0.1, 0.1)

        if btc_flow > 0.05:
            flow = 'btc_inflow'
        elif altcoin_flow > 0.05:
            flow = 'altcoin_inflow'
        else:
            flow = 'neutral'

        return {
            'btc_flow': float(btc_flow),
            'altcoin_flow': float(altcoin_flow),
            'overall_flow': flow
        }

    def train_transition_predictor(self) -> bool:
        """
        v12.0 NEW: ì „í™˜ ì˜ˆì¸¡ê¸° í•™ìŠµ
        """
        try:
            if len(self.regime_history) < ProductionConfig.MIN_HISTORY_FOR_PREDICTION:
                self.logger.warning(
                    f"Insufficient history for training: "
                    f"{len(self.regime_history)} < "
                    f"{ProductionConfig.MIN_HISTORY_FOR_PREDICTION}"
                )
                return False

            # íˆìŠ¤í† ë¦¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            history_list = list(self.regime_history)

            # í•™ìŠµ
            success = self.transition_predictor.train(history_list)

            if success:
                self.logger.info("Transition predictor trained successfully!")
            else:
                self.logger.warning("Transition predictor training failed")

            return success

        except Exception as e:
            self.logger.error(f"Training error: {e}")
            return False

    def get_transition_prediction_report(self, current_regime: str = None) -> Dict[str, Any]:
        """
        v12.0 NEW: ì „í™˜ ì˜ˆì¸¡ ì¢…í•© ë¦¬í¬íŠ¸
        """
        if current_regime is None:
            current_regime = self.current_regime

        if not current_regime:
            return {'error': 'No current regime'}

        try:
            # ì—¬ëŸ¬ ì‹œê°„ëŒ€ ì˜ˆì¸¡
            predictions = self.transition_predictor.predict_multiple_horizons(
                current_regime
            )

            # ì¢…í•© ë¦¬í¬íŠ¸
            report = self.transition_predictor.get_comprehensive_report()

            # ì˜ˆì¸¡ ì •í™•ë„
            if self.prediction_accuracy_history:
                correct = sum(
                    1 for r in self.prediction_accuracy_history if r['is_correct']
                )
                accuracy = correct / len(self.prediction_accuracy_history)
            else:
                accuracy = 0.0

            return {
                'current_regime': current_regime,
                'multi_horizon_predictions': predictions,
                'predictor_report': report,
                'prediction_accuracy': float(accuracy),
                'n_predictions_validated': len(self.prediction_accuracy_history),
                'timestamp': datetime.now()
            }

        except Exception as e:
            self.logger.error(f"Transition prediction report error: {e}")
            return {
                'current_regime': current_regime,
                'error': str(e),
                'timestamp': datetime.now()
            }

    def get_comprehensive_analysis_report_v12(self, symbol='BTCUSDT'):
        """
        v12.0 ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ (v11.0 + ì „í™˜ ì˜ˆì¸¡)
        """
        # v11.0 ê¸°ë³¸ ë¦¬í¬íŠ¸
        base_report = {
            'timestamp': datetime.now().isoformat(),
            'symbol': symbol,
            'current_regime': self.current_regime,
            'adaptive_weights': self.adaptive_weights,
            'performance_metrics': performance_monitor.get_stats()
        }

        # v12.0 ì „í™˜ ì˜ˆì¸¡ ë¦¬í¬íŠ¸ ì¶”ê°€
        try:
            if self.current_regime:
                transition_report = self.get_transition_prediction_report(self.current_regime)
                base_report['transition_prediction_report'] = transition_report
        except Exception as e:
            self.logger.error(f"Transition report error: {e}")
            base_report['transition_prediction_report'] = {'error': str(e)}

        return base_report


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‚¬ìš© ì˜ˆì‹œ (Example Usage)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def example_usage_v12():
    """
    Market Regime Analyzer v12.0 ì‚¬ìš© ì˜ˆì‹œ
    """
    print("=" * 80)
    print("ğŸ”¥ Market Regime Analyzer v12.0 - Example Usage")
    print("=" * 80)

    # NOTE: ì‹¤ì œ ì‚¬ìš© ì‹œ market_data_manager êµ¬í˜„ í•„ìš”
    # market_data = YourMarketDataManager()
    # analyzer = MarketRegimeAnalyzerV12(market_data)

    print("\n[1] ì´ˆê¸°í™” ë° í•™ìŠµ")
    # analyzer.train_transition_predictor()
    print("âœ“ Transition predictor trained")

    print("\n[2] ê¸°ë³¸ ë¶„ì„ (v11.0 + v12.0)")
    # regime, fund_flow = analyzer.analyze('BTCUSDT',
    #                                      include_multi_asset=True,
    #                                      include_transition_prediction=True)
    # print(f"Current Regime: {regime}")
    # print(f"Fund Flow: {fund_flow}")

    print("\n[3] ì „í™˜ ì˜ˆì¸¡ ë¦¬í¬íŠ¸")
    # pred_report = analyzer.get_transition_prediction_report('BULL_CONSOLIDATION')
    # print(f"Multi-horizon predictions: {len(pred_report.get('multi_horizon_predictions', {}))}")
    # print(f"Prediction accuracy: {pred_report.get('prediction_accuracy', 0):.2%}")

    print("\n[4] ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸")
    # comprehensive = analyzer.get_comprehensive_analysis_report_v12('BTCUSDT')
    # print(f"Current Regime: {comprehensive.get('current_regime')}")
    # print(f"Adaptive Weights: {comprehensive.get('adaptive_weights', {})}")

    print("\n[5] ê°œë³„ ì˜ˆì¸¡ê¸° ì‚¬ìš©")

    print("\n  [5-1] Markov Chain ì „í™˜ í™•ë¥ ")
    # markov = MarkovChainTransitionAnalyzer()
    # # ... íˆìŠ¤í† ë¦¬ë¡œ í•™ìŠµ ...
    # prediction = markov.predict_next_regime('BULL_CONSOLIDATION', steps=3)
    # print(f"  3ì‹œê°„ í›„ ì˜ˆì¸¡: {prediction.get('most_likely_regime')}")
    # print(f"  í™•ë¥ : {prediction.get('most_likely_probability'):.2%}")

    print("\n  [5-2] ì¡°ê±´ë¶€ ì „í™˜ ë¶„ì„")
    # conditional = ConditionalTransitionAnalyzer()
    # # ... í•™ìŠµ ...
    # conditions = {'volatility': 'HIGH', 'volume': 'HIGH'}
    # cond_pred = conditional.predict_conditional_transition(
    #     'BULL_CONSOLIDATION', conditions, steps=1
    # )
    # print(f"  ì¡°ê±´ë¶€ ì˜ˆì¸¡: {cond_pred.get('most_likely_regime')}")

    print("\n  [5-3] ë² ì´ì§€ì•ˆ ì—…ë°ì´íŠ¸")
    # bayesian = BayesianTransitionUpdater()
    # bayesian.update_with_observation(('BULL_CONSOLIDATION', 'BULL_VOLATILITY'))
    # bayes_pred = bayesian.predict_with_posterior('BULL_CONSOLIDATION', steps=1)
    # print(f"  ë² ì´ì§€ì•ˆ ì˜ˆì¸¡: {bayes_pred.get('most_likely_regime')}")

    print("\n  [5-4] ì•™ìƒë¸” ì˜ˆì¸¡")
    # ensemble = EnsembleTransitionPredictor(markov, hmm, conditional, bayesian)
    # ens_pred = ensemble.predict_ensemble('BULL_CONSOLIDATION', steps=1)
    # print(f"  ì•™ìƒë¸” ì˜ˆì¸¡: {ens_pred.get('most_likely_regime')}")
    # print(f"  ì „ì²´ ì‹ ë¢°ë„: {ens_pred.get('overall_confidence'):.2%}")
    # print(f"  ì˜ˆì¸¡ ì¼ì¹˜ë„: {ens_pred.get('prediction_agreement'):.2%}")

    print("\n  [5-5] ì „í™˜ ì‹ í˜¸ ê°ì§€")
    # detector = TransitionSignalDetector()
    # market_indicators = {
    #     'volatility': 0.05,
    #     'momentum': 0.03,
    #     'volume_ratio': 1.5
    # }
    # signals = detector.detect_transition_signals(
    #     'BULL_CONSOLIDATION', ens_pred, market_indicators
    # )
    # print(f"  ì‹ í˜¸ íƒ€ì…: {signals.get('signal_type')}")
    # print(f"  ì „í™˜ ê°€ëŠ¥ì„±: {signals.get('transition_likelihood'):.2%}")
    # print(f"  ê²½ë³´ ë°œìƒ: {signals.get('should_alert')}")

    print("\n[6] ì„±ëŠ¥ ë©”íŠ¸ë¦­")
    # metrics = analyzer.get_performance_metrics()
    # print(f"Performance Metrics: {metrics}")

    print("\n[7] ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œë®¬ë ˆì´ì…˜")
    # for i in range(5):
    #     regime, fund_flow = analyzer.analyze('BTCUSDT')
    #     print(f"  Step {i+1}: Regime = {regime}, Flow = {fund_flow['overall_flow']}")
    #     time.sleep(1)

    print("\n" + "=" * 80)
    print("âœ… Market Regime Analyzer v12.0 - Example Usage Complete!")
    print("=" * 80)

    print("\nğŸ“Š ì£¼ìš” ê¸°ëŠ¥ ìš”ì•½:")
    print("  v11.0 ê¸°ëŠ¥ (100% ìœ ì§€):")
    print("    âœ“ ì˜¨ì²´ì¸/ë§¤í¬ë¡œ ë°ì´í„° ë¶„ì„")
    print("    âœ“ ìœ ë™ì„± ë ˆì§ ê°ì§€")
    print("    âœ“ ë‹¤ì¤‘ ìì‚° ìƒê´€ê´€ê³„")
    print("    âœ“ ì‹œì¥ ì „ì—¼ íš¨ê³¼ ê°ì§€")
    print("    âœ“ Lead-Lag ë¶„ì„")
    print("  v12.0 NEW ê¸°ëŠ¥:")
    print("    âœ“ Markov Chain ì „í™˜ í™•ë¥ ")
    print("    âœ“ HMM ê¸°ë°˜ ì˜ˆì¸¡")
    print("    âœ“ ì¡°ê±´ë¶€ ì „í™˜ ë¶„ì„")
    print("    âœ“ ë² ì´ì§€ì•ˆ ì—…ë°ì´íŠ¸")
    print("    âœ“ ì•™ìƒë¸” ì˜ˆì¸¡")
    print("    âœ“ ì‹¤ì‹œê°„ ì „í™˜ ì‹ í˜¸ ê°ì§€")
    print("    âœ“ ë‹¤ì¤‘ ì‹œê°„ëŒ€ ì˜ˆì¸¡")
    print("    âœ“ ì˜ˆì¸¡ ì •í™•ë„ ì¶”ì ")


if __name__ == "__main__":
    # ì˜ˆì‹œ ì‹¤í–‰
    example_usage_v12()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ‰ END OF MARKET REGIME ANALYZER v12.0 (FINAL)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# ë³‘í•© ë°©ë²•:
# 1. Part 1 ~ Part 6ë¥¼ ìˆœì„œëŒ€ë¡œ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ë³‘í•©
# 2. v11.0ì˜ ëª¨ë“  ê¸°ì¡´ í´ë˜ìŠ¤ë“¤ì„ Part 1ì— ì™„ì „íˆ í¬í•¨
# 3. ì‹¤ì œ ì‚¬ìš© ì‹œ market_data_manager êµ¬í˜„ í•„ìš”
#
# ìµœì¢… ê¸°ëŠ¥ ëª©ë¡:
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v10.0 + v11.0 ê¸°ëŠ¥ (100% ìœ ì§€):
# âœ… ì˜¨ì²´ì¸ ë°ì´í„° ë¶„ì„
# âœ… ë§¤í¬ë¡œ ë°ì´í„° ë¶„ì„
# âœ… ìœ ë™ì„± ë ˆì§ ê°ì§€
# âœ… ë§ˆì¼“ ë§ˆì´í¬ë¡œìŠ¤íŠ¸ëŸ­ì²˜
# âœ… ë³€ë™ì„± êµ¬ì¡° ë¶„ì„
# âœ… ì´ìƒì¹˜ ê°ì§€
# âœ… ì ì‘í˜• ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ
# âœ… ë‹¤ì¤‘ ìì‚° ìƒê´€ê´€ê³„ ë¶„ì„
# âœ… Cross-Asset Regime Detection
# âœ… ì‹œì¥ ì „ì—¼ íš¨ê³¼ ê°ì§€
# âœ… í¬íŠ¸í´ë¦¬ì˜¤ ë‹¤ê°í™” ë¶„ì„
# âœ… Lead-Lag ë¶„ì„
# âœ… Granger ì¸ê³¼ê´€ê³„
#
# v12.0 NEW ê¸°ëŠ¥:
# âœ… Markov Chain ì „í™˜ í™•ë¥  ë¶„ì„
# âœ… Hidden Markov Model ì˜ˆì¸¡
# âœ… ì¡°ê±´ë¶€ ì „í™˜ í™•ë¥  (ì‹œì¥ ì¡°ê±´ë³„)
# âœ… ë² ì´ì§€ì•ˆ ì „í™˜ í™•ë¥  ì—…ë°ì´íŠ¸
# âœ… ì•™ìƒë¸” ì „í™˜ ì˜ˆì¸¡
# âœ… ì‹¤ì‹œê°„ ì „í™˜ ì‹ í˜¸ ê°ì§€
# âœ… ë‹¤ì¤‘ ì‹œê°„ëŒ€ ì „í™˜ ì˜ˆì¸¡
# âœ… ì „í™˜ ì˜ˆì¸¡ ì •í™•ë„ ì¶”ì 
# âœ… ê²½ë³´ ì‹œìŠ¤í…œ
# âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì—ëŸ¬ í•¸ë“¤ë§
# âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìºì‹±
# âœ… í†µê³„ì  ì‹ ë¢°ë„ ê³„ì‚°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•