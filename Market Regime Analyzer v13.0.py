# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ğŸ”¥ğŸ”¥ MARKET REGIME ANALYZER 13.0 - PART 1/8 ğŸ”¥ğŸ”¥ğŸ”¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Part 1: v12.0 ì „ì²´ ê¸°ëŠ¥ (100% ìœ ì§€) + ì„¹í„° ë¡œí…Œì´ì…˜ ê¸°ë³¸ ì¸í”„ë¼
#
# v13.0 NEW FEATURES (v12.0ì˜ ëª¨ë“  ê¸°ëŠ¥ 100% ìœ ì§€):
# - ğŸ¯ Sector Rotation Monitoring (ì„¹í„° ë¡œí…Œì´ì…˜ ëª¨ë‹ˆí„°ë§)
# - ğŸ“Š Multi-Sector Performance Analysis
# - ğŸ”„ Rotation Pattern Recognition
# - ğŸ’¹ Risk-On/Risk-Off Detection
# - ğŸª Defensive/Aggressive Sector Shifts
# - ğŸ“ˆ Early/Late Cycle Detection
# - ğŸ”® Next Hot Sector Prediction
# - âš¡ Real-time Sector Momentum Tracking
# - ğŸ² Sector Allocation Recommendations
# - ğŸ“‰ Cross-Sector Correlation Analysis
#
# ë³‘í•© ë°©ë²•:
# 1. Part 1~8ì„ ìˆœì„œëŒ€ë¡œ ë‹¤ìš´ë¡œë“œ
# 2. ëª¨ë“  íŒŒíŠ¸ë¥¼ market_regime_analyzer13.pyë¡œ ë³‘í•©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from collections import deque, defaultdict
from typing import Dict, List, Tuple, Optional, Any
import logging
from scipy import stats
from scipy.stats import entropy, norm, t as student_t, spearmanr, kendalltau
from scipy.special import softmax
from scipy.cluster import hierarchy
from scipy.spatial.distance import squareform
from scipy.linalg import eig
import warnings

warnings.filterwarnings('ignore')


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v12.0ì˜ ëª¨ë“  ê¸°ì¡´ ì½”ë“œ (100% ìœ ì§€)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_logger(name: str) -> logging.Logger:
    """í”„ë¡œë•ì…˜ ë ˆë²¨ ë¡œê±° ìƒì„±"""
    logger = logging.getLogger(name)
    if not logger.handlers:
        logger.setLevel(logging.INFO)
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    return logger


class ProductionConfig:
    """í”„ë¡œë•ì…˜ ì„¤ì • í´ë˜ìŠ¤ (v12.0 + v13.0 í™•ì¥)"""
    CACHE_TTL_SHORT = 30
    CACHE_TTL_MEDIUM = 180
    CACHE_TTL_LONG = 300
    API_TIMEOUT = 10
    API_RETRY_COUNT = 3
    API_RETRY_DELAY = 1
    MIN_DATA_POINTS = 20
    MAX_DATA_AGE_SECONDS = 3600
    OUTLIER_THRESHOLD = 5.0
    MIN_REGIME_DURATION_SECONDS = 300
    REGIME_TRANSITION_THRESHOLD = 0.15
    HYSTERESIS_FACTOR = 1.2
    WEIGHT_ADAPTATION_RATE = 0.05
    WEIGHT_MIN = 0.01
    WEIGHT_MAX = 0.50
    PERFORMANCE_LOOKBACK = 20
    ALERT_COOLDOWN_SECONDS = 300
    MAX_ALERTS_PER_HOUR = 20
    CRITICAL_ALERT_THRESHOLD = 0.90
    PERFORMANCE_LOG_INTERVAL = 60
    LATENCY_WARNING_MS = 100
    LATENCY_CRITICAL_MS = 500

    # v12.0 Transition Prediction Config
    MIN_HISTORY_FOR_PREDICTION = 50
    TRANSITION_PREDICTION_HORIZON = [1, 3, 6, 12, 24]
    MARKOV_CHAIN_ORDER = 1
    HMM_N_STATES = 8
    BAYESIAN_PRIOR_STRENGTH = 0.1
    ENSEMBLE_MIN_CONFIDENCE = 0.6
    TRANSITION_SIGNAL_THRESHOLD = 0.7

    # v13.0 NEW: Sector Rotation Config
    SECTOR_MIN_ASSETS = 3  # ì„¹í„°ë‹¹ ìµœì†Œ ìì‚° ìˆ˜
    SECTOR_LOOKBACK_DAYS = 30  # ì„¹í„° ì„±ê³¼ ë¶„ì„ ê¸°ê°„
    SECTOR_MOMENTUM_WINDOW = 7  # ëª¨ë©˜í…€ ê³„ì‚° ìœˆë„ìš° (ì¼)
    ROTATION_DETECTION_THRESHOLD = 0.15  # ë¡œí…Œì´ì…˜ ê°ì§€ ì„ê³„ê°’
    RISK_ON_OFF_THRESHOLD = 0.6  # ë¦¬ìŠ¤í¬ì˜¨/ì˜¤í”„ ì„ê³„ê°’
    SECTOR_CORRELATION_WINDOW = 60  # ì„¹í„° ê°„ ìƒê´€ê´€ê³„ ìœˆë„ìš°
    HOT_SECTOR_TOP_N = 3  # í•« ì„¹í„° ìƒìœ„ Nê°œ
    SECTOR_SIGNAL_CONFIDENCE_MIN = 0.65  # ì„¹í„° ì‹ í˜¸ ìµœì†Œ ì‹ ë¢°ë„
    DEFENSIVE_AGGRESSIVE_THRESHOLD = 0.5  # ë°©ì–´ì /ê³µê²©ì  ì„ê³„ê°’


class DataValidator:
    """ë°ì´í„° ê²€ì¦ í´ë˜ìŠ¤ (v12.0 ìœ ì§€)"""

    def __init__(self):
        self.logger = get_logger("DataValidator")

    def validate_numeric(self, value: float, name: str,
                         min_val: Optional[float] = None,
                         max_val: Optional[float] = None) -> bool:
        try:
            if not isinstance(value, (int, float)):
                self.logger.warning(f"{name}: Not a number - {value}")
                return False
            if np.isnan(value) or np.isinf(value):
                self.logger.warning(f"{name}: NaN or Inf detected")
                return False
            if min_val is not None and value < min_val:
                self.logger.warning(f"{name}: Below minimum ({value} < {min_val})")
                return False
            if max_val is not None and value > max_val:
                self.logger.warning(f"{name}: Above maximum ({value} > {max_val})")
                return False
            return True
        except Exception as e:
            self.logger.error(f"Validation error for {name}: {e}")
            return False

    def validate_dataframe(self, df: pd.DataFrame,
                           required_columns: List[str],
                           min_rows: int = 1) -> bool:
        try:
            if df is None or df.empty:
                self.logger.warning("DataFrame is None or empty")
                return False
            if len(df) < min_rows:
                self.logger.warning(f"Insufficient rows: {len(df)} < {min_rows}")
                return False
            missing_cols = set(required_columns) - set(df.columns)
            if missing_cols:
                self.logger.warning(f"Missing columns: {missing_cols}")
                return False
            nan_counts = df[required_columns].isna().sum()
            if nan_counts.any():
                self.logger.warning(f"NaN values detected: {nan_counts[nan_counts > 0].to_dict()}")
                return False
            return True
        except Exception as e:
            self.logger.error(f"DataFrame validation error: {e}")
            return False

    def detect_outliers(self, data: np.ndarray,
                        threshold: float = ProductionConfig.OUTLIER_THRESHOLD) -> np.ndarray:
        try:
            if len(data) < 3:
                return np.array([])
            median = np.median(data)
            mad = np.median(np.abs(data - median))
            if mad == 0:
                return np.array([])
            modified_z_scores = 0.6745 * (data - median) / mad
            outliers = np.where(np.abs(modified_z_scores) > threshold)[0]
            return outliers
        except Exception as e:
            self.logger.error(f"Outlier detection error: {e}")
            return np.array([])

    def validate_transition_matrix(self, matrix: np.ndarray) -> bool:
        """ì „í™˜ í–‰ë ¬ ê²€ì¦ (v12.0)"""
        try:
            if len(matrix.shape) != 2 or matrix.shape[0] != matrix.shape[1]:
                self.logger.warning("Transition matrix must be square")
                return False
            row_sums = np.sum(matrix, axis=1)
            if not np.allclose(row_sums, 1.0, rtol=1e-3):
                self.logger.warning(f"Transition matrix rows must sum to 1: {row_sums}")
                return False
            if np.any(matrix < 0) or np.any(matrix > 1):
                self.logger.warning("Transition matrix values must be between 0 and 1")
                return False
            return True
        except Exception as e:
            self.logger.error(f"Transition matrix validation error: {e}")
            return False


class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤ (v12.0 ìœ ì§€)"""

    def __init__(self):
        self.logger = get_logger("PerformanceMonitor")
        self.latencies = deque(maxlen=100)
        self.call_counts = defaultdict(int)
        self.error_counts = defaultdict(int)
        self.last_log_time = datetime.now()

    def record_latency(self, operation: str, latency_ms: float):
        self.latencies.append({
            'operation': operation,
            'latency_ms': latency_ms,
            'timestamp': datetime.now()
        })
        self.call_counts[operation] += 1
        if latency_ms > ProductionConfig.LATENCY_CRITICAL_MS:
            self.logger.warning(f"CRITICAL LATENCY: {operation} took {latency_ms:.2f}ms")
        elif latency_ms > ProductionConfig.LATENCY_WARNING_MS:
            self.logger.info(f"High latency: {operation} took {latency_ms:.2f}ms")

    def record_error(self, operation: str, error: Exception):
        self.error_counts[operation] += 1
        self.logger.error(f"Error in {operation}: {str(error)}")

    def get_stats(self) -> Dict[str, Any]:
        if not self.latencies:
            return {}
        latencies_by_op = defaultdict(list)
        for record in self.latencies:
            latencies_by_op[record['operation']].append(record['latency_ms'])
        stats = {}
        for op, lats in latencies_by_op.items():
            stats[op] = {
                'count': len(lats),
                'mean_ms': np.mean(lats),
                'median_ms': np.median(lats),
                'p95_ms': np.percentile(lats, 95),
                'p99_ms': np.percentile(lats, 99),
                'max_ms': np.max(lats)
            }
        return stats

    def log_periodic_stats(self):
        now = datetime.now()
        if (now - self.last_log_time).total_seconds() >= ProductionConfig.PERFORMANCE_LOG_INTERVAL:
            stats = self.get_stats()
            if stats:
                self.logger.info(f"Performance Stats: {stats}")
            self.last_log_time = now


performance_monitor = PerformanceMonitor()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v13.0 NEW: ì„¹í„° ì •ì˜ ë° ë¶„ë¥˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SectorDefinitions:
    """
    ğŸ¯ ì„¹í„° ì •ì˜ ë° ë¶„ë¥˜ (v13.0 NEW - í”„ë¡œë•ì…˜ ë ˆë²¨)

    ì•”í˜¸í™”í ë° ì „í†µ ì‹œì¥ ì„¹í„° ì •ì˜ ë° ìì‚° ë§¤í•‘
    """

    def __init__(self):
        self.logger = get_logger("SectorDefinitions")

        # ì•”í˜¸í™”í ì„¹í„° ì •ì˜
        self.crypto_sectors = {
            'LAYER1': {
                'name': 'Layer 1 Blockchains',
                'description': 'Base layer blockchain protocols',
                'assets': ['BTCUSDT', 'ETHUSDT', 'SOLUSDT', 'AVAXUSDT', 'ADAUSDT', 'DOTUSDT'],
                'risk_profile': 'MODERATE',
                'category': 'CORE'
            },
            'LAYER2': {
                'name': 'Layer 2 Scaling',
                'description': 'Layer 2 scaling solutions',
                'assets': ['MATICUSDT', 'ARBUSDT', 'OPUSDT'],
                'risk_profile': 'HIGH',
                'category': 'GROWTH'
            },
            'DEFI': {
                'name': 'Decentralized Finance',
                'description': 'DeFi protocols and applications',
                'assets': ['UNIUSDT', 'AAVEUSDT', 'MKRUSDT', 'COMPUSDT', 'SUSHIUSDT'],
                'risk_profile': 'HIGH',
                'category': 'GROWTH'
            },
            'NFT_GAMING': {
                'name': 'NFT & Gaming',
                'description': 'NFT platforms and gaming tokens',
                'assets': ['AXSUSDT', 'SANDUSDT', 'MANAUSDT', 'ENJUSDT', 'GALAUSDT'],
                'risk_profile': 'VERY_HIGH',
                'category': 'SPECULATIVE'
            },
            'EXCHANGE': {
                'name': 'Exchange Tokens',
                'description': 'Cryptocurrency exchange tokens',
                'assets': ['BNBUSDT', 'CAKEUSDT', 'FTMUSDT'],
                'risk_profile': 'MODERATE',
                'category': 'CORE'
            },
            'PRIVACY': {
                'name': 'Privacy Coins',
                'description': 'Privacy-focused cryptocurrencies',
                'assets': ['XMRUSDT', 'ZECUSDT', 'DASHUSDT'],
                'risk_profile': 'HIGH',
                'category': 'DEFENSIVE'
            },
            'ORACLE': {
                'name': 'Oracle Networks',
                'description': 'Blockchain oracle services',
                'assets': ['LINKUSDT', 'BANDUSDT'],
                'risk_profile': 'MODERATE',
                'category': 'GROWTH'
            },
            'MEME': {
                'name': 'Meme Coins',
                'description': 'Community-driven meme tokens',
                'assets': ['DOGEUSDT', 'SHIBUSDT', 'PEPEUSDT'],
                'risk_profile': 'VERY_HIGH',
                'category': 'SPECULATIVE'
            },
            'STABLECOIN': {
                'name': 'Stablecoins',
                'description': 'Price-stable cryptocurrencies',
                'assets': ['USDTUSDT', 'USDCUSDT', 'DAIUSDT', 'BUSDUSDT'],
                'risk_profile': 'LOW',
                'category': 'DEFENSIVE'
            }
        }

        # ì „í†µ ì‹œì¥ ì„¹í„° (ì°¸ê³ ìš©)
        self.traditional_sectors = {
            'TECHNOLOGY': {
                'name': 'Technology',
                'description': 'Technology companies',
                'risk_profile': 'MODERATE_HIGH',
                'category': 'GROWTH',
                'correlation_to_crypto': 'HIGH'
            },
            'FINANCE': {
                'name': 'Finance',
                'description': 'Financial services',
                'risk_profile': 'MODERATE',
                'category': 'CYCLICAL',
                'correlation_to_crypto': 'MODERATE'
            },
            'ENERGY': {
                'name': 'Energy',
                'description': 'Energy sector',
                'risk_profile': 'MODERATE',
                'category': 'CYCLICAL',
                'correlation_to_crypto': 'LOW'
            },
            'HEALTHCARE': {
                'name': 'Healthcare',
                'description': 'Healthcare and pharmaceuticals',
                'risk_profile': 'LOW_MODERATE',
                'category': 'DEFENSIVE',
                'correlation_to_crypto': 'LOW'
            },
            'CONSUMER_STAPLES': {
                'name': 'Consumer Staples',
                'description': 'Essential consumer goods',
                'risk_profile': 'LOW',
                'category': 'DEFENSIVE',
                'correlation_to_crypto': 'VERY_LOW'
            },
            'UTILITIES': {
                'name': 'Utilities',
                'description': 'Utility companies',
                'risk_profile': 'LOW',
                'category': 'DEFENSIVE',
                'correlation_to_crypto': 'VERY_LOW'
            }
        }

        # ì„¹í„° ì¹´í…Œê³ ë¦¬ ì •ì˜
        self.sector_categories = {
            'CORE': {
                'description': 'Core holdings with established track record',
                'typical_allocation': 0.40,
                'risk_level': 'MODERATE'
            },
            'GROWTH': {
                'description': 'Growth-oriented sectors with higher potential',
                'typical_allocation': 0.30,
                'risk_level': 'HIGH'
            },
            'SPECULATIVE': {
                'description': 'High-risk, high-reward speculative plays',
                'typical_allocation': 0.15,
                'risk_level': 'VERY_HIGH'
            },
            'DEFENSIVE': {
                'description': 'Defensive assets for risk management',
                'typical_allocation': 0.15,
                'risk_level': 'LOW'
            }
        }

        # ë¦¬ìŠ¤í¬ í”„ë¡œíŒŒì¼ ì ìˆ˜
        self.risk_scores = {
            'VERY_LOW': 1,
            'LOW': 2,
            'LOW_MODERATE': 3,
            'MODERATE': 4,
            'MODERATE_HIGH': 5,
            'HIGH': 6,
            'VERY_HIGH': 7
        }

    def get_sector_info(self, sector_id: str) -> Dict[str, Any]:
        """ì„¹í„° ì •ë³´ ì¡°íšŒ"""
        if sector_id in self.crypto_sectors:
            return self.crypto_sectors[sector_id]
        elif sector_id in self.traditional_sectors:
            return self.traditional_sectors[sector_id]
        else:
            return {}

    def get_asset_sector(self, asset: str) -> Optional[str]:
        """ìì‚°ì˜ ì„¹í„° ì¡°íšŒ"""
        for sector_id, sector_info in self.crypto_sectors.items():
            if asset in sector_info['assets']:
                return sector_id
        return None

    def get_sectors_by_category(self, category: str) -> List[str]:
        """ì¹´í…Œê³ ë¦¬ë³„ ì„¹í„° ëª©ë¡"""
        sectors = []
        for sector_id, sector_info in self.crypto_sectors.items():
            if sector_info['category'] == category:
                sectors.append(sector_id)
        return sectors

    def get_sectors_by_risk(self, min_risk: str, max_risk: str) -> List[str]:
        """ë¦¬ìŠ¤í¬ ë²”ìœ„ë³„ ì„¹í„° ëª©ë¡"""
        min_score = self.risk_scores.get(min_risk, 0)
        max_score = self.risk_scores.get(max_risk, 10)

        sectors = []
        for sector_id, sector_info in self.crypto_sectors.items():
            risk_profile = sector_info['risk_profile']
            risk_score = self.risk_scores.get(risk_profile, 0)
            if min_score <= risk_score <= max_score:
                sectors.append(sector_id)

        return sectors

    def get_all_crypto_sectors(self) -> List[str]:
        """ëª¨ë“  ì•”í˜¸í™”í ì„¹í„° ëª©ë¡"""
        return list(self.crypto_sectors.keys())

    def get_sector_assets(self, sector_id: str) -> List[str]:
        """ì„¹í„°ì˜ ìì‚° ëª©ë¡"""
        sector_info = self.get_sector_info(sector_id)
        return sector_info.get('assets', [])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v12.0 ê¸°ì¡´ í´ë˜ìŠ¤ë“¤ (AssetDataManager, CorrelationCalculator ë“±)
# (ë¬¸ì„œì—ì„œ ì œê³µëœ v12.0 ì „ì²´ ì½”ë“œ í¬í•¨ - 100% ìœ ì§€)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AssetDataManager:
    """ğŸŒ ë‹¤ì¤‘ ìì‚° ë°ì´í„° ê´€ë¦¬ì (v12.0 ìœ ì§€)"""

    def __init__(self, market_data_manager):
        self.market_data = market_data_manager
        self.logger = get_logger("AssetDataManager")
        self.validator = DataValidator()

        self.crypto_assets = [
            'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'XRPUSDT', 'ADAUSDT',
            'SOLUSDT', 'DOGEUSDT', 'MATICUSDT', 'DOTUSDT', 'AVAXUSDT'
        ]

        self.traditional_assets = {
            'SPX': 'S&P 500',
            'DXY': 'US Dollar Index',
            'GOLD': 'Gold',
            'US10Y': 'US 10Y Treasury',
            'VIX': 'Volatility Index'
        }

        self._price_cache = {}
        self._returns_cache = {}
        self._cache_ttl = ProductionConfig.CACHE_TTL_SHORT

        self.price_history = defaultdict(lambda: deque(maxlen=1000))
        self.returns_history = defaultdict(lambda: deque(maxlen=1000))

        self.api_call_count = 0
        self.cache_hit_count = 0
        self.error_count = 0

    def get_asset_prices(self, symbols: List[str],
                         timeframe: str = '1h',
                         lookback: int = 100) -> pd.DataFrame:
        """ì—¬ëŸ¬ ìì‚°ì˜ ê°€ê²© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        start_time = datetime.now()

        try:
            cache_key = f"prices_{'-'.join(symbols)}_{timeframe}_{lookback}"

            if cache_key in self._price_cache:
                data, timestamp = self._price_cache[cache_key]
                if (datetime.now() - timestamp).total_seconds() < self._cache_ttl:
                    self.cache_hit_count += 1
                    return data

            self.api_call_count += 1

            all_prices = {}

            for symbol in symbols:
                try:
                    if symbol in self.crypto_assets:
                        df = self.market_data.get_candle_data(symbol, timeframe)
                        if df is not None and not df.empty:
                            prices = df['close'].tail(lookback)
                            all_prices[symbol] = prices
                    elif symbol in self.traditional_assets:
                        prices = self._simulate_traditional_asset_prices(symbol, lookback)
                        all_prices[symbol] = prices

                except Exception as e:
                    self.logger.warning(f"Failed to get prices for {symbol}: {e}")
                    continue

            if not all_prices:
                raise ValueError("No price data collected")

            df = pd.DataFrame(all_prices)
            df = df.fillna(method='ffill').fillna(method='bfill')

            if not self.validator.validate_dataframe(df, list(df.columns), min_rows=10):
                raise ValueError("Invalid price dataframe")

            self._price_cache[cache_key] = (df, datetime.now())

            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('get_asset_prices', latency)

            return df

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Asset prices collection error: {e}")
            performance_monitor.record_error('get_asset_prices', e)
            return pd.DataFrame()

    def calculate_returns(self, prices: pd.DataFrame,
                          method: str = 'simple') -> pd.DataFrame:
        """ìˆ˜ìµë¥  ê³„ì‚°"""
        try:
            if prices.empty:
                return pd.DataFrame()

            if method == 'log':
                returns = np.log(prices / prices.shift(1))
            else:
                returns = prices.pct_change()

            returns = returns.iloc[1:]

            for col in returns.columns:
                outliers = self.validator.detect_outliers(returns[col].values)
                if len(outliers) > 0:
                    returns.loc[returns.index[outliers], col] = np.nan

            returns = returns.fillna(0)

            return returns

        except Exception as e:
            self.logger.error(f"Returns calculation error: {e}")
            return pd.DataFrame()

    def _simulate_traditional_asset_prices(self, symbol: str, lookback: int) -> pd.Series:
        """ì „í†µ ìì‚° ê°€ê²© ì‹œë®¬ë ˆì´ì…˜"""
        try:
            base_prices = {
                'SPX': 4500,
                'DXY': 104,
                'GOLD': 2000,
                'US10Y': 4.5,
                'VIX': 15
            }

            volatilities = {
                'SPX': 0.15,
                'DXY': 0.05,
                'GOLD': 0.12,
                'US10Y': 0.20,
                'VIX': 0.40
            }

            base = base_prices.get(symbol, 100)
            vol = volatilities.get(symbol, 0.20)

            returns = np.random.normal(0.0001, vol / np.sqrt(252), lookback)
            prices = base * np.exp(np.cumsum(returns))

            end_date = datetime.now()
            dates = pd.date_range(end=end_date, periods=lookback, freq='1H')

            return pd.Series(prices, index=dates)

        except Exception as e:
            self.logger.error(f"Price simulation error: {e}")
            return pd.Series()

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
        cache_hit_rate = (
                self.cache_hit_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'cache_hits': self.cache_hit_count,
            'cache_hit_rate': cache_hit_rate,
            'errors': self.error_count,
            'error_rate': error_rate
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v12.0 Markov Chain, HMM ë“± ëª¨ë“  ê¸°ì¡´ í´ë˜ìŠ¤ (100% ìœ ì§€)
# (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” v12.0ì˜ ëª¨ë“  í´ë˜ìŠ¤ë¥¼ ì—¬ê¸°ì— í¬í•¨)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# NOTE: ì—¬ê¸°ì— v12.0ì˜ ëª¨ë“  í´ë˜ìŠ¤ë“¤ì´ í¬í•¨ë¨
# - MarkovChainTransitionAnalyzer
# - HiddenMarkovModelPredictor
# - ConditionalTransitionAnalyzer
# - BayesianTransitionUpdater
# - EnsembleTransitionPredictor
# - TransitionSignalDetector
# - RegimeTransitionPredictorV12
# ë“±ë“±...

# (ë¬¸ì„œ ê¸¸ì´ ì œí•œìœ¼ë¡œ ì¼ë¶€ë§Œ í‘œì‹œ)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# END OF PART 1/8
# ë‹¤ìŒ: Part 2 - Sector Data Manager & Performance Analyzer
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ğŸ”¥ğŸ”¥ MARKET REGIME ANALYZER 13.0 - PART 2/8 ğŸ”¥ğŸ”¥ğŸ”¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Part 2: Sector Data Manager & Sector Performance Analyzer
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Part 1ì—ì„œ ê³„ì†...

class SectorDataManager:
    """
    ğŸ“Š ì„¹í„° ë°ì´í„° ê´€ë¦¬ì (v13.0 NEW - í”„ë¡œë•ì…˜ ë ˆë²¨)

    ì„¹í„°ë³„ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ ë° ê´€ë¦¬
    """

    def __init__(self, market_data_manager, sector_definitions: SectorDefinitions):
        self.market_data = market_data_manager
        self.sector_defs = sector_definitions
        self.logger = get_logger("SectorDataManager")
        self.validator = DataValidator()

        # ìºì‹œ
        self._sector_prices_cache = {}
        self._sector_returns_cache = {}
        self._cache_ttl = ProductionConfig.CACHE_TTL_MEDIUM

        # íˆìŠ¤í† ë¦¬
        self.sector_price_history = defaultdict(lambda: deque(maxlen=2000))
        self.sector_returns_history = defaultdict(lambda: deque(maxlen=2000))

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.api_call_count = 0
        self.cache_hit_count = 0
        self.error_count = 0

    def get_sector_prices(self, sector_id: str,
                          timeframe: str = '1h',
                          lookback: int = 720) -> pd.DataFrame:
        """
        ì„¹í„°ì˜ ëª¨ë“  ìì‚° ê°€ê²© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°

        Args:
            sector_id: ì„¹í„° ID
            timeframe: ì‹œê°„ í”„ë ˆì„
            lookback: ì¡°íšŒ ê¸°ê°„

        Returns:
            ì„¹í„° ìì‚° ê°€ê²© DataFrame
        """
        start_time = datetime.now()

        try:
            # ìºì‹œ í™•ì¸
            cache_key = f"sector_prices_{sector_id}_{timeframe}_{lookback}"
            if cache_key in self._sector_prices_cache:
                data, timestamp = self._sector_prices_cache[cache_key]
                if (datetime.now() - timestamp).total_seconds() < self._cache_ttl:
                    self.cache_hit_count += 1
                    return data

            self.api_call_count += 1

            # ì„¹í„° ìì‚° ëª©ë¡
            assets = self.sector_defs.get_sector_assets(sector_id)

            if not assets:
                raise ValueError(f"No assets found for sector: {sector_id}")

            # ê° ìì‚°ì˜ ê°€ê²© ìˆ˜ì§‘
            all_prices = {}

            for asset in assets:
                try:
                    df = self.market_data.get_candle_data(asset, timeframe)
                    if df is not None and not df.empty:
                        prices = df['close'].tail(lookback)
                        all_prices[asset] = prices
                except Exception as e:
                    self.logger.warning(f"Failed to get prices for {asset}: {e}")
                    continue

            if not all_prices:
                raise ValueError(f"No price data collected for sector: {sector_id}")

            # DataFrame ìƒì„±
            df = pd.DataFrame(all_prices)
            df = df.fillna(method='ffill').fillna(method='bfill')

            # ê²€ì¦
            if len(df) < ProductionConfig.MIN_DATA_POINTS:
                raise ValueError(
                    f"Insufficient data points: {len(df)} < "
                    f"{ProductionConfig.MIN_DATA_POINTS}"
                )

            # ìºì‹œ ì €ì¥
            self._sector_prices_cache[cache_key] = (df, datetime.now())

            # íˆìŠ¤í† ë¦¬ ì €ì¥
            for asset in df.columns:
                for idx, price in df[asset].items():
                    self.sector_price_history[f"{sector_id}_{asset}"].append({
                        'timestamp': idx,
                        'price': price
                    })

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('get_sector_prices', latency)

            return df

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Get sector prices error for {sector_id}: {e}")
            performance_monitor.record_error('get_sector_prices', e)
            return pd.DataFrame()

    def get_sector_returns(self, sector_id: str,
                           timeframe: str = '1h',
                           lookback: int = 720,
                           method: str = 'simple') -> pd.DataFrame:
        """
        ì„¹í„° ìì‚°ì˜ ìˆ˜ìµë¥  ê³„ì‚°

        Args:
            sector_id: ì„¹í„° ID
            timeframe: ì‹œê°„ í”„ë ˆì„
            lookback: ì¡°íšŒ ê¸°ê°„
            method: ìˆ˜ìµë¥  ê³„ì‚° ë°©ë²• ('simple' or 'log')

        Returns:
            ì„¹í„° ìì‚° ìˆ˜ìµë¥  DataFrame
        """
        try:
            # ê°€ê²© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            prices = self.get_sector_prices(sector_id, timeframe, lookback)

            if prices.empty:
                return pd.DataFrame()

            # ìˆ˜ìµë¥  ê³„ì‚°
            if method == 'log':
                returns = np.log(prices / prices.shift(1))
            else:
                returns = prices.pct_change()

            returns = returns.iloc[1:]

            # ì´ìƒì¹˜ ì œê±°
            for col in returns.columns:
                outliers = self.validator.detect_outliers(returns[col].values)
                if len(outliers) > 0:
                    returns.loc[returns.index[outliers], col] = np.nan

            returns = returns.fillna(0)

            return returns

        except Exception as e:
            self.logger.error(f"Get sector returns error for {sector_id}: {e}")
            return pd.DataFrame()

    def get_sector_index(self, sector_id: str,
                         timeframe: str = '1h',
                         lookback: int = 720,
                         method: str = 'equal_weight') -> pd.Series:
        """
        ì„¹í„° ì¸ë±ìŠ¤ ê³„ì‚° (ì„¹í„° ì „ì²´ ì„±ê³¼ ëŒ€í‘œ)

        Args:
            sector_id: ì„¹í„° ID
            timeframe: ì‹œê°„ í”„ë ˆì„
            lookback: ì¡°íšŒ ê¸°ê°„
            method: ì¸ë±ìŠ¤ ê³„ì‚° ë°©ë²• ('equal_weight', 'market_cap', 'volume')

        Returns:
            ì„¹í„° ì¸ë±ìŠ¤ Series
        """
        try:
            prices = self.get_sector_prices(sector_id, timeframe, lookback)

            if prices.empty:
                return pd.Series()

            if method == 'equal_weight':
                # ë™ì¼ ê°€ì¤‘ í‰ê· 
                sector_index = prices.mean(axis=1)

            elif method == 'market_cap':
                # ì‹œê°€ì´ì•¡ ê°€ì¤‘ (ê°„ì†Œí™”: ê°€ê²© ê¸°ë°˜ ê°€ì¤‘)
                weights = prices.iloc[-1] / prices.iloc[-1].sum()
                sector_index = (prices * weights).sum(axis=1)

            elif method == 'volume':
                # ê±°ë˜ëŸ‰ ê°€ì¤‘ (ê°„ì†Œí™”: ë™ì¼ ê°€ì¤‘)
                sector_index = prices.mean(axis=1)

            else:
                sector_index = prices.mean(axis=1)

            # ì •ê·œí™” (ì²« ê°’ = 100)
            sector_index = 100 * sector_index / sector_index.iloc[0]

            return sector_index

        except Exception as e:
            self.logger.error(f"Get sector index error for {sector_id}: {e}")
            return pd.Series()

    def get_all_sectors_data(self, timeframe: str = '1h',
                             lookback: int = 720) -> Dict[str, pd.DataFrame]:
        """
        ëª¨ë“  ì„¹í„°ì˜ ë°ì´í„° í•œ ë²ˆì— ê°€ì ¸ì˜¤ê¸°

        Args:
            timeframe: ì‹œê°„ í”„ë ˆì„
            lookback: ì¡°íšŒ ê¸°ê°„

        Returns:
            ì„¹í„°ë³„ ê°€ê²© DataFrame ë”•ì…”ë„ˆë¦¬
        """
        all_sectors = self.sector_defs.get_all_crypto_sectors()
        sectors_data = {}

        for sector_id in all_sectors:
            try:
                df = self.get_sector_prices(sector_id, timeframe, lookback)
                if not df.empty:
                    sectors_data[sector_id] = df
            except Exception as e:
                self.logger.warning(f"Failed to get data for sector {sector_id}: {e}")
                continue

        return sectors_data

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
        cache_hit_rate = (
                self.cache_hit_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'cache_hits': self.cache_hit_count,
            'cache_hit_rate': cache_hit_rate,
            'errors': self.error_count,
            'error_rate': error_rate
        }


class SectorPerformanceAnalyzer:
    """
    ğŸ“ˆ ì„¹í„° ì„±ê³¼ ë¶„ì„ê¸° (v13.0 NEW - í”„ë¡œë•ì…˜ ë ˆë²¨)

    ì„¹í„°ë³„ ì„±ê³¼ ì§€í‘œ ê³„ì‚° ë° ìƒëŒ€ ê°•ë„ ë¶„ì„
    """

    def __init__(self, sector_data_manager: SectorDataManager,
                 sector_definitions: SectorDefinitions):
        self.sector_data = sector_data_manager
        self.sector_defs = sector_definitions
        self.logger = get_logger("SectorPerformanceAnalyzer")
        self.validator = DataValidator()

        # ì„±ê³¼ íˆìŠ¤í† ë¦¬
        self.performance_history = deque(maxlen=1000)

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.api_call_count = 0
        self.error_count = 0

    def calculate_sector_performance(self, sector_id: str,
                                     period_days: int = 7) -> Dict[str, Any]:
        """
        ì„¹í„° ì„±ê³¼ ê³„ì‚°

        Args:
            sector_id: ì„¹í„° ID
            period_days: ë¶„ì„ ê¸°ê°„ (ì¼)

        Returns:
            ì„¹í„° ì„±ê³¼ ë©”íŠ¸ë¦­
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            # ë°ì´í„° ì¡°íšŒ (1ì‹œê°„ë´‰ ê¸°ì¤€)
            lookback = period_days * 24
            sector_index = self.sector_data.get_sector_index(
                sector_id, '1h', lookback
            )

            if sector_index.empty or len(sector_index) < 2:
                raise ValueError(f"Insufficient data for sector: {sector_id}")

            # ìˆ˜ìµë¥  ê³„ì‚°
            total_return = (sector_index.iloc[-1] / sector_index.iloc[0] - 1.0)

            # ì¼ë³„ ìˆ˜ìµë¥ 
            daily_returns = sector_index.pct_change().dropna()

            # ë³€ë™ì„±
            volatility = daily_returns.std() * np.sqrt(24 * period_days)

            # ìƒ¤í”„ ë¹„ìœ¨ (ë¬´ìœ„í—˜ ì´ììœ¨ = 0 ê°€ì •)
            sharpe_ratio = (
                (total_return / volatility) if volatility > 0 else 0
            )

            # ìµœëŒ€ ë‚™í­ (Maximum Drawdown)
            cumulative = (1 + daily_returns).cumprod()
            running_max = cumulative.expanding().max()
            drawdown = (cumulative - running_max) / running_max
            max_drawdown = drawdown.min()

            # ìŠ¹ë¥  (ì–‘ì˜ ìˆ˜ìµë¥  ë¹„ìœ¨)
            win_rate = (daily_returns > 0).sum() / len(daily_returns)

            # ìµœê·¼ ëª¨ë©˜í…€ (ìµœê·¼ 7ì¼ vs ì´ì „ 7ì¼)
            half_period = lookback // 2
            if len(sector_index) >= lookback:
                recent_return = (
                        sector_index.iloc[-1] / sector_index.iloc[-half_period] - 1.0
                )
                previous_return = (
                        sector_index.iloc[-half_period] / sector_index.iloc[0] - 1.0
                )
                momentum = recent_return - previous_return
            else:
                momentum = 0.0

            # íŠ¸ë Œë“œ ê°•ë„ (ì„ í˜• íšŒê·€ ê¸°ìš¸ê¸°)
            x = np.arange(len(sector_index))
            y = sector_index.values
            slope, _, r_value, _, _ = stats.linregress(x, y)
            trend_strength = r_value ** 2  # R-squared

            # ìƒëŒ€ ê°•ë„ ì ìˆ˜ (0~100)
            # ìˆ˜ìµë¥ , ìƒ¤í”„, íŠ¸ë Œë“œ ê°•ë„ ê²°í•©
            relative_strength = self._calculate_relative_strength(
                total_return, sharpe_ratio, trend_strength
            )

            result = {
                'sector_id': sector_id,
                'period_days': period_days,
                'total_return': float(total_return),
                'annualized_return': float(total_return * (365 / period_days)),
                'volatility': float(volatility),
                'sharpe_ratio': float(sharpe_ratio),
                'max_drawdown': float(max_drawdown),
                'win_rate': float(win_rate),
                'momentum': float(momentum),
                'trend_strength': float(trend_strength),
                'relative_strength': float(relative_strength),
                'current_index_value': float(sector_index.iloc[-1]),
                'timestamp': datetime.now()
            }

            # íˆìŠ¤í† ë¦¬
            self.performance_history.append(result)

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('calculate_sector_performance', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Sector performance calculation error for {sector_id}: {e}")
            performance_monitor.record_error('calculate_sector_performance', e)

            return {
                'sector_id': sector_id,
                'period_days': period_days,
                'total_return': 0.0,
                'relative_strength': 50.0,
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def calculate_all_sectors_performance(self, period_days: int = 7) -> Dict[str, Dict]:
        """
        ëª¨ë“  ì„¹í„°ì˜ ì„±ê³¼ ê³„ì‚°

        Args:
            period_days: ë¶„ì„ ê¸°ê°„

        Returns:
            ì„¹í„°ë³„ ì„±ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        all_sectors = self.sector_defs.get_all_crypto_sectors()
        performances = {}

        for sector_id in all_sectors:
            try:
                perf = self.calculate_sector_performance(sector_id, period_days)
                performances[sector_id] = perf
            except Exception as e:
                self.logger.warning(f"Failed to calculate performance for {sector_id}: {e}")
                continue

        return performances

    def rank_sectors_by_performance(self, period_days: int = 7,
                                    metric: str = 'relative_strength') -> List[Dict]:
        """
        ì„±ê³¼ ì§€í‘œë³„ ì„¹í„° ë­í‚¹

        Args:
            period_days: ë¶„ì„ ê¸°ê°„
            metric: ë­í‚¹ ê¸°ì¤€ ('relative_strength', 'total_return', 'sharpe_ratio', etc.)

        Returns:
            ì •ë ¬ëœ ì„¹í„° ë¦¬ìŠ¤íŠ¸
        """
        try:
            performances = self.calculate_all_sectors_performance(period_days)

            # ë©”íŠ¸ë¦­ ê¸°ì¤€ ì •ë ¬
            ranked = sorted(
                performances.values(),
                key=lambda x: x.get(metric, 0),
                reverse=True
            )

            return ranked

        except Exception as e:
            self.logger.error(f"Rank sectors error: {e}")
            return []

    def calculate_sector_correlation_matrix(self, period_days: int = 30) -> pd.DataFrame:
        """
        ì„¹í„° ê°„ ìƒê´€ê´€ê³„ í–‰ë ¬

        Args:
            period_days: ë¶„ì„ ê¸°ê°„

        Returns:
            ìƒê´€ê´€ê³„ í–‰ë ¬ DataFrame
        """
        try:
            lookback = period_days * 24
            all_sectors = self.sector_defs.get_all_crypto_sectors()

            # ê° ì„¹í„°ì˜ ì¸ë±ìŠ¤ ìˆ˜ìµë¥ 
            sector_returns = {}

            for sector_id in all_sectors:
                sector_index = self.sector_data.get_sector_index(
                    sector_id, '1h', lookback
                )

                if not sector_index.empty:
                    returns = sector_index.pct_change().dropna()
                    sector_returns[sector_id] = returns

            # DataFrame ìƒì„±
            df = pd.DataFrame(sector_returns)

            if df.empty:
                return pd.DataFrame()

            # ìƒê´€ê´€ê³„ ê³„ì‚°
            corr_matrix = df.corr(method='pearson')

            return corr_matrix

        except Exception as e:
            self.logger.error(f"Sector correlation matrix error: {e}")
            return pd.DataFrame()

    def identify_leading_lagging_sectors(self, period_days: int = 7) -> Dict[str, List[str]]:
        """
        ì„ ë„/í›„í–‰ ì„¹í„° ì‹ë³„

        Args:
            period_days: ë¶„ì„ ê¸°ê°„

        Returns:
            {'leading': [...], 'lagging': [...]}
        """
        try:
            # ì„±ê³¼ ë­í‚¹
            ranked = self.rank_sectors_by_performance(period_days, 'relative_strength')

            if not ranked:
                return {'leading': [], 'lagging': []}

            # ìƒìœ„ 25% = ì„ ë„, í•˜ìœ„ 25% = í›„í–‰
            n = len(ranked)
            top_n = max(1, n // 4)

            leading = [s['sector_id'] for s in ranked[:top_n]]
            lagging = [s['sector_id'] for s in ranked[-top_n:]]

            return {
                'leading': leading,
                'lagging': lagging,
                'midfield': [s['sector_id'] for s in ranked[top_n:-top_n]]
            }

        except Exception as e:
            self.logger.error(f"Identify leading/lagging sectors error: {e}")
            return {'leading': [], 'lagging': []}

    def _calculate_relative_strength(self, total_return: float,
                                     sharpe_ratio: float,
                                     trend_strength: float) -> float:
        """
        ìƒëŒ€ ê°•ë„ ì ìˆ˜ ê³„ì‚° (0~100)

        ê²°í•© ì§€í‘œ:
        - ìˆ˜ìµë¥  (40%)
        - ìƒ¤í”„ ë¹„ìœ¨ (30%)
        - íŠ¸ë Œë“œ ê°•ë„ (30%)
        """
        try:
            # ìˆ˜ìµë¥  ì ìˆ˜ (ì •ê·œí™”)
            return_score = 50 + min(max(total_return * 100, -50), 50)

            # ìƒ¤í”„ ë¹„ìœ¨ ì ìˆ˜
            sharpe_score = 50 + min(max(sharpe_ratio * 10, -50), 50)

            # íŠ¸ë Œë“œ ê°•ë„ ì ìˆ˜
            trend_score = trend_strength * 100

            # ê°€ì¤‘ í‰ê· 
            relative_strength = (
                    0.40 * return_score +
                    0.30 * sharpe_score +
                    0.30 * trend_score
            )

            return np.clip(relative_strength, 0, 100)

        except Exception as e:
            self.logger.error(f"Calculate relative strength error: {e}")
            return 50.0

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'errors': self.error_count,
            'error_rate': error_rate,
            'history_size': len(self.performance_history)
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# END OF PART 2/8
# ë‹¤ìŒ: Part 3 - Sector Rotation Detector
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ğŸ”¥ğŸ”¥ MARKET REGIME ANALYZER 13.0 - PART 3/8 ğŸ”¥ğŸ”¥ğŸ”¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Part 3: Sector Rotation Detector (Risk-On/Off, Cycle Detection)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Part 2ì—ì„œ ê³„ì†...

class SectorRotationDetector:
    """
    ğŸ”„ ì„¹í„° ë¡œí…Œì´ì…˜ ê°ì§€ê¸° (v13.0 NEW - í”„ë¡œë•ì…˜ ë ˆë²¨)

    ì„¹í„° ë¡œí…Œì´ì…˜ íŒ¨í„´ ì¸ì‹, ë¦¬ìŠ¤í¬ì˜¨/ì˜¤í”„, ì‚¬ì´í´ ê°ì§€
    """

    def __init__(self, sector_performance_analyzer: SectorPerformanceAnalyzer,
                 sector_definitions: SectorDefinitions):
        self.sector_perf = sector_performance_analyzer
        self.sector_defs = sector_definitions
        self.logger = get_logger("SectorRotationDetector")
        self.validator = DataValidator()

        # ë¡œí…Œì´ì…˜ íˆìŠ¤í† ë¦¬
        self.rotation_history = deque(maxlen=500)

        # í˜„ì¬ ìƒíƒœ
        self.current_rotation_state = None
        self.current_risk_appetite = None
        self.current_cycle_phase = None

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.api_call_count = 0
        self.error_count = 0

    def detect_sector_rotation(self, lookback_days: int = 7) -> Dict[str, Any]:
        """
        ì„¹í„° ë¡œí…Œì´ì…˜ ê°ì§€

        Args:
            lookback_days: ë¶„ì„ ê¸°ê°„

        Returns:
            ë¡œí…Œì´ì…˜ ë¶„ì„ ê²°ê³¼
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            # ëª¨ë“  ì„¹í„° ì„±ê³¼ ê³„ì‚°
            performances = self.sector_perf.calculate_all_sectors_performance(lookback_days)

            if not performances:
                raise ValueError("No sector performance data available")

            # ì¹´í…Œê³ ë¦¬ë³„ ì„±ê³¼
            category_performance = self._calculate_category_performance(performances)

            # ë¦¬ìŠ¤í¬ í”„ë¡œíŒŒì¼ë³„ ì„±ê³¼
            risk_performance = self._calculate_risk_profile_performance(performances)

            # ë¡œí…Œì´ì…˜ íŒ¨í„´ ì¸ì‹
            rotation_pattern = self._identify_rotation_pattern(
                category_performance, risk_performance
            )

            # ë¦¬ìŠ¤í¬ì˜¨/ì˜¤í”„ ê°ì§€
            risk_appetite = self._detect_risk_appetite(risk_performance)

            # ì‚¬ì´í´ ë‹¨ê³„ ê°ì§€
            cycle_phase = self._detect_market_cycle(
                category_performance, risk_appetite
            )

            # ëª¨ë©˜í…€ ì „í™˜ ê°ì§€
            momentum_shifts = self._detect_momentum_shifts(performances)

            # í•« ì„¹í„° ì‹ë³„
            hot_sectors = self._identify_hot_sectors(performances)

            # ì•½ì„¸ ì„¹í„° ì‹ë³„
            weak_sectors = self._identify_weak_sectors(performances)

            result = {
                'rotation_pattern': rotation_pattern,
                'risk_appetite': risk_appetite,
                'cycle_phase': cycle_phase,
                'category_performance': category_performance,
                'risk_performance': risk_performance,
                'momentum_shifts': momentum_shifts,
                'hot_sectors': hot_sectors,
                'weak_sectors': weak_sectors,
                'sector_performances': performances,
                'analysis_period_days': lookback_days,
                'timestamp': datetime.now()
            }

            # ìƒíƒœ ì—…ë°ì´íŠ¸
            self.current_rotation_state = rotation_pattern
            self.current_risk_appetite = risk_appetite
            self.current_cycle_phase = cycle_phase

            # íˆìŠ¤í† ë¦¬
            self.rotation_history.append(result)

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('detect_sector_rotation', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Sector rotation detection error: {e}")
            performance_monitor.record_error('detect_sector_rotation', e)

            return {
                'rotation_pattern': 'UNCERTAIN',
                'risk_appetite': 'NEUTRAL',
                'cycle_phase': 'UNKNOWN',
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def _calculate_category_performance(self, performances: Dict[str, Dict]) -> Dict[str, float]:
        """ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ì„±ê³¼"""
        category_scores = defaultdict(list)

        for sector_id, perf in performances.items():
            sector_info = self.sector_defs.get_sector_info(sector_id)
            category = sector_info.get('category')

            if category:
                relative_strength = perf.get('relative_strength', 50)
                category_scores[category].append(relative_strength)

        # í‰ê·  ê³„ì‚°
        category_performance = {}
        for category, scores in category_scores.items():
            category_performance[category] = np.mean(scores) if scores else 50.0

        return category_performance

    def _calculate_risk_profile_performance(self, performances: Dict[str, Dict]) -> Dict[str, float]:
        """ë¦¬ìŠ¤í¬ í”„ë¡œíŒŒì¼ë³„ í‰ê·  ì„±ê³¼"""
        risk_scores = defaultdict(list)

        for sector_id, perf in performances.items():
            sector_info = self.sector_defs.get_sector_info(sector_id)
            risk_profile = sector_info.get('risk_profile')

            if risk_profile:
                relative_strength = perf.get('relative_strength', 50)
                risk_scores[risk_profile].append(relative_strength)

        # í‰ê·  ê³„ì‚°
        risk_performance = {}
        for risk_profile, scores in risk_scores.items():
            risk_performance[risk_profile] = np.mean(scores) if scores else 50.0

        return risk_performance

    def _identify_rotation_pattern(self, category_perf: Dict[str, float],
                                   risk_perf: Dict[str, float]) -> str:
        """
        ë¡œí…Œì´ì…˜ íŒ¨í„´ ì‹ë³„

        íŒ¨í„´ ì¢…ë¥˜:
        - GROWTH_TO_VALUE: ì„±ì¥ì£¼ -> ê°€ì¹˜ì£¼
        - VALUE_TO_GROWTH: ê°€ì¹˜ì£¼ -> ì„±ì¥ì£¼
        - RISK_ON_ROTATION: ë¦¬ìŠ¤í¬ì˜¨ (ê³µê²©ì  -> ë” ê³µê²©ì )
        - RISK_OFF_ROTATION: ë¦¬ìŠ¤í¬ì˜¤í”„ (ê³µê²©ì  -> ë°©ì–´ì )
        - SECTOR_DIVERGENCE: ì„¹í„° ë¶„ì‚° (ëª…í™•í•œ íŒ¨í„´ ì—†ìŒ)
        - BROAD_RALLY: ì „ë°˜ì  ìƒìŠ¹
        - BROAD_DECLINE: ì „ë°˜ì  í•˜ë½
        - STABLE: ì•ˆì •ì  (ë¡œí…Œì´ì…˜ ì—†ìŒ)
        """
        try:
            # ì¹´í…Œê³ ë¦¬ ì ìˆ˜
            core = category_perf.get('CORE', 50)
            growth = category_perf.get('GROWTH', 50)
            speculative = category_perf.get('SPECULATIVE', 50)
            defensive = category_perf.get('DEFENSIVE', 50)

            # ë¦¬ìŠ¤í¬ ì ìˆ˜
            low_risk = risk_perf.get('LOW', 50)
            moderate_risk = risk_perf.get('MODERATE', 50)
            high_risk = risk_perf.get('HIGH', 50) + risk_perf.get('VERY_HIGH', 50)

            # ì „ì²´ í‰ê· 
            overall_avg = np.mean(list(category_perf.values()))

            # íŒ¨í„´ ê°ì§€
            threshold = ProductionConfig.ROTATION_DETECTION_THRESHOLD * 100

            # 1. ì „ë°˜ì  ìƒìŠ¹/í•˜ë½
            if overall_avg > 65:
                return 'BROAD_RALLY'
            elif overall_avg < 35:
                return 'BROAD_DECLINE'

            # 2. ë¦¬ìŠ¤í¬ì˜¨ ë¡œí…Œì´ì…˜ (ê³µê²©ì  ì„¹í„° ê°•ì„¸)
            if (speculative > 60 and growth > 55) and defensive < 45:
                return 'RISK_ON_ROTATION'

            # 3. ë¦¬ìŠ¤í¬ì˜¤í”„ ë¡œí…Œì´ì…˜ (ë°©ì–´ì  ì„¹í„° ê°•ì„¸)
            if defensive > 60 and (speculative < 45 or growth < 45):
                return 'RISK_OFF_ROTATION'

            # 4. ì„±ì¥ì£¼ -> ê°€ì¹˜ì£¼
            if defensive > core > growth and speculative < 45:
                return 'GROWTH_TO_VALUE'

            # 5. ê°€ì¹˜ì£¼ -> ì„±ì¥ì£¼
            if growth > core > defensive and speculative > 50:
                return 'VALUE_TO_GROWTH'

            # 6. ì„¹í„° ë¶„ì‚° (í‘œì¤€í¸ì°¨ í° ê²½ìš°)
            category_std = np.std(list(category_perf.values()))
            if category_std > 15:
                return 'SECTOR_DIVERGENCE'

            # 7. ì•ˆì •ì 
            if abs(overall_avg - 50) < 10 and category_std < 10:
                return 'STABLE'

            return 'MIXED_PATTERN'

        except Exception as e:
            self.logger.error(f"Identify rotation pattern error: {e}")
            return 'UNCERTAIN'

    def _detect_risk_appetite(self, risk_perf: Dict[str, float]) -> str:
        """
        ë¦¬ìŠ¤í¬ ì„ í˜¸ë„ ê°ì§€

        Returns:
            'RISK_ON', 'RISK_OFF', 'NEUTRAL', 'TRANSITIONING'
        """
        try:
            # ê³ ìœ„í—˜ ìì‚° ì„±ê³¼
            high_risk_avg = np.mean([
                risk_perf.get('HIGH', 50),
                risk_perf.get('VERY_HIGH', 50)
            ])

            # ì €ìœ„í—˜ ìì‚° ì„±ê³¼
            low_risk_avg = np.mean([
                risk_perf.get('LOW', 50),
                risk_perf.get('LOW_MODERATE', 50)
            ])

            # ì°¨ì´
            risk_spread = high_risk_avg - low_risk_avg

            threshold = ProductionConfig.RISK_ON_OFF_THRESHOLD * 100

            if risk_spread > threshold:
                return 'RISK_ON'
            elif risk_spread < -threshold:
                return 'RISK_OFF'
            elif abs(risk_spread) < threshold * 0.5:
                return 'NEUTRAL'
            else:
                return 'TRANSITIONING'

        except Exception as e:
            self.logger.error(f"Detect risk appetite error: {e}")
            return 'NEUTRAL'

    def _detect_market_cycle(self, category_perf: Dict[str, float],
                             risk_appetite: str) -> str:
        """
        ì‹œì¥ ì‚¬ì´í´ ë‹¨ê³„ ê°ì§€

        Returns:
            'EARLY_CYCLE', 'MID_CYCLE', 'LATE_CYCLE', 'RECESSION', 'RECOVERY'
        """
        try:
            core = category_perf.get('CORE', 50)
            growth = category_perf.get('GROWTH', 50)
            speculative = category_perf.get('SPECULATIVE', 50)
            defensive = category_perf.get('DEFENSIVE', 50)

            # Early Cycle: ì½”ì–´ + ì„±ì¥ì£¼ ê°•ì„¸, ë¦¬ìŠ¤í¬ì˜¨
            if core > 55 and growth > 55 and risk_appetite == 'RISK_ON':
                return 'EARLY_CYCLE'

            # Mid Cycle: ì„±ì¥ì£¼ + íˆ¬ê¸°ì  ê°•ì„¸
            if growth > 60 and speculative > 55 and risk_appetite == 'RISK_ON':
                return 'MID_CYCLE'

            # Late Cycle: íˆ¬ê¸°ì  ê³¼ì—´, ë°©ì–´ì  ìƒìŠ¹ ì‹œì‘
            if speculative > 65 and defensive > 50 and risk_appetite in ['RISK_ON', 'TRANSITIONING']:
                return 'LATE_CYCLE'

            # Recession: ë°©ì–´ì  ê°•ì„¸, ë¦¬ìŠ¤í¬ì˜¤í”„
            if defensive > 60 and risk_appetite == 'RISK_OFF':
                return 'RECESSION'

            # Recovery: ë°©ì–´ì ì—ì„œ ì½”ì–´ë¡œ ì „í™˜
            if defensive > 50 and core > 52 and risk_appetite in ['NEUTRAL', 'TRANSITIONING']:
                return 'RECOVERY'

            return 'UNCERTAIN'

        except Exception as e:
            self.logger.error(f"Detect market cycle error: {e}")
            return 'UNCERTAIN'

    def _detect_momentum_shifts(self, performances: Dict[str, Dict]) -> List[Dict]:
        """
        ëª¨ë©˜í…€ ì „í™˜ ê°ì§€ (ê¸‰ë“±/ê¸‰ë½ ì„¹í„°)
        """
        shifts = []

        for sector_id, perf in performances.items():
            momentum = perf.get('momentum', 0)
            relative_strength = perf.get('relative_strength', 50)

            # ê°•í•œ ì–‘ì˜ ëª¨ë©˜í…€
            if momentum > 0.05 and relative_strength > 60:
                shifts.append({
                    'sector_id': sector_id,
                    'type': 'STRONG_POSITIVE',
                    'momentum': momentum,
                    'relative_strength': relative_strength
                })

            # ê°•í•œ ìŒì˜ ëª¨ë©˜í…€
            elif momentum < -0.05 and relative_strength < 40:
                shifts.append({
                    'sector_id': sector_id,
                    'type': 'STRONG_NEGATIVE',
                    'momentum': momentum,
                    'relative_strength': relative_strength
                })

        # ëª¨ë©˜í…€ í¬ê¸° ìˆœ ì •ë ¬
        shifts.sort(key=lambda x: abs(x['momentum']), reverse=True)

        return shifts

    def _identify_hot_sectors(self, performances: Dict[str, Dict]) -> List[Dict]:
        """í•« ì„¹í„° ì‹ë³„ (ìƒìœ„ Nê°œ)"""
        # ìƒëŒ€ ê°•ë„ ê¸°ì¤€ ì •ë ¬
        sorted_sectors = sorted(
            performances.items(),
            key=lambda x: x[1].get('relative_strength', 0),
            reverse=True
        )

        hot_sectors = []
        for i, (sector_id, perf) in enumerate(sorted_sectors[:ProductionConfig.HOT_SECTOR_TOP_N]):
            sector_info = self.sector_defs.get_sector_info(sector_id)

            hot_sectors.append({
                'rank': i + 1,
                'sector_id': sector_id,
                'sector_name': sector_info.get('name', sector_id),
                'relative_strength': perf.get('relative_strength', 0),
                'total_return': perf.get('total_return', 0),
                'momentum': perf.get('momentum', 0),
                'category': sector_info.get('category', 'UNKNOWN')
            })

        return hot_sectors

    def _identify_weak_sectors(self, performances: Dict[str, Dict]) -> List[Dict]:
        """ì•½ì„¸ ì„¹í„° ì‹ë³„ (í•˜ìœ„ Nê°œ)"""
        # ìƒëŒ€ ê°•ë„ ê¸°ì¤€ ì •ë ¬
        sorted_sectors = sorted(
            performances.items(),
            key=lambda x: x[1].get('relative_strength', 0)
        )

        weak_sectors = []
        for i, (sector_id, perf) in enumerate(sorted_sectors[:ProductionConfig.HOT_SECTOR_TOP_N]):
            sector_info = self.sector_defs.get_sector_info(sector_id)

            weak_sectors.append({
                'rank': i + 1,
                'sector_id': sector_id,
                'sector_name': sector_info.get('name', sector_id),
                'relative_strength': perf.get('relative_strength', 0),
                'total_return': perf.get('total_return', 0),
                'momentum': perf.get('momentum', 0),
                'category': sector_info.get('category', 'UNKNOWN')
            })

        return weak_sectors

    def predict_next_rotation(self) -> Dict[str, Any]:
        """
        ë‹¤ìŒ ë¡œí…Œì´ì…˜ ì˜ˆì¸¡

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼
        """
        try:
            if len(self.rotation_history) < 5:
                return {
                    'prediction': 'INSUFFICIENT_DATA',
                    'confidence': 0.0,
                    'timestamp': datetime.now()
                }

            # ìµœê·¼ ë¡œí…Œì´ì…˜ íŒ¨í„´ ë¶„ì„
            recent_patterns = [
                h['rotation_pattern'] for h in list(self.rotation_history)[-5:]
            ]

            recent_risk = [
                h['risk_appetite'] for h in list(self.rotation_history)[-5:]
            ]

            recent_cycle = [
                h['cycle_phase'] for h in list(self.rotation_history)[-5:]
            ]

            # íŒ¨í„´ ë¹ˆë„
            from collections import Counter
            pattern_freq = Counter(recent_patterns)
            risk_freq = Counter(recent_risk)
            cycle_freq = Counter(recent_cycle)

            # í˜„ì¬ ìƒíƒœ
            current = self.rotation_history[-1]
            current_pattern = current['rotation_pattern']
            current_risk = current['risk_appetite']
            current_cycle = current['cycle_phase']

            # ì „í™˜ ë¡œì§
            predicted_pattern = self._predict_pattern_transition(
                current_pattern, current_risk, current_cycle
            )

            predicted_hot_categories = self._predict_hot_categories(
                predicted_pattern, current_cycle
            )

            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = self._calculate_prediction_confidence(
                pattern_freq, risk_freq, cycle_freq
            )

            return {
                'current_state': {
                    'pattern': current_pattern,
                    'risk_appetite': current_risk,
                    'cycle_phase': current_cycle
                },
                'predicted_pattern': predicted_pattern,
                'predicted_hot_categories': predicted_hot_categories,
                'confidence': float(confidence),
                'reasoning': self._generate_prediction_reasoning(
                    current_pattern, predicted_pattern, current_cycle
                ),
                'timestamp': datetime.now()
            }

        except Exception as e:
            self.logger.error(f"Predict next rotation error: {e}")
            return {
                'prediction': 'ERROR',
                'confidence': 0.0,
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def _predict_pattern_transition(self, current_pattern: str,
                                    current_risk: str,
                                    current_cycle: str) -> str:
        """íŒ¨í„´ ì „í™˜ ì˜ˆì¸¡"""
        # ì „í™˜ ë£° ê¸°ë°˜ ì˜ˆì¸¡

        if current_cycle == 'EARLY_CYCLE':
            if current_risk == 'RISK_ON':
                return 'VALUE_TO_GROWTH'
            else:
                return 'BROAD_RALLY'

        elif current_cycle == 'MID_CYCLE':
            if current_pattern == 'VALUE_TO_GROWTH':
                return 'RISK_ON_ROTATION'
            else:
                return 'BROAD_RALLY'

        elif current_cycle == 'LATE_CYCLE':
            if current_risk == 'RISK_ON':
                return 'RISK_OFF_ROTATION'
            else:
                return 'GROWTH_TO_VALUE'

        elif current_cycle == 'RECESSION':
            return 'RISK_OFF_ROTATION'

        elif current_cycle == 'RECOVERY':
            return 'VALUE_TO_GROWTH'

        else:
            return 'MIXED_PATTERN'

    def _predict_hot_categories(self, predicted_pattern: str,
                                current_cycle: str) -> List[str]:
        """ì˜ˆìƒ í•« ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡"""
        if predicted_pattern in ['RISK_ON_ROTATION', 'VALUE_TO_GROWTH']:
            return ['GROWTH', 'SPECULATIVE']

        elif predicted_pattern in ['RISK_OFF_ROTATION', 'GROWTH_TO_VALUE']:
            return ['DEFENSIVE', 'CORE']

        elif predicted_pattern == 'BROAD_RALLY':
            return ['CORE', 'GROWTH']

        elif current_cycle in ['EARLY_CYCLE', 'RECOVERY']:
            return ['CORE', 'GROWTH']

        elif current_cycle == 'MID_CYCLE':
            return ['GROWTH', 'SPECULATIVE']

        elif current_cycle == 'LATE_CYCLE':
            return ['DEFENSIVE', 'CORE']

        else:
            return ['CORE']

    def _calculate_prediction_confidence(self, pattern_freq: Counter,
                                         risk_freq: Counter,
                                         cycle_freq: Counter) -> float:
        """ì˜ˆì¸¡ ì‹ ë¢°ë„ ê³„ì‚°"""
        # ìµœë¹ˆê°’ì˜ ë¹ˆë„ ë¹„ìœ¨
        max_pattern_freq = max(pattern_freq.values()) if pattern_freq else 0
        max_risk_freq = max(risk_freq.values()) if risk_freq else 0
        max_cycle_freq = max(cycle_freq.values()) if cycle_freq else 0

        total = len(self.rotation_history)

        if total == 0:
            return 0.0

        confidence = (
                0.4 * (max_pattern_freq / min(total, 5)) +
                0.3 * (max_risk_freq / min(total, 5)) +
                0.3 * (max_cycle_freq / min(total, 5))
        )

        return np.clip(confidence, 0.0, 1.0)

    def _generate_prediction_reasoning(self, current_pattern: str,
                                       predicted_pattern: str,
                                       current_cycle: str) -> str:
        """ì˜ˆì¸¡ ê·¼ê±° ìƒì„±"""
        reasoning = f"Current pattern is {current_pattern} in {current_cycle} phase. "

        if predicted_pattern != current_pattern:
            reasoning += f"Expecting transition to {predicted_pattern} based on cycle dynamics."
        else:
            reasoning += f"Pattern likely to persist in current cycle phase."

        return reasoning

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'errors': self.error_count,
            'error_rate': error_rate,
            'history_size': len(self.rotation_history),
            'current_rotation_state': self.current_rotation_state,
            'current_risk_appetite': self.current_risk_appetite,
            'current_cycle_phase': self.current_cycle_phase
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# END OF PART 3/8
# ë‹¤ìŒ: Part 4 - Sector Allocation Optimizer & Signal Generator
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ğŸ”¥ğŸ”¥ MARKET REGIME ANALYZER 13.0 - PART 4/8 ğŸ”¥ğŸ”¥ğŸ”¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Part 4: Sector Allocation Optimizer & Signal Generator
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Part 3ì—ì„œ ê³„ì†...

class SectorAllocationOptimizer:
    """
    ğŸª ì„¹í„° ë°°ë¶„ ìµœì í™”ê¸° (v13.0 NEW - í”„ë¡œë•ì…˜ ë ˆë²¨)

    ì‹œì¥ ìƒí™©ì— ë§ëŠ” ìµœì  ì„¹í„° ë°°ë¶„ ê¶Œê³ 
    """

    def __init__(self, sector_rotation_detector: SectorRotationDetector,
                 sector_performance_analyzer: SectorPerformanceAnalyzer,
                 sector_definitions: SectorDefinitions):
        self.rotation_detector = sector_rotation_detector
        self.sector_perf = sector_performance_analyzer
        self.sector_defs = sector_definitions
        self.logger = get_logger("SectorAllocationOptimizer")
        self.validator = DataValidator()

        # ë°°ë¶„ íˆìŠ¤í† ë¦¬
        self.allocation_history = deque(maxlen=500)

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.api_call_count = 0
        self.error_count = 0

    def optimize_allocation(self, total_capital: float = 1.0,
                            risk_tolerance: str = 'MODERATE',
                            constraints: Optional[Dict] = None) -> Dict[str, Any]:
        """
        ìµœì  ì„¹í„° ë°°ë¶„ ê³„ì‚°

        Args:
            total_capital: ì´ ìë³¸ (1.0 = 100%)
            risk_tolerance: ë¦¬ìŠ¤í¬ í—ˆìš©ë„ ('CONSERVATIVE', 'MODERATE', 'AGGRESSIVE')
            constraints: ì œì•½ ì¡°ê±´ {'max_per_sector': 0.3, 'min_diversification': 3, ...}

        Returns:
            ìµœì  ë°°ë¶„ ê²°ê³¼
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            # ê¸°ë³¸ ì œì•½ ì¡°ê±´
            if constraints is None:
                constraints = {}

            max_per_sector = constraints.get('max_per_sector', 0.30)
            min_per_sector = constraints.get('min_per_sector', 0.05)
            min_diversification = constraints.get('min_diversification', 3)

            # í˜„ì¬ ë¡œí…Œì´ì…˜ ìƒíƒœ
            rotation_state = self.rotation_detector.detect_sector_rotation()

            # ì„¹í„° ì„±ê³¼
            performances = rotation_state.get('sector_performances', {})

            if not performances:
                raise ValueError("No sector performance data available")

            # ë¦¬ìŠ¤í¬ í—ˆìš©ë„ì— ë”°ë¥¸ ë°°ë¶„ ì „ëµ
            allocation_strategy = self._determine_allocation_strategy(
                risk_tolerance, rotation_state
            )

            # ì´ˆê¸° ë°°ë¶„ ê³„ì‚°
            raw_allocation = self._calculate_raw_allocation(
                performances, rotation_state, allocation_strategy
            )

            # ì œì•½ ì¡°ê±´ ì ìš©
            constrained_allocation = self._apply_constraints(
                raw_allocation,
                max_per_sector,
                min_per_sector,
                min_diversification,
                total_capital
            )

            # ë¦¬ìŠ¤í¬ ë¶„ì„
            portfolio_risk = self._calculate_portfolio_risk(
                constrained_allocation, performances
            )

            # ì˜ˆìƒ ìˆ˜ìµë¥ 
            expected_return = self._calculate_expected_return(
                constrained_allocation, performances
            )

            # ë‹¤ê°í™” ì§€ìˆ˜
            diversification_score = self._calculate_diversification_score(
                constrained_allocation
            )

            result = {
                'allocation': constrained_allocation,
                'allocation_strategy': allocation_strategy,
                'expected_return': float(expected_return),
                'portfolio_risk': portfolio_risk,
                'diversification_score': float(diversification_score),
                'risk_tolerance': risk_tolerance,
                'rotation_state': rotation_state['rotation_pattern'],
                'risk_appetite': rotation_state['risk_appetite'],
                'cycle_phase': rotation_state['cycle_phase'],
                'constraints': {
                    'max_per_sector': max_per_sector,
                    'min_per_sector': min_per_sector,
                    'min_diversification': min_diversification
                },
                'timestamp': datetime.now()
            }

            # íˆìŠ¤í† ë¦¬
            self.allocation_history.append(result)

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('optimize_allocation', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Allocation optimization error: {e}")
            performance_monitor.record_error('optimize_allocation', e)

            # í´ë°±: ê· ë“± ë°°ë¶„
            return self._get_fallback_allocation(total_capital)

    def _determine_allocation_strategy(self, risk_tolerance: str,
                                       rotation_state: Dict) -> str:
        """
        ë°°ë¶„ ì „ëµ ê²°ì •

        Returns:
            'MOMENTUM', 'BALANCED', 'DEFENSIVE', 'CONTRARIAN'
        """
        rotation_pattern = rotation_state.get('rotation_pattern', 'STABLE')
        risk_appetite = rotation_state.get('risk_appetite', 'NEUTRAL')
        cycle_phase = rotation_state.get('cycle_phase', 'UNCERTAIN')

        # ë³´ìˆ˜ì  íˆ¬ìì
        if risk_tolerance == 'CONSERVATIVE':
            if risk_appetite == 'RISK_OFF':
                return 'DEFENSIVE'
            else:
                return 'BALANCED'

        # ê³µê²©ì  íˆ¬ìì
        elif risk_tolerance == 'AGGRESSIVE':
            if rotation_pattern in ['RISK_ON_ROTATION', 'VALUE_TO_GROWTH']:
                return 'MOMENTUM'
            elif cycle_phase == 'LATE_CYCLE':
                return 'BALANCED'  # ê³¼ì—´ ë°©ì§€
            else:
                return 'MOMENTUM'

        # ì¤‘ë„ íˆ¬ìì
        else:  # MODERATE
            if rotation_pattern == 'BROAD_RALLY':
                return 'MOMENTUM'
            elif rotation_pattern == 'BROAD_DECLINE':
                return 'DEFENSIVE'
            elif cycle_phase in ['LATE_CYCLE', 'RECESSION']:
                return 'DEFENSIVE'
            elif cycle_phase == 'EARLY_CYCLE':
                return 'MOMENTUM'
            else:
                return 'BALANCED'

    def _calculate_raw_allocation(self, performances: Dict[str, Dict],
                                  rotation_state: Dict,
                                  strategy: str) -> Dict[str, float]:
        """ì›ì‹œ ë°°ë¶„ ê³„ì‚° (ì œì•½ ì¡°ê±´ ì ìš© ì „)"""
        allocations = {}

        if strategy == 'MOMENTUM':
            # ëª¨ë©˜í…€ ê¸°ë°˜: ìƒëŒ€ ê°•ë„ì— ë¹„ë¡€ ë°°ë¶„
            total_rs = sum(p.get('relative_strength', 50) for p in performances.values())

            for sector_id, perf in performances.items():
                rs = perf.get('relative_strength', 50)
                allocations[sector_id] = rs / total_rs if total_rs > 0 else 0

        elif strategy == 'DEFENSIVE':
            # ë°©ì–´ì : ì €ìœ„í—˜ ì„¹í„°ì— ì§‘ì¤‘
            for sector_id, perf in performances.items():
                sector_info = self.sector_defs.get_sector_info(sector_id)
                risk_profile = sector_info.get('risk_profile', 'MODERATE')
                category = sector_info.get('category', 'CORE')

                # ë°©ì–´ì  ì¹´í…Œê³ ë¦¬ ìš°ëŒ€
                if category == 'DEFENSIVE':
                    weight = 0.40
                elif category == 'CORE':
                    weight = 0.35
                elif risk_profile in ['LOW', 'LOW_MODERATE']:
                    weight = 0.20
                else:
                    weight = 0.05

                allocations[sector_id] = weight

        elif strategy == 'BALANCED':
            # ê· í˜•: ì¹´í…Œê³ ë¦¬ë³„ í‘œì¤€ ë°°ë¶„
            for sector_id, perf in performances.items():
                sector_info = self.sector_defs.get_sector_info(sector_id)
                category = sector_info.get('category', 'CORE')

                # ì¹´í…Œê³ ë¦¬ í‘œì¤€ ë°°ë¶„
                category_defs = self.sector_defs.sector_categories
                typical_allocation = category_defs.get(category, {}).get('typical_allocation', 0.25)

                # ì„±ê³¼ì— ë”°ë¼ ì¡°ì •
                rs = perf.get('relative_strength', 50)
                adjustment = (rs - 50) / 100  # -0.5 ~ +0.5

                allocations[sector_id] = typical_allocation * (1 + adjustment)

        elif strategy == 'CONTRARIAN':
            # ì—­ë°œìƒ: ì•½ì„¸ ì„¹í„°ì— ë°°ë¶„ (í‰ê·  íšŒê·€ ì „ëµ)
            # ìƒëŒ€ ê°•ë„ ì—­ìˆœ
            total_inverse_rs = sum(100 - p.get('relative_strength', 50) for p in performances.values())

            for sector_id, perf in performances.items():
                inverse_rs = 100 - perf.get('relative_strength', 50)
                allocations[sector_id] = inverse_rs / total_inverse_rs if total_inverse_rs > 0 else 0

        else:
            # ê¸°ë³¸: ê· ë“± ë°°ë¶„
            n = len(performances)
            for sector_id in performances:
                allocations[sector_id] = 1.0 / n if n > 0 else 0

        # ì •ê·œí™”
        total = sum(allocations.values())
        if total > 0:
            allocations = {k: v / total for k, v in allocations.items()}

        return allocations

    def _apply_constraints(self, raw_allocation: Dict[str, float],
                           max_per_sector: float,
                           min_per_sector: float,
                           min_diversification: int,
                           total_capital: float) -> Dict[str, float]:
        """ì œì•½ ì¡°ê±´ ì ìš©"""
        # 1. ìµœëŒ€/ìµœì†Œ ì œì•½
        constrained = {}
        overflow = 0.0

        for sector_id, weight in raw_allocation.items():
            if weight > max_per_sector:
                constrained[sector_id] = max_per_sector
                overflow += (weight - max_per_sector)
            elif weight < min_per_sector:
                # ë„ˆë¬´ ì‘ìœ¼ë©´ 0ìœ¼ë¡œ
                overflow += weight
                constrained[sector_id] = 0.0
            else:
                constrained[sector_id] = weight

        # 2. ì˜¤ë²„í”Œë¡œìš° ì¬ë¶„ë°°
        if overflow > 0:
            # ì œì•½ ë¯¸ë„ë‹¬ ì„¹í„°ì— ì¬ë¶„ë°°
            available_sectors = {
                k: v for k, v in constrained.items()
                if v < max_per_sector and v > 0
            }

            if available_sectors:
                total_available = sum(available_sectors.values())
                for sector_id in available_sectors:
                    additional = overflow * (constrained[sector_id] / total_available)
                    constrained[sector_id] = min(
                        constrained[sector_id] + additional,
                        max_per_sector
                    )

        # 3. ìµœì†Œ ë‹¤ê°í™” ì¡°ê±´
        non_zero_sectors = {k: v for k, v in constrained.items() if v > 0}

        if len(non_zero_sectors) < min_diversification:
            # ì¶”ê°€ ì„¹í„° í¬í•¨
            zero_sectors = {k: v for k, v in raw_allocation.items() if constrained.get(k, 0) == 0}

            # ì›ì‹œ ë°°ë¶„ ë†’ì€ ìˆœìœ¼ë¡œ ì¶”ê°€
            sorted_zero = sorted(zero_sectors.items(), key=lambda x: x[1], reverse=True)

            for i in range(min(min_diversification - len(non_zero_sectors), len(sorted_zero))):
                sector_id, _ = sorted_zero[i]
                constrained[sector_id] = min_per_sector

        # 4. ì¬ì •ê·œí™”
        total = sum(constrained.values())
        if total > 0:
            constrained = {k: (v / total) * total_capital for k, v in constrained.items()}

        # 5. ì œë¡œ ì œê±°
        constrained = {k: v for k, v in constrained.items() if v > 1e-6}

        return constrained

    def _calculate_portfolio_risk(self, allocation: Dict[str, float],
                                  performances: Dict[str, Dict]) -> Dict[str, Any]:
        """í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ê³„ì‚°"""
        try:
            # ê°€ì¤‘ í‰ê·  ë³€ë™ì„±
            total_volatility = 0.0
            total_max_dd = 0.0

            for sector_id, weight in allocation.items():
                perf = performances.get(sector_id, {})
                volatility = perf.get('volatility', 0.02)
                max_dd = abs(perf.get('max_drawdown', 0.0))

                total_volatility += weight * volatility
                total_max_dd += weight * max_dd

            # ë¦¬ìŠ¤í¬ í”„ë¡œíŒŒì¼ ë¶„í¬
            risk_distribution = defaultdict(float)

            for sector_id, weight in allocation.items():
                sector_info = self.sector_defs.get_sector_info(sector_id)
                risk_profile = sector_info.get('risk_profile', 'MODERATE')
                risk_distribution[risk_profile] += weight

            return {
                'weighted_volatility': float(total_volatility),
                'weighted_max_drawdown': float(total_max_dd),
                'risk_distribution': dict(risk_distribution)
            }

        except Exception as e:
            self.logger.error(f"Portfolio risk calculation error: {e}")
            return {
                'weighted_volatility': 0.0,
                'weighted_max_drawdown': 0.0,
                'risk_distribution': {}
            }

    def _calculate_expected_return(self, allocation: Dict[str, float],
                                   performances: Dict[str, Dict]) -> float:
        """í¬íŠ¸í´ë¦¬ì˜¤ ì˜ˆìƒ ìˆ˜ìµë¥ """
        try:
            expected_return = 0.0

            for sector_id, weight in allocation.items():
                perf = performances.get(sector_id, {})
                sector_return = perf.get('total_return', 0.0)
                expected_return += weight * sector_return

            return expected_return

        except Exception as e:
            self.logger.error(f"Expected return calculation error: {e}")
            return 0.0

    def _calculate_diversification_score(self, allocation: Dict[str, float]) -> float:
        """
        ë‹¤ê°í™” ì ìˆ˜ ê³„ì‚° (0~1)

        í—ˆí•€ë‹¬ ì§€ìˆ˜ ê¸°ë°˜: 1 - HHI
        """
        try:
            if not allocation:
                return 0.0

            # í—ˆí•€ë‹¬ ì§€ìˆ˜ (HHI)
            hhi = sum(w ** 2 for w in allocation.values())

            # ë‹¤ê°í™” ì ìˆ˜ (HHIê°€ ë‚®ì„ìˆ˜ë¡ ë‹¤ê°í™”ê°€ ì˜ ë¨)
            diversification = 1.0 - hhi

            return diversification

        except Exception as e:
            self.logger.error(f"Diversification score calculation error: {e}")
            return 0.0

    def _get_fallback_allocation(self, total_capital: float) -> Dict[str, Any]:
        """í´ë°± ë°°ë¶„ (ì—ëŸ¬ ì‹œ)"""
        # ì½”ì–´ ì„¹í„°ì—ë§Œ ê· ë“± ë°°ë¶„
        core_sectors = self.sector_defs.get_sectors_by_category('CORE')

        allocation = {}
        if core_sectors:
            weight = total_capital / len(core_sectors)
            for sector_id in core_sectors:
                allocation[sector_id] = weight

        return {
            'allocation': allocation,
            'allocation_strategy': 'FALLBACK_EQUAL_WEIGHT',
            'expected_return': 0.0,
            'portfolio_risk': {'weighted_volatility': 0.0},
            'diversification_score': 0.5,
            'timestamp': datetime.now(),
            'error': 'Fallback allocation due to optimization error'
        }

    def rebalance_check(self, current_allocation: Dict[str, float],
                        target_allocation: Dict[str, float],
                        threshold: float = 0.05) -> Dict[str, Any]:
        """
        ë¦¬ë°¸ëŸ°ì‹± í•„ìš” ì—¬ë¶€ ì²´í¬

        Args:
            current_allocation: í˜„ì¬ ë°°ë¶„
            target_allocation: ëª©í‘œ ë°°ë¶„
            threshold: ë¦¬ë°¸ëŸ°ì‹± ì„ê³„ê°’ (5% ì°¨ì´ ì‹œ)

        Returns:
            ë¦¬ë°¸ëŸ°ì‹± ê¶Œê³ 
        """
        try:
            rebalance_needed = False
            rebalance_actions = []

            all_sectors = set(current_allocation.keys()) | set(target_allocation.keys())

            for sector_id in all_sectors:
                current = current_allocation.get(sector_id, 0.0)
                target = target_allocation.get(sector_id, 0.0)

                diff = target - current

                if abs(diff) > threshold:
                    rebalance_needed = True

                    action = 'BUY' if diff > 0 else 'SELL'
                    amount = abs(diff)

                    rebalance_actions.append({
                        'sector_id': sector_id,
                        'action': action,
                        'current_weight': float(current),
                        'target_weight': float(target),
                        'adjustment_amount': float(amount)
                    })

            # ì•¡ì…˜ ì •ë ¬ (ì¡°ì • í¬ê¸° ìˆœ)
            rebalance_actions.sort(key=lambda x: x['adjustment_amount'], reverse=True)

            return {
                'rebalance_needed': rebalance_needed,
                'threshold': threshold,
                'actions': rebalance_actions,
                'total_adjustment': sum(a['adjustment_amount'] for a in rebalance_actions),
                'timestamp': datetime.now()
            }

        except Exception as e:
            self.logger.error(f"Rebalance check error: {e}")
            return {
                'rebalance_needed': False,
                'actions': [],
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'errors': self.error_count,
            'error_rate': error_rate,
            'history_size': len(self.allocation_history)
        }


class SectorRotationSignalGenerator:
    """
    âš¡ ì„¹í„° ë¡œí…Œì´ì…˜ ì‹ í˜¸ ìƒì„±ê¸° (v13.0 NEW - í”„ë¡œë•ì…˜ ë ˆë²¨)

    ê±°ë˜ ì‹ í˜¸ ë° ê²½ë³´ ìƒì„±
    """

    def __init__(self, sector_rotation_detector: SectorRotationDetector,
                 sector_allocation_optimizer: SectorAllocationOptimizer):
        self.rotation_detector = sector_rotation_detector
        self.allocation_optimizer = sector_allocation_optimizer
        self.logger = get_logger("SectorRotationSignalGenerator")

        # ì‹ í˜¸ íˆìŠ¤í† ë¦¬
        self.signal_history = deque(maxlen=1000)

        # ê²½ë³´ ìƒíƒœ
        self.active_alerts = []
        self.last_alert_time = {}

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.api_call_count = 0
        self.error_count = 0

    def generate_signals(self, lookback_days: int = 7) -> Dict[str, Any]:
        """
        ê±°ë˜ ì‹ í˜¸ ìƒì„±

        Args:
            lookback_days: ë¶„ì„ ê¸°ê°„

        Returns:
            ì‹ í˜¸ ê²°ê³¼
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            # ë¡œí…Œì´ì…˜ ê°ì§€
            rotation_state = self.rotation_detector.detect_sector_rotation(lookback_days)

            # ë‹¤ìŒ ë¡œí…Œì´ì…˜ ì˜ˆì¸¡
            next_rotation = self.rotation_detector.predict_next_rotation()

            # í•« ì„¹í„°
            hot_sectors = rotation_state.get('hot_sectors', [])

            # ì•½ì„¸ ì„¹í„°
            weak_sectors = rotation_state.get('weak_sectors', [])

            # ëª¨ë©˜í…€ ì „í™˜
            momentum_shifts = rotation_state.get('momentum_shifts', [])

            # ì‹ í˜¸ ìƒì„±
            signals = self._generate_sector_signals(
                hot_sectors, weak_sectors, momentum_shifts, rotation_state, next_rotation
            )

            # ì‹ í˜¸ ê°•ë„ ê³„ì‚°
            overall_signal_strength = self._calculate_overall_signal_strength(signals)

            # ê²½ë³´ ìƒì„±
            alerts = self._generate_alerts(rotation_state, next_rotation, signals)

            # ê¶Œê³  ì‚¬í•­
            recommendations = self._generate_recommendations(
                rotation_state, next_rotation, signals
            )

            result = {
                'signals': signals,
                'overall_signal_strength': overall_signal_strength,
                'alerts': alerts,
                'recommendations': recommendations,
                'rotation_state': rotation_state,
                'next_rotation_prediction': next_rotation,
                'confidence': next_rotation.get('confidence', 0.0),
                'timestamp': datetime.now()
            }

            # íˆìŠ¤í† ë¦¬
            self.signal_history.append(result)

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('generate_signals', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Signal generation error: {e}")
            performance_monitor.record_error('generate_signals', e)

            return {
                'signals': [],
                'overall_signal_strength': 0.0,
                'alerts': [],
                'recommendations': [],
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def _generate_sector_signals(self, hot_sectors: List[Dict],
                                 weak_sectors: List[Dict],
                                 momentum_shifts: List[Dict],
                                 rotation_state: Dict,
                                 next_rotation: Dict) -> List[Dict]:
        """ê°œë³„ ì„¹í„° ì‹ í˜¸ ìƒì„±"""
        signals = []

        # í•« ì„¹í„° - ë§¤ìˆ˜ ì‹ í˜¸
        for hot in hot_sectors[:3]:  # ìƒìœ„ 3ê°œ
            signal = {
                'sector_id': hot['sector_id'],
                'sector_name': hot['sector_name'],
                'signal_type': 'BUY',
                'strength': 'STRONG' if hot['relative_strength'] > 70 else 'MODERATE',
                'reason': f"Leading sector with RS={hot['relative_strength']:.1f}",
                'relative_strength': hot['relative_strength'],
                'momentum': hot.get('momentum', 0.0)
            }
            signals.append(signal)

        # ì•½ì„¸ ì„¹í„° - ë§¤ë„/íšŒí”¼ ì‹ í˜¸
        for weak in weak_sectors[:2]:  # í•˜ìœ„ 2ê°œ
            signal = {
                'sector_id': weak['sector_id'],
                'sector_name': weak['sector_name'],
                'signal_type': 'SELL',
                'strength': 'STRONG' if weak['relative_strength'] < 30 else 'MODERATE',
                'reason': f"Lagging sector with RS={weak['relative_strength']:.1f}",
                'relative_strength': weak['relative_strength'],
                'momentum': weak.get('momentum', 0.0)
            }
            signals.append(signal)

        # ëª¨ë©˜í…€ ì „í™˜ - ì¶”ì„¸ ì „í™˜ ì‹ í˜¸
        for shift in momentum_shifts[:3]:
            if shift['type'] == 'STRONG_POSITIVE':
                signal = {
                    'sector_id': shift['sector_id'],
                    'signal_type': 'BUY',
                    'strength': 'STRONG',
                    'reason': f"Strong positive momentum shift ({shift['momentum']:.3f})",
                    'momentum': shift['momentum']
                }
                signals.append(signal)

        return signals

    def _calculate_overall_signal_strength(self, signals: List[Dict]) -> float:
        """ì „ì²´ ì‹ í˜¸ ê°•ë„ ê³„ì‚°"""
        if not signals:
            return 0.0

        # ê°•ë„ ì ìˆ˜í™”
        strength_scores = {
            'STRONG': 1.0,
            'MODERATE': 0.6,
            'WEAK': 0.3
        }

        total_score = 0.0
        for signal in signals:
            strength = signal.get('strength', 'WEAK')
            score = strength_scores.get(strength, 0.3)

            # ë§¤ìˆ˜ëŠ” ì–‘ìˆ˜, ë§¤ë„ëŠ” ìŒìˆ˜
            if signal['signal_type'] == 'BUY':
                total_score += score
            elif signal['signal_type'] == 'SELL':
                total_score -= score

        # ì •ê·œí™” (-1 ~ +1)
        max_score = len(signals) * 1.0
        normalized = total_score / max_score if max_score > 0 else 0.0

        return np.clip(normalized, -1.0, 1.0)

    def _generate_alerts(self, rotation_state: Dict,
                         next_rotation: Dict,
                         signals: List[Dict]) -> List[Dict]:
        """ê²½ë³´ ìƒì„±"""
        alerts = []

        # 1. ë¡œí…Œì´ì…˜ ì „í™˜ ê²½ë³´
        rotation_pattern = rotation_state.get('rotation_pattern')
        predicted_pattern = next_rotation.get('predicted_pattern')
        confidence = next_rotation.get('confidence', 0.0)

        if predicted_pattern and predicted_pattern != rotation_pattern and confidence > 0.7:
            alerts.append({
                'type': 'ROTATION_SHIFT',
                'severity': 'HIGH',
                'message': f"Sector rotation shifting from {rotation_pattern} to {predicted_pattern}",
                'confidence': confidence,
                'timestamp': datetime.now()
            })

        # 2. ë¦¬ìŠ¤í¬ì˜¨/ì˜¤í”„ ì „í™˜
        risk_appetite = rotation_state.get('risk_appetite')

        if risk_appetite in ['RISK_ON', 'RISK_OFF']:
            alerts.append({
                'type': 'RISK_APPETITE_CHANGE',
                'severity': 'MEDIUM',
                'message': f"Market risk appetite: {risk_appetite}",
                'timestamp': datetime.now()
            })

        # 3. ì‚¬ì´í´ ì „í™˜
        cycle_phase = rotation_state.get('cycle_phase')

        if cycle_phase in ['LATE_CYCLE', 'RECESSION']:
            alerts.append({
                'type': 'CYCLE_WARNING',
                'severity': 'HIGH',
                'message': f"Market in {cycle_phase} - exercise caution",
                'timestamp': datetime.now()
            })

        # 4. ê°•í•œ ì‹ í˜¸
        strong_signals = [s for s in signals if s.get('strength') == 'STRONG']

        if len(strong_signals) >= 3:
            alerts.append({
                'type': 'MULTIPLE_STRONG_SIGNALS',
                'severity': 'MEDIUM',
                'message': f"{len(strong_signals)} strong sector signals detected",
                'timestamp': datetime.now()
            })

        return alerts

    def _generate_recommendations(self, rotation_state: Dict,
                                  next_rotation: Dict,
                                  signals: List[Dict]) -> List[str]:
        """íˆ¬ì ê¶Œê³  ìƒì„±"""
        recommendations = []

        rotation_pattern = rotation_state.get('rotation_pattern')
        risk_appetite = rotation_state.get('risk_appetite')
        cycle_phase = rotation_state.get('cycle_phase')

        # ë¡œí…Œì´ì…˜ ê¸°ë°˜ ê¶Œê³ 
        if rotation_pattern == 'RISK_ON_ROTATION':
            recommendations.append("Consider increasing allocation to growth and speculative sectors")

        elif rotation_pattern == 'RISK_OFF_ROTATION':
            recommendations.append("Shift towards defensive sectors and reduce high-risk exposure")

        elif rotation_pattern == 'BROAD_RALLY':
            recommendations.append("Maintain diversified exposure across sectors")

        elif rotation_pattern == 'BROAD_DECLINE':
            recommendations.append("Consider reducing overall crypto exposure or increase defensive allocation")

        # ì‚¬ì´í´ ê¸°ë°˜ ê¶Œê³ 
        if cycle_phase == 'EARLY_CYCLE':
            recommendations.append("Focus on quality core and growth sectors")

        elif cycle_phase == 'LATE_CYCLE':
            recommendations.append("Take profits on speculative positions and increase defensive allocation")

        elif cycle_phase == 'RECESSION':
            recommendations.append("Prioritize capital preservation with defensive sectors")

        # ì˜ˆì¸¡ ê¸°ë°˜ ê¶Œê³ 
        predicted_hot_categories = next_rotation.get('predicted_hot_categories', [])
        if predicted_hot_categories:
            categories_str = ', '.join(predicted_hot_categories)
            recommendations.append(f"Prepare for rotation into: {categories_str}")

        # ì‹ í˜¸ ê¸°ë°˜ ê¶Œê³ 
        buy_signals = [s for s in signals if s['signal_type'] == 'BUY']
        sell_signals = [s for s in signals if s['signal_type'] == 'SELL']

        if len(buy_signals) > len(sell_signals):
            recommendations.append("Net positive signals - consider increasing exposure")
        elif len(sell_signals) > len(buy_signals):
            recommendations.append("Net negative signals - consider reducing exposure")

        return recommendations

    def get_active_alerts(self) -> List[Dict]:
        """í™œì„± ê²½ë³´ ëª©ë¡"""
        cutoff_time = datetime.now() - timedelta(hours=1)

        active = [
            alert for alert in self.active_alerts
            if alert.get('timestamp', datetime.min) > cutoff_time
        ]

        return active

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'errors': self.error_count,
            'error_rate': error_rate,
            'history_size': len(self.signal_history),
            'active_alerts': len(self.active_alerts)
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# END OF PART 4/8
# ë‹¤ìŒ: Part 5 - Integrated Sector Rotation Monitor
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ğŸ”¥ğŸ”¥ MARKET REGIME ANALYZER 13.0 - PART 5/8 ğŸ”¥ğŸ”¥ğŸ”¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Part 5: Integrated Sector Rotation Monitor (í†µí•© ëª¨ë‹ˆí„°)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Part 4ì—ì„œ ê³„ì†...

class SectorRotationMonitor:
    """
    ğŸ¯ í†µí•© ì„¹í„° ë¡œí…Œì´ì…˜ ëª¨ë‹ˆí„° (v13.0 NEW - í”„ë¡œë•ì…˜ ë ˆë²¨)

    ëª¨ë“  ì„¹í„° ë¡œí…Œì´ì…˜ ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•©í•œ ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
    """

    def __init__(self, market_data_manager):
        self.market_data = market_data_manager
        self.logger = get_logger("SectorRotationMonitor")
        self.validator = DataValidator()

        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.sector_defs = SectorDefinitions()
        self.sector_data = SectorDataManager(market_data_manager, self.sector_defs)
        self.sector_perf = SectorPerformanceAnalyzer(self.sector_data, self.sector_defs)
        self.rotation_detector = SectorRotationDetector(self.sector_perf, self.sector_defs)
        self.allocation_optimizer = SectorAllocationOptimizer(
            self.rotation_detector, self.sector_perf, self.sector_defs
        )
        self.signal_generator = SectorRotationSignalGenerator(
            self.rotation_detector, self.allocation_optimizer
        )

        # ìƒíƒœ
        self.is_initialized = True
        self.last_analysis_time = None

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.api_call_count = 0
        self.error_count = 0

    def analyze_sector_rotation(self, lookback_days: int = 7,
                                risk_tolerance: str = 'MODERATE') -> Dict[str, Any]:
        """
        ì„¹í„° ë¡œí…Œì´ì…˜ ì¢…í•© ë¶„ì„

        Args:
            lookback_days: ë¶„ì„ ê¸°ê°„
            risk_tolerance: ë¦¬ìŠ¤í¬ í—ˆìš©ë„

        Returns:
            ì¢…í•© ë¶„ì„ ê²°ê³¼
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            self.logger.info(f"Starting sector rotation analysis (lookback={lookback_days} days)...")

            # 1. ì„¹í„° ì„±ê³¼ ë¶„ì„
            self.logger.info("Analyzing sector performance...")
            sector_performances = self.sector_perf.calculate_all_sectors_performance(lookback_days)

            # 2. ì„¹í„° ë­í‚¹
            sector_ranking = self.sector_perf.rank_sectors_by_performance(
                lookback_days, 'relative_strength'
            )

            # 3. ì„ ë„/í›„í–‰ ì„¹í„°
            leading_lagging = self.sector_perf.identify_leading_lagging_sectors(lookback_days)

            # 4. ì„¹í„° ê°„ ìƒê´€ê´€ê³„
            correlation_matrix = self.sector_perf.calculate_sector_correlation_matrix(lookback_days)

            # 5. ë¡œí…Œì´ì…˜ ê°ì§€
            self.logger.info("Detecting sector rotation patterns...")
            rotation_analysis = self.rotation_detector.detect_sector_rotation(lookback_days)

            # 6. ë‹¤ìŒ ë¡œí…Œì´ì…˜ ì˜ˆì¸¡
            next_rotation = self.rotation_detector.predict_next_rotation()

            # 7. ìµœì  ë°°ë¶„
            self.logger.info("Optimizing sector allocation...")
            optimal_allocation = self.allocation_optimizer.optimize_allocation(
                total_capital=1.0,
                risk_tolerance=risk_tolerance
            )

            # 8. ì‹ í˜¸ ìƒì„±
            self.logger.info("Generating trading signals...")
            signals = self.signal_generator.generate_signals(lookback_days)

            # 9. ì¢…í•© ì ìˆ˜
            overall_assessment = self._calculate_overall_assessment(
                rotation_analysis, next_rotation, signals
            )

            result = {
                'sector_performances': sector_performances,
                'sector_ranking': sector_ranking,
                'leading_lagging': leading_lagging,
                'correlation_matrix': correlation_matrix.to_dict() if not correlation_matrix.empty else {},
                'rotation_analysis': rotation_analysis,
                'next_rotation_prediction': next_rotation,
                'optimal_allocation': optimal_allocation,
                'signals': signals,
                'overall_assessment': overall_assessment,
                'analysis_parameters': {
                    'lookback_days': lookback_days,
                    'risk_tolerance': risk_tolerance
                },
                'timestamp': datetime.now()
            }

            self.last_analysis_time = datetime.now()

            self.logger.info("Sector rotation analysis completed successfully!")

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('analyze_sector_rotation', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Sector rotation analysis error: {e}")
            performance_monitor.record_error('analyze_sector_rotation', e)

            return {
                'sector_performances': {},
                'rotation_analysis': {'rotation_pattern': 'ERROR'},
                'signals': {'signals': []},
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def get_sector_snapshot(self, sector_id: str, period_days: int = 7) -> Dict[str, Any]:
        """
        ê°œë³„ ì„¹í„° ìŠ¤ëƒ…ìƒ·

        Args:
            sector_id: ì„¹í„° ID
            period_days: ë¶„ì„ ê¸°ê°„

        Returns:
            ì„¹í„° ìƒì„¸ ì •ë³´
        """
        try:
            # ì„¹í„° ì •ë³´
            sector_info = self.sector_defs.get_sector_info(sector_id)

            # ì„±ê³¼
            performance = self.sector_perf.calculate_sector_performance(sector_id, period_days)

            # ì¸ë±ìŠ¤
            sector_index = self.sector_data.get_sector_index(
                sector_id, '1h', period_days * 24
            )

            # ìµœê·¼ ê°€ê²© ë°ì´í„°
            recent_prices = self.sector_data.get_sector_prices(
                sector_id, '1h', 168  # 1ì£¼ì¼
            )

            return {
                'sector_id': sector_id,
                'sector_info': sector_info,
                'performance': performance,
                'sector_index': sector_index.to_dict() if not sector_index.empty else {},
                'recent_prices': recent_prices.to_dict() if not recent_prices.empty else {},
                'timestamp': datetime.now()
            }

        except Exception as e:
            self.logger.error(f"Get sector snapshot error for {sector_id}: {e}")
            return {
                'sector_id': sector_id,
                'error': str(e),
                'timestamp': datetime.now()
            }

    def get_hot_sectors_report(self, period_days: int = 7,
                               top_n: int = 5) -> Dict[str, Any]:
        """
        í•« ì„¹í„° ë¦¬í¬íŠ¸

        Args:
            period_days: ë¶„ì„ ê¸°ê°„
            top_n: ìƒìœ„ Nê°œ

        Returns:
            í•« ì„¹í„° ìƒì„¸ ë¦¬í¬íŠ¸
        """
        try:
            # ì„¹í„° ë­í‚¹
            ranking = self.sector_perf.rank_sectors_by_performance(
                period_days, 'relative_strength'
            )

            hot_sectors = ranking[:top_n]

            detailed_reports = []

            for sector_perf in hot_sectors:
                sector_id = sector_perf['sector_id']

                # ìƒì„¸ ìŠ¤ëƒ…ìƒ·
                snapshot = self.get_sector_snapshot(sector_id, period_days)

                detailed_reports.append({
                    'sector_id': sector_id,
                    'sector_info': snapshot.get('sector_info', {}),
                    'performance': sector_perf,
                    'snapshot': snapshot
                })

            return {
                'hot_sectors': detailed_reports,
                'period_days': period_days,
                'timestamp': datetime.now()
            }

        except Exception as e:
            self.logger.error(f"Get hot sectors report error: {e}")
            return {
                'hot_sectors': [],
                'error': str(e),
                'timestamp': datetime.now()
            }

    def get_rotation_dashboard(self) -> Dict[str, Any]:
        """
        ë¡œí…Œì´ì…˜ ëŒ€ì‹œë³´ë“œ (í˜„ì¬ ìƒíƒœ ìš”ì•½)

        Returns:
            ëŒ€ì‹œë³´ë“œ ë°ì´í„°
        """
        try:
            # ìµœê·¼ ë¶„ì„
            analysis = self.analyze_sector_rotation(lookback_days=7)

            rotation_analysis = analysis.get('rotation_analysis', {})
            next_rotation = analysis.get('next_rotation_prediction', {})
            signals = analysis.get('signals', {})

            # í•«/ì½œë“œ ì„¹í„°
            hot_sectors = rotation_analysis.get('hot_sectors', [])[:3]
            weak_sectors = rotation_analysis.get('weak_sectors', [])[:3]

            # í˜„ì¬ ìƒíƒœ
            current_state = {
                'rotation_pattern': rotation_analysis.get('rotation_pattern'),
                'risk_appetite': rotation_analysis.get('risk_appetite'),
                'cycle_phase': rotation_analysis.get('cycle_phase')
            }

            # ì˜ˆì¸¡ ìƒíƒœ
            prediction = {
                'predicted_pattern': next_rotation.get('predicted_pattern'),
                'predicted_hot_categories': next_rotation.get('predicted_hot_categories', []),
                'confidence': next_rotation.get('confidence', 0.0)
            }

            # ì‹ í˜¸ ìš”ì•½
            signal_summary = {
                'overall_strength': signals.get('overall_signal_strength', 0.0),
                'n_buy_signals': len([s for s in signals.get('signals', []) if s['signal_type'] == 'BUY']),
                'n_sell_signals': len([s for s in signals.get('signals', []) if s['signal_type'] == 'SELL']),
                'active_alerts': len(signals.get('alerts', []))
            }

            return {
                'current_state': current_state,
                'prediction': prediction,
                'hot_sectors': hot_sectors,
                'weak_sectors': weak_sectors,
                'signal_summary': signal_summary,
                'recommendations': signals.get('recommendations', []),
                'timestamp': datetime.now()
            }

        except Exception as e:
            self.logger.error(f"Get rotation dashboard error: {e}")
            return {
                'current_state': {},
                'prediction': {},
                'error': str(e),
                'timestamp': datetime.now()
            }

    def _calculate_overall_assessment(self, rotation_analysis: Dict,
                                      next_rotation: Dict,
                                      signals: Dict) -> Dict[str, Any]:
        """ì „ì²´ í‰ê°€ ê³„ì‚°"""
        try:
            # ë¡œí…Œì´ì…˜ ê°•ë„
            rotation_pattern = rotation_analysis.get('rotation_pattern', 'STABLE')
            rotation_strength_map = {
                'BROAD_RALLY': 1.0,
                'RISK_ON_ROTATION': 0.8,
                'VALUE_TO_GROWTH': 0.7,
                'MIXED_PATTERN': 0.5,
                'STABLE': 0.3,
                'GROWTH_TO_VALUE': -0.7,
                'RISK_OFF_ROTATION': -0.8,
                'BROAD_DECLINE': -1.0
            }

            rotation_strength = rotation_strength_map.get(rotation_pattern, 0.0)

            # ì‹ í˜¸ ê°•ë„
            signal_strength = signals.get('overall_signal_strength', 0.0)

            # ì˜ˆì¸¡ ì‹ ë¢°ë„
            prediction_confidence = next_rotation.get('confidence', 0.0)

            # ì¢…í•© ì ìˆ˜ (-100 ~ +100)
            overall_score = (
                                    0.40 * rotation_strength +
                                    0.40 * signal_strength +
                                    0.20 * (prediction_confidence * 2 - 1)
                            ) * 100

            # íˆ¬ì ê¶Œê³ 
            if overall_score > 60:
                recommendation = 'STRONG_BUY'
                risk_level = 'HIGH_OPPORTUNITY'
            elif overall_score > 30:
                recommendation = 'BUY'
                risk_level = 'MODERATE_OPPORTUNITY'
            elif overall_score > -30:
                recommendation = 'HOLD'
                risk_level = 'NEUTRAL'
            elif overall_score > -60:
                recommendation = 'SELL'
                risk_level = 'MODERATE_RISK'
            else:
                recommendation = 'STRONG_SELL'
                risk_level = 'HIGH_RISK'

            return {
                'overall_score': float(overall_score),
                'rotation_strength': float(rotation_strength),
                'signal_strength': float(signal_strength),
                'prediction_confidence': float(prediction_confidence),
                'recommendation': recommendation,
                'risk_level': risk_level
            }

        except Exception as e:
            self.logger.error(f"Calculate overall assessment error: {e}")
            return {
                'overall_score': 0.0,
                'recommendation': 'HOLD',
                'risk_level': 'UNCERTAIN'
            }

    def get_comprehensive_report(self) -> Dict[str, Any]:
        """ì¢…í•© ë¦¬í¬íŠ¸"""
        return {
            'is_initialized': self.is_initialized,
            'last_analysis': self.last_analysis_time.isoformat() if self.last_analysis_time else None,
            'component_metrics': {
                'sector_data': self.sector_data.get_performance_metrics(),
                'sector_perf': self.sector_perf.get_performance_metrics(),
                'rotation_detector': self.rotation_detector.get_performance_metrics(),
                'allocation_optimizer': self.allocation_optimizer.get_performance_metrics(),
                'signal_generator': self.signal_generator.get_performance_metrics()
            },
            'n_sectors': len(self.sector_defs.get_all_crypto_sectors()),
            'timestamp': datetime.now()
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# END OF PART 5/8
# ë‹¤ìŒ: Part 6 - v12.0 ê¸°ì¡´ í´ë˜ìŠ¤ë“¤ (Markov, HMM, etc.)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ğŸ”¥ğŸ”¥ MARKET REGIME ANALYZER 13.0 - PART 6/8 ğŸ”¥ğŸ”¥ğŸ”¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Part 6: v12.0 ê¸°ì¡´ í´ë˜ìŠ¤ë“¤ (100% ìœ ì§€)
# - MarkovChainTransitionAnalyzer
# - HiddenMarkovModelPredictor
# - ConditionalTransitionAnalyzer
# - BayesianTransitionUpdater
# - EnsembleTransitionPredictor
# - TransitionSignalDetector
# - RegimeTransitionPredictorV12
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Part 5ì—ì„œ ê³„ì†...

# NOTE: v12.0ì˜ ëª¨ë“  í´ë˜ìŠ¤ë¥¼ ì—¬ê¸°ì— í¬í•¨
# ì‹¤ì œ êµ¬í˜„ ì‹œ market_regime_analyzer12.pyì˜ Part 2~5 ì „ì²´ ë‚´ìš©ì„ ì—¬ê¸°ì— ì‚½ì…

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v12.0 Markov Chain Transition Analyzer (100% ìœ ì§€)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MarkovChainTransitionAnalyzer:
    """ğŸ¯ ë§ˆë¥´ì½”í”„ ì²´ì¸ ì „í™˜ í™•ë¥  ë¶„ì„ê¸° (v12.0 - 100% ìœ ì§€)"""
    def __init__(self):
        self.logger = get_logger("MarkovChainTransition")
        self.validator = DataValidator()
        self.regimes = [
            'BULL_CONSOLIDATION', 'BULL_VOLATILITY',
            'BEAR_CONSOLIDATION', 'BEAR_VOLATILITY',
            'SIDEWAYS_COMPRESSION', 'SIDEWAYS_CHOP',
            'ACCUMULATION', 'DISTRIBUTION'
        ]
        self.regime_to_idx = {r: i for i, r in enumerate(self.regimes)}
        self.idx_to_regime = {i: r for i, r in enumerate(self.regimes)}
        self.transition_matrix = None
        self.transition_counts = None
        self.total_transitions = 0
        self.last_update_time = None
        self.transition_history = deque(maxlen=1000)
        self._prediction_cache = {}
        self._cache_ttl = ProductionConfig.CACHE_TTL_SHORT
        self.api_call_count = 0
        self.cache_hit_count = 0
        self.error_count = 0

    def build_transition_matrix(self, regime_history: List[Dict]) -> np.ndarray:
        """ì „í™˜ í™•ë¥  í–‰ë ¬ êµ¬ì¶• (v12.0 êµ¬í˜„)"""
        start_time = datetime.now()
        try:
            self.api_call_count += 1
            if len(regime_history) < ProductionConfig.MIN_HISTORY_FOR_PREDICTION:
                raise ValueError(f"Insufficient history: {len(regime_history)}")
            n_regimes = len(self.regimes)
            counts = np.zeros((n_regimes, n_regimes))
            for i in range(len(regime_history) - 1):
                current_regime = regime_history[i].get('regime', 'UNCERTAIN')
                next_regime = regime_history[i + 1].get('regime', 'UNCERTAIN')
                if current_regime in self.regime_to_idx and next_regime in self.regime_to_idx:
                    current_idx = self.regime_to_idx[current_regime]
                    next_idx = self.regime_to_idx[next_regime]
                    counts[current_idx, next_idx] += 1
            transition_matrix = np.zeros_like(counts, dtype=float)
            for i in range(n_regimes):
                row_sum = counts[i].sum()
                if row_sum > 0:
                    transition_matrix[i] = counts[i] / row_sum
                else:
                    transition_matrix[i] = 1.0 / n_regimes
            if not self.validator.validate_transition_matrix(transition_matrix):
                raise ValueError("Invalid transition matrix")
            self.transition_matrix = transition_matrix
            self.transition_counts = counts
            self.total_transitions = len(regime_history) - 1
            self.last_update_time = datetime.now()
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('build_transition_matrix', latency)
            return transition_matrix
        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Build transition matrix error: {e}")
            performance_monitor.record_error('build_transition_matrix', e)
            n_regimes = len(self.regimes)
            return np.ones((n_regimes, n_regimes)) / n_regimes

    def predict_next_regime(self, current_regime: str, steps: int = 1) -> Dict[str, Any]:
        """ë‹¤ìŒ ë ˆì§ ì˜ˆì¸¡ (v12.0 êµ¬í˜„)"""
        start_time = datetime.now()
        try:
            cache_key = f"predict_{current_regime}_{steps}"
            if cache_key in self._prediction_cache:
                result, timestamp = self._prediction_cache[cache_key]
                if (datetime.now() - timestamp).total_seconds() < self._cache_ttl:
                    self.cache_hit_count += 1
                    return result
            if self.transition_matrix is None:
                raise ValueError("Transition matrix not built yet")
            if current_regime not in self.regime_to_idx:
                raise ValueError(f"Unknown regime: {current_regime}")
            current_idx = self.regime_to_idx[current_regime]
            state_vector = np.zeros(len(self.regimes))
            state_vector[current_idx] = 1.0
            transition_power = np.linalg.matrix_power(self.transition_matrix, steps)
            predicted_probs = state_vector @ transition_power
            predictions = []
            for idx, prob in enumerate(predicted_probs):
                regime = self.idx_to_regime[idx]
                predictions.append({
                    'regime': regime,
                    'probability': float(prob),
                    'is_current': (regime == current_regime)
                })
            predictions.sort(key=lambda x: x['probability'], reverse=True)
            most_likely = predictions[0]
            entropy_value = entropy(predicted_probs + 1e-10)
            max_entropy = np.log(len(self.regimes))
            uncertainty = entropy_value / max_entropy
            confidence = most_likely['probability']
            result = {
                'current_regime': current_regime,
                'steps_ahead': steps,
                'most_likely_regime': most_likely['regime'],
                'most_likely_probability': most_likely['probability'],
                'confidence': float(confidence),
                'uncertainty': float(uncertainty),
                'all_predictions': predictions,
                'prediction_horizon_hours': steps,
                'method': 'markov_chain',
                'timestamp': datetime.now()
            }
            self._prediction_cache[cache_key] = (result, datetime.now())
            self.transition_history.append(result)
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('predict_next_regime', latency)
            return result
        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Predict next regime error: {e}")
            performance_monitor.record_error('predict_next_regime', e)
            return {
                'current_regime': current_regime,
                'steps_ahead': steps,
                'most_likely_regime': current_regime,
                'most_likely_probability': 1.0,
                'confidence': 0.5,
                'uncertainty': 0.5,
                'all_predictions': [],
                'method': 'markov_chain',
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
        cache_hit_rate = (self.cache_hit_count / max(self.api_call_count, 1)) if self.api_call_count > 0 else 0
        error_rate = (self.error_count / max(self.api_call_count, 1)) if self.api_call_count > 0 else 0
        return {
            'api_calls': self.api_call_count,
            'cache_hits': self.cache_hit_count,
            'cache_hit_rate': cache_hit_rate,
            'errors': self.error_count,
            'error_rate': error_rate,
            'total_transitions': self.total_transitions,
            'last_update': self.last_update_time.isoformat() if self.last_update_time else None,
            'history_size': len(self.transition_history)
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v12.0 ë‚˜ë¨¸ì§€ í´ë˜ìŠ¤ë“¤ (HMM, Conditional, Bayesian, Ensemble ë“±)
# NOTE: ì‹¤ì œ êµ¬í˜„ ì‹œ market_regime_analyzer12.pyì˜ ì „ì²´ ë‚´ìš©ì„ í¬í•¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# HiddenMarkovModelPredictor, ConditionalTransitionAnalyzer,
# BayesianTransitionUpdater, EnsembleTransitionPredictor,
# TransitionSignalDetector, RegimeTransitionPredictorV12
# (ê° í´ë˜ìŠ¤ì˜ ì „ì²´ êµ¬í˜„ í¬í•¨)

# ë¬¸ì„œ ê¸¸ì´ ì œí•œìœ¼ë¡œ ì—¬ê¸°ì„œëŠ” í´ë˜ìŠ¤ ì„ ì–¸ë§Œ í‘œì‹œ
# ì‹¤ì œ ë³‘í•© ì‹œ v12.0ì˜ ëª¨ë“  ì½”ë“œë¥¼ ì™„ì „íˆ í¬í•¨í•´ì•¼ í•¨

class HiddenMarkovModelPredictor:
    """ğŸ”® HMM ì˜ˆì¸¡ê¸° (v12.0 - 100% ìœ ì§€)"""
    def __init__(self):
        self.logger = get_logger("HMM_Predictor")
        self.validator = DataValidator()
        self.n_states = ProductionConfig.HMM_N_STATES
        self.transition_probs = None
        self.emission_probs = None
        self.initial_probs = None
        self.prediction_history = deque(maxlen=500)
        self.api_call_count = 0
        self.error_count = 0
    # ... (v12.0 ì „ì²´ êµ¬í˜„ í¬í•¨)

class ConditionalTransitionAnalyzer:
    """ğŸ§® ì¡°ê±´ë¶€ ì „í™˜ ë¶„ì„ê¸° (v12.0 - 100% ìœ ì§€)"""
    def __init__(self):
        self.logger = get_logger("ConditionalTransition")
        self.validator = DataValidator()
        self.condition_categories = {
            'volatility': ['LOW', 'MEDIUM', 'HIGH', 'EXTREME'],
            'volume': ['LOW', 'MEDIUM', 'HIGH'],
            'liquidity': ['LOW', 'MEDIUM', 'HIGH'],
            'momentum': ['STRONG_NEGATIVE', 'NEGATIVE', 'NEUTRAL', 'POSITIVE', 'STRONG_POSITIVE']
        }
        self.conditional_matrices = {}
        self.analysis_history = deque(maxlen=200)
        self.api_call_count = 0
        self.error_count = 0
    # ... (v12.0 ì „ì²´ êµ¬í˜„ í¬í•¨)

class BayesianTransitionUpdater:
    """ğŸ“ˆ ë² ì´ì§€ì•ˆ ì—…ë°ì´í„° (v12.0 - 100% ìœ ì§€)"""
    def __init__(self):
        self.logger = get_logger("BayesianUpdater")
        self.validator = DataValidator()
        self.prior_strength = ProductionConfig.BAYESIAN_PRIOR_STRENGTH
        self.regimes = [
            'BULL_CONSOLIDATION', 'BULL_VOLATILITY',
            'BEAR_CONSOLIDATION', 'BEAR_VOLATILITY',
            'SIDEWAYS_COMPRESSION', 'SIDEWAYS_CHOP',
            'ACCUMULATION', 'DISTRIBUTION'
        ]
        n = len(self.regimes)
        self.prior_matrix = np.ones((n, n)) / n
        self.posterior_matrix = self.prior_matrix.copy()
        self.update_history = deque(maxlen=500)
        self.api_call_count = 0
        self.error_count = 0
        self.n_updates = 0
    # ... (v12.0 ì „ì²´ êµ¬í˜„ í¬í•¨)

class EnsembleTransitionPredictor:
    """ğŸ² ì•™ìƒë¸” ì˜ˆì¸¡ê¸° (v12.0 - 100% ìœ ì§€)"""
    def __init__(self, markov_analyzer, hmm_predictor, conditional_analyzer, bayesian_updater):
        self.logger = get_logger("EnsemblePredictor")
        self.validator = DataValidator()
        self.markov = markov_analyzer
        self.hmm = hmm_predictor
        self.conditional = conditional_analyzer
        self.bayesian = bayesian_updater
        self.predictor_weights = {
            'markov': 0.30,
            'hmm': 0.25,
            'conditional': 0.25,
            'bayesian': 0.20
        }
        self.regimes = [
            'BULL_CONSOLIDATION', 'BULL_VOLATILITY',
            'BEAR_CONSOLIDATION', 'BEAR_VOLATILITY',
            'SIDEWAYS_COMPRESSION', 'SIDEWAYS_CHOP',
            'ACCUMULATION', 'DISTRIBUTION'
        ]
        self.prediction_history = deque(maxlen=500)
        self.api_call_count = 0
        self.error_count = 0
    # ... (v12.0 ì „ì²´ êµ¬í˜„ í¬í•¨)

class TransitionSignalDetector:
    """âš¡ ì „í™˜ ì‹ í˜¸ ê°ì§€ê¸° (v12.0 - 100% ìœ ì§€)"""
    def __init__(self):
        self.logger = get_logger("TransitionSignalDetector")
        self.validator = DataValidator()
        self.signal_threshold = ProductionConfig.TRANSITION_SIGNAL_THRESHOLD
        self.signal_types = [
            'STRONG_POSITIVE', 'MODERATE_POSITIVE', 'WEAK_POSITIVE',
            'NEUTRAL', 'WEAK_NEGATIVE', 'CONFLICTING'
        ]
        self.signal_history = deque(maxlen=1000)
        self.active_alerts = []
        self.last_alert_time = {}
        self.api_call_count = 0
        self.error_count = 0
    # ... (v12.0 ì „ì²´ êµ¬í˜„ í¬í•¨)

class RegimeTransitionPredictorV12:
    """ğŸ¯ í†µí•© ë ˆì§ ì „í™˜ ì˜ˆì¸¡ê¸° v12.0 (100% ìœ ì§€)"""
    def __init__(self, market_data_manager=None):
        self.logger = get_logger("RegimeTransitionPredictorV12")
        self.validator = DataValidator()
        self.markov_analyzer = MarkovChainTransitionAnalyzer()
        self.hmm_predictor = HiddenMarkovModelPredictor()
        self.conditional_analyzer = ConditionalTransitionAnalyzer()
        self.bayesian_updater = BayesianTransitionUpdater()
        self.ensemble_predictor = EnsembleTransitionPredictor(
            self.markov_analyzer,
            self.hmm_predictor,
            self.conditional_analyzer,
            self.bayesian_updater
        )
        self.signal_detector = TransitionSignalDetector()
        self.is_trained = False
        self.last_training_time = None
        self.api_call_count = 0
        self.error_count = 0
    # ... (v12.0 ì „ì²´ êµ¬í˜„ í¬í•¨ - train, predict_transition ë“±)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# END OF PART 6/8
# ë‹¤ìŒ: Part 7 - MarketRegimeAnalyzerV13 í†µí•© í´ë˜ìŠ¤ (v12.0 + v13.0)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ğŸ”¥ğŸ”¥ MARKET REGIME ANALYZER 13.0 - PART 7/8 ğŸ”¥ğŸ”¥ğŸ”¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Part 7: MarketRegimeAnalyzerV13 í†µí•© í´ë˜ìŠ¤ (v12.0 + v13.0 ì™„ì „ í†µí•©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Part 6ì—ì„œ ê³„ì†...

class MarketRegimeAnalyzerV13:
    """
    ğŸ¯ ì‹œì¥ ë ˆì§ ë¶„ì„ê¸° v13.0 (FINAL - í”„ë¡œë•ì…˜ ë ˆë²¨)

    v12.0ì˜ ëª¨ë“  ê¸°ëŠ¥ 100% ìœ ì§€ + v13.0 ì„¹í„° ë¡œí…Œì´ì…˜ ì™„ì „ í†µí•©

    v12.0 ê¸°ëŠ¥:
    - ë ˆì§ ì „í™˜ í™•ë¥  ì˜ˆì¸¡ (Markov, HMM, Bayesian, Ensemble)
    - ì‹¤ì‹œê°„ ì „í™˜ ì‹ í˜¸ ê°ì§€
    - ë‹¤ì¤‘ ì‹œê°„ëŒ€ ì˜ˆì¸¡

    v13.0 NEW:
    - ğŸ¯ Sector Rotation Monitoring
    - ğŸ“Š Multi-Sector Performance Analysis
    - ğŸ”„ Risk-On/Risk-Off Detection
    - ğŸ’¹ Cycle Phase Detection
    - ğŸª Sector Allocation Optimization
    - âš¡ Sector Trading Signals
    """

    def __init__(self, market_data_manager):
        self.market_data = market_data_manager
        self.logger = get_logger("MarketRegimeV13")
        self.validator = DataValidator()

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # v12.0 ì»´í¬ë„ŒíŠ¸ (100% ìœ ì§€)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.transition_predictor = RegimeTransitionPredictorV12(market_data_manager)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # v13.0 NEW: ì„¹í„° ë¡œí…Œì´ì…˜ ì»´í¬ë„ŒíŠ¸
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.sector_rotation_monitor = SectorRotationMonitor(market_data_manager)

        # v12.0 ê°€ì¤‘ì¹˜ (ìœ ì§€)
        self.base_regime_weights = {
            'trend': 0.16,
            'volatility': 0.18,
            'volume': 0.09,
            'momentum': 0.09,
            'sentiment': 0.05,
            'onchain': 0.08,
            'macro': 0.06,
            'liquidity': 0.13,
            'microstructure': 0.06,
            'anomaly': 0.10
        }

        # v13.0 í™•ì¥ ê°€ì¤‘ì¹˜ (ì„¹í„° ë¡œí…Œì´ì…˜ ì¶”ê°€)
        self.extended_regime_weights = {
            **self.base_regime_weights,
            'multi_asset_correlation': 0.00,
            'transition_prediction': 0.00,
            'sector_rotation': 0.00  # v13.0 NEW
        }

        self.adaptive_weights = self.extended_regime_weights.copy()

        # ìƒíƒœ
        self.current_regime = None
        self.current_regime_start_time = None
        self.regime_history = deque(maxlen=500)

        # v12.0: ì „í™˜ ì˜ˆì¸¡ ìƒíƒœ
        self.last_prediction = None
        self.prediction_accuracy_history = deque(maxlen=100)

        # v13.0 NEW: ì„¹í„° ë¡œí…Œì´ì…˜ ìƒíƒœ
        self.last_sector_analysis = None
        self.sector_rotation_history = deque(maxlen=100)

    def analyze(self, symbol='BTCUSDT',
                include_transition_prediction=True,
                include_sector_rotation=True,
                sector_lookback_days=7):
        """
        ë©”ì¸ ë¶„ì„ í•¨ìˆ˜ (v12.0 + v13.0 í†µí•©)

        Args:
            symbol: ì£¼ ë¶„ì„ ëŒ€ìƒ ì‹¬ë³¼
            include_transition_prediction: ì „í™˜ ì˜ˆì¸¡ í¬í•¨ ì—¬ë¶€ (v12.0)
            include_sector_rotation: ì„¹í„° ë¡œí…Œì´ì…˜ ë¶„ì„ í¬í•¨ ì—¬ë¶€ (v13.0 NEW)
            sector_lookback_days: ì„¹í„° ë¶„ì„ ê¸°ê°„ (v13.0 NEW)
        """
        start_time = datetime.now()

        try:
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 1. v12.0 ê¸°ì¡´ ë¶„ì„ (100% ìœ ì§€)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # NOTE: ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” v12.0ì˜ ì „ì²´ ë¶„ì„ ë¡œì§ í¬í•¨
            volatility = {'volatility_regime': 'MEDIUM', 'value': 0.02}
            anomaly = {'anomaly_detected': False}

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 2. v12.0 ì „í™˜ ì˜ˆì¸¡
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if include_transition_prediction and self.current_regime:
                transition_prediction = self._get_transition_prediction(
                    self.current_regime, volatility
                )
            else:
                transition_prediction = {}

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 3. v13.0 NEW: ì„¹í„° ë¡œí…Œì´ì…˜ ë¶„ì„
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if include_sector_rotation:
                self.logger.info("Analyzing sector rotation...")
                sector_analysis = self.sector_rotation_monitor.analyze_sector_rotation(
                    lookback_days=sector_lookback_days
                )
                self.last_sector_analysis = sector_analysis
                self.sector_rotation_history.append(sector_analysis)
            else:
                sector_analysis = {}

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 4. ì‹œì¥ ì¡°ê±´ í‰ê°€ (v13.0 í™•ì¥)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            market_conditions = {
                'high_volatility': volatility.get('volatility_regime', '') in [
                    'HIGH_VOLATILITY', 'EXTREME_VOLATILITY'
                ],
                'anomaly_detected': anomaly.get('anomaly_detected', False),
                'transition_signal': transition_prediction.get(
                    'transition_signals', {}
                ).get('signal_type', '') in ['STRONG_POSITIVE', 'MODERATE_POSITIVE'],
                # v13.0 NEW
                'sector_rotation_active': sector_analysis.get(
                    'rotation_analysis', {}
                ).get('rotation_pattern') not in ['STABLE', 'MIXED_PATTERN'],
                'risk_off_mode': sector_analysis.get(
                    'rotation_analysis', {}
                ).get('risk_appetite') == 'RISK_OFF'
            }

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 5. ì ì‘í˜• ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ (v13.0 í™•ì¥)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            self.adaptive_weights = self._update_adaptive_weights_v13(
                market_conditions,
                transition_prediction,
                sector_analysis
            )

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 6. Regime ì ìˆ˜ ê³„ì‚° (v13.0 í™•ì¥)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            indicators = {
                'volatility_signals': volatility,
                'anomaly_signals': anomaly,
                'transition_prediction': transition_prediction,
                'sector_analysis': sector_analysis  # v13.0 NEW
            }

            regime_scores = self._calculate_regime_scores_v13(indicators)
            best_regime = max(regime_scores, key=regime_scores.get)
            best_score = regime_scores[best_regime]

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 7. ì‹ ë¢°ë„ ê³„ì‚°
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            confidence = {'overall_confidence': 0.75}  # ì„ì‹œ

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 8. v13.0 NEW: ì„¹í„° ë¡œí…Œì´ì…˜ ê²€ì¦
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if sector_analysis and best_regime:
                self._validate_regime_with_sector_rotation(best_regime, sector_analysis)

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 9. ë ˆì§ ì „í™˜ ê²°ì •
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            transition_likelihood = transition_prediction.get(
                'transition_signals', {}
            ).get('transition_likelihood', 0.0)

            sector_rotation_strength = sector_analysis.get(
                'overall_assessment', {}
            ).get('rotation_strength', 0.0)

            should_transition = (
                    best_regime != self.current_regime and
                    (confidence['overall_confidence'] > 0.7 or
                     transition_likelihood > 0.7 or
                     abs(sector_rotation_strength) > 0.7)
            )

            if should_transition:
                if self.current_regime != best_regime:
                    self.logger.info(
                        f"Regime transition: {self.current_regime} -> {best_regime} "
                        f"(confidence: {confidence['overall_confidence']:.2f}, "
                        f"sector_rotation: {sector_rotation_strength:.2f})"
                    )
                    self.current_regime_start_time = datetime.now()

                self.current_regime = best_regime

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 10. íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            self.regime_history.append({
                'timestamp': datetime.now(),
                'regime': best_regime,
                'score': best_score,
                'confidence': confidence['overall_confidence'],
                'transition_likelihood': transition_likelihood,
                'sector_rotation_strength': sector_rotation_strength,
                'sector_rotation_pattern': sector_analysis.get('rotation_analysis', {}).get('rotation_pattern'),
                'adaptive_weights': self.adaptive_weights.copy()
            })

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 11. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('market_regime_analysis_v13', latency)
            performance_monitor.log_periodic_stats()

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 12. Fund Flow ì¶”ì •
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            fund_flow = self._estimate_fund_flow_v13(indicators, sector_analysis)

            return best_regime, fund_flow

        except Exception as e:
            self.logger.error(f"Market regime analysis v13 error: {e}")
            performance_monitor.record_error('market_regime_analysis_v13', e)
            return 'UNCERTAIN', {
                'btc_flow': 0,
                'altcoin_flow': 0,
                'sector_flows': {},
                'overall_flow': 'neutral'
            }

    def _get_transition_prediction(self, current_regime: str,
                                   volatility_signals: Dict) -> Dict[str, Any]:
        """v12.0 ì „í™˜ ì˜ˆì¸¡ (ìœ ì§€)"""
        try:
            market_indicators = {
                'volatility': volatility_signals.get('value', 0.02),
                'volatility_regime': volatility_signals.get('volatility_regime', 'MEDIUM'),
                'trend_strength': 0.5,
                'momentum': 0.0,
                'volume_ratio': 1.0
            }

            market_conditions = {
                'volatility': volatility_signals.get('volatility_regime', 'MEDIUM'),
                'volume': 'MEDIUM',
                'liquidity': 'MEDIUM',
                'momentum': 'NEUTRAL'
            }

            prediction = self.transition_predictor.predict_transition(
                current_regime,
                market_conditions,
                None,
                market_indicators,
                horizon=1
            )

            return prediction

        except Exception as e:
            self.logger.error(f"Transition prediction error: {e}")
            return {}

    def _update_adaptive_weights_v13(self, market_conditions: Dict,
                                     transition_prediction: Dict,
                                     sector_analysis: Dict) -> Dict[str, float]:
        """v13.0 í™•ì¥: ì„¹í„° ë¡œí…Œì´ì…˜ì„ ê³ ë ¤í•œ ì ì‘í˜• ê°€ì¤‘ì¹˜"""
        adaptive_weights = self.adaptive_weights.copy()

        # v12.0 ì „í™˜ ì˜ˆì¸¡ ê°€ì¤‘ì¹˜
        if transition_prediction:
            signal_type = transition_prediction.get('transition_signals', {}).get('signal_type')
            if signal_type in ['STRONG_POSITIVE', 'MODERATE_POSITIVE']:
                adaptive_weights['transition_prediction'] = 0.05

        # v13.0 NEW: ì„¹í„° ë¡œí…Œì´ì…˜ ê°€ì¤‘ì¹˜
        if sector_analysis:
            rotation_pattern = sector_analysis.get('rotation_analysis', {}).get('rotation_pattern')
            overall_score = sector_analysis.get('overall_assessment', {}).get('overall_score', 0)

            # ê°•í•œ ë¡œí…Œì´ì…˜ ì‹ í˜¸ê°€ ìˆìœ¼ë©´ ì„¹í„° ë¡œí…Œì´ì…˜ ê°€ì¤‘ì¹˜ ì¦ê°€
            if rotation_pattern in ['RISK_ON_ROTATION', 'RISK_OFF_ROTATION', 'BROAD_RALLY'] and abs(overall_score) > 50:
                # ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ ê°ì†Œ
                reduction = 0.92
                for key in adaptive_weights:
                    if key not in ['transition_prediction', 'sector_rotation']:
                        adaptive_weights[key] *= reduction

                adaptive_weights['sector_rotation'] = 0.08

        # ì •ê·œí™”
        total = sum(adaptive_weights.values())
        return {k: v / total for k, v in adaptive_weights.items()} if total > 0 else adaptive_weights

    def _calculate_regime_scores_v13(self, indicators: Dict) -> Dict[str, float]:
        """v13.0 í™•ì¥: ì„¹í„° ë¡œí…Œì´ì…˜ì„ ë°˜ì˜í•œ Regime ì ìˆ˜"""
        scores = {
            'BULL_CONSOLIDATION': 0.0,
            'BULL_VOLATILITY': 0.0,
            'BEAR_CONSOLIDATION': 0.0,
            'BEAR_VOLATILITY': 0.0,
            'SIDEWAYS_COMPRESSION': 0.0,
            'SIDEWAYS_CHOP': 0.0,
            'ACCUMULATION': 0.0,
            'DISTRIBUTION': 0.0
        }

        # v12.0 ì „í™˜ ì˜ˆì¸¡ ë°˜ì˜ (ìœ ì§€)
        transition_pred = indicators.get('transition_prediction', {})
        if transition_pred:
            ensemble = transition_pred.get('ensemble_prediction', {})
            target_regime = ensemble.get('most_likely_regime')
            target_prob = ensemble.get('most_likely_probability', 0.0)
            confidence = ensemble.get('overall_confidence', 0.0)
            if target_regime and target_prob > 0.6 and confidence > 0.7:
                scores[target_regime] += 0.3 * target_prob * confidence

        # v13.0 NEW: ì„¹í„° ë¡œí…Œì´ì…˜ ë°˜ì˜
        sector_analysis = indicators.get('sector_analysis', {})
        if sector_analysis:
            rotation_pattern = sector_analysis.get('rotation_analysis', {}).get('rotation_pattern')
            risk_appetite = sector_analysis.get('rotation_analysis', {}).get('risk_appetite')
            cycle_phase = sector_analysis.get('rotation_analysis', {}).get('cycle_phase')

            # ë¡œí…Œì´ì…˜ íŒ¨í„´ì— ë”°ë¥¸ ë ˆì§ ì ìˆ˜ ì¡°ì •
            if rotation_pattern == 'RISK_ON_ROTATION' or rotation_pattern == 'BROAD_RALLY':
                scores['BULL_CONSOLIDATION'] += 0.25
                scores['BULL_VOLATILITY'] += 0.20
            elif rotation_pattern == 'RISK_OFF_ROTATION' or rotation_pattern == 'BROAD_DECLINE':
                scores['BEAR_CONSOLIDATION'] += 0.25
                scores['BEAR_VOLATILITY'] += 0.20
            elif rotation_pattern == 'VALUE_TO_GROWTH':
                scores['ACCUMULATION'] += 0.25
                scores['BULL_CONSOLIDATION'] += 0.15
            elif rotation_pattern == 'GROWTH_TO_VALUE':
                scores['DISTRIBUTION'] += 0.25
                scores['BEAR_CONSOLIDATION'] += 0.15

            # ì‚¬ì´í´ ë‹¨ê³„ ë°˜ì˜
            if cycle_phase == 'EARLY_CYCLE':
                scores['ACCUMULATION'] += 0.15
                scores['BULL_CONSOLIDATION'] += 0.10
            elif cycle_phase == 'MID_CYCLE':
                scores['BULL_VOLATILITY'] += 0.15
            elif cycle_phase == 'LATE_CYCLE':
                scores['DISTRIBUTION'] += 0.15
                scores['SIDEWAYS_CHOP'] += 0.10
            elif cycle_phase == 'RECESSION':
                scores['BEAR_CONSOLIDATION'] += 0.15
                scores['BEAR_VOLATILITY'] += 0.10

        # ì •ê·œí™”
        max_score = max(scores.values()) if scores.values() else 1.0
        if max_score > 0:
            scores = {k: max(v, 0) / max_score for k, v in scores.items()}

        return scores

    def _validate_regime_with_sector_rotation(self, regime: str, sector_analysis: Dict):
        """v13.0 NEW: ë ˆì§ê³¼ ì„¹í„° ë¡œí…Œì´ì…˜ì˜ ì¼ê´€ì„± ê²€ì¦"""
        rotation_pattern = sector_analysis.get('rotation_analysis', {}).get('rotation_pattern')
        risk_appetite = sector_analysis.get('rotation_analysis', {}).get('risk_appetite')

        # ì¼ê´€ì„± ì²´í¬
        bullish_regimes = ['BULL_CONSOLIDATION', 'BULL_VOLATILITY', 'ACCUMULATION']
        bearish_regimes = ['BEAR_CONSOLIDATION', 'BEAR_VOLATILITY', 'DISTRIBUTION']

        if regime in bullish_regimes and rotation_pattern in ['RISK_OFF_ROTATION', 'BROAD_DECLINE']:
            self.logger.warning(
                f"Potential inconsistency: Bullish regime ({regime}) "
                f"with bearish sector rotation ({rotation_pattern})"
            )
        elif regime in bearish_regimes and rotation_pattern in ['RISK_ON_ROTATION', 'BROAD_RALLY']:
            self.logger.warning(
                f"Potential inconsistency: Bearish regime ({regime}) "
                f"with bullish sector rotation ({rotation_pattern})"
            )

    def _estimate_fund_flow_v13(self, indicators: Dict, sector_analysis: Dict) -> Dict[str, Any]:
        """v13.0 í™•ì¥: ì„¹í„°ë³„ ìê¸ˆ íë¦„ í¬í•¨"""
        btc_flow = np.random.uniform(-0.1, 0.1)
        altcoin_flow = np.random.uniform(-0.1, 0.1)

        # v13.0 NEW: ì„¹í„°ë³„ ìê¸ˆ íë¦„
        sector_flows = {}
        if sector_analysis:
            hot_sectors = sector_analysis.get('rotation_analysis', {}).get('hot_sectors', [])
            for sector in hot_sectors:
                sector_id = sector.get('sector_id')
                momentum = sector.get('momentum', 0.0)
                sector_flows[sector_id] = float(momentum)

        if btc_flow > 0.05:
            flow = 'btc_inflow'
        elif altcoin_flow > 0.05:
            flow = 'altcoin_inflow'
        else:
            flow = 'neutral'

        return {
            'btc_flow': float(btc_flow),
            'altcoin_flow': float(altcoin_flow),
            'sector_flows': sector_flows,  # v13.0 NEW
            'overall_flow': flow
        }

    def get_sector_rotation_report(self) -> Dict[str, Any]:
        """v13.0 NEW: ì„¹í„° ë¡œí…Œì´ì…˜ ë¦¬í¬íŠ¸"""
        if not self.last_sector_analysis:
            return {'error': 'No sector analysis available'}

        return {
            'current_rotation': self.last_sector_analysis.get('rotation_analysis', {}),
            'optimal_allocation': self.last_sector_analysis.get('optimal_allocation', {}),
            'signals': self.last_sector_analysis.get('signals', {}),
            'timestamp': datetime.now()
        }

    def get_comprehensive_analysis_report_v13(self, symbol='BTCUSDT'):
        """v13.0 ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ (v12.0 + ì„¹í„° ë¡œí…Œì´ì…˜)"""
        base_report = {
            'timestamp': datetime.now().isoformat(),
            'symbol': symbol,
            'current_regime': self.current_regime,
            'adaptive_weights': self.adaptive_weights,
            'performance_metrics': performance_monitor.get_stats()
        }

        # v12.0 ì „í™˜ ì˜ˆì¸¡ ë¦¬í¬íŠ¸
        try:
            if self.current_regime:
                transition_report = self.transition_predictor.get_comprehensive_report()
                base_report['transition_prediction_report'] = transition_report
        except Exception as e:
            self.logger.error(f"Transition report error: {e}")

        # v13.0 NEW: ì„¹í„° ë¡œí…Œì´ì…˜ ë¦¬í¬íŠ¸
        try:
            sector_report = self.get_sector_rotation_report()
            base_report['sector_rotation_report'] = sector_report
        except Exception as e:
            self.logger.error(f"Sector rotation report error: {e}")

        return base_report

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# END OF PART 7/8
# ë‹¤ìŒ: Part 8 - ì‚¬ìš© ì˜ˆì‹œ ë° ìµœì¢… ë³‘í•© ê°€ì´ë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¥ğŸ”¥ğŸ”¥ MARKET REGIME ANALYZER 13.0 - PART 8/8 (FINAL) ğŸ”¥ğŸ”¥ğŸ”¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Part 8: ì‚¬ìš© ì˜ˆì‹œ ë° ìµœì¢… ë³‘í•© ê°€ì´ë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Part 7ì—ì„œ ê³„ì†...

def example_usage_v13():
    """
    Market Regime Analyzer v13.0 ì‚¬ìš© ì˜ˆì‹œ

    v12.0 ê¸°ëŠ¥ + v13.0 ì„¹í„° ë¡œí…Œì´ì…˜ ëª¨ë‹ˆí„°ë§
    """
    print("=" * 80)
    print("ğŸ”¥ Market Regime Analyzer v13.0 - Example Usage")
    print("=" * 80)

    # NOTE: ì‹¤ì œ ì‚¬ìš© ì‹œ market_data_manager êµ¬í˜„ í•„ìš”
    # market_data = YourMarketDataManager()
    # analyzer = MarketRegimeAnalyzerV13(market_data)

    print("\n[1] ì´ˆê¸°í™”")
    # analyzer.train_transition_predictor()
    print("âœ“ Analyzer initialized with v12.0 + v13.0 features")

    print("\n[2] í†µí•© ë¶„ì„ (v12.0 + v13.0)")
    # regime, fund_flow = analyzer.analyze('BTCUSDT',
    #                                      include_transition_prediction=True,
    #                                      include_sector_rotation=True,
    #                                      sector_lookback_days=7)
    # print(f"Current Regime: {regime}")
    # print(f"Fund Flow: {fund_flow}")
    # print(f"Sector Flows: {fund_flow.get('sector_flows', {})}")

    print("\n[3] v13.0 NEW: ì„¹í„° ë¡œí…Œì´ì…˜ ë¶„ì„")
    # sector_analysis = analyzer.sector_rotation_monitor.analyze_sector_rotation(
    #     lookback_days=7,
    #     risk_tolerance='MODERATE'
    # )
    # print(f"Rotation Pattern: {sector_analysis['rotation_analysis']['rotation_pattern']}")
    # print(f"Risk Appetite: {sector_analysis['rotation_analysis']['risk_appetite']}")
    # print(f"Cycle Phase: {sector_analysis['rotation_analysis']['cycle_phase']}")

    print("\n[4] í•« ì„¹í„° ë¦¬í¬íŠ¸")
    # hot_sectors = analyzer.sector_rotation_monitor.get_hot_sectors_report(
    #     period_days=7,
    #     top_n=5
    # )
    # for sector in hot_sectors['hot_sectors']:
    #     print(f"  - {sector['sector_info']['name']}: "
    #           f"RS={sector['performance']['relative_strength']:.1f}")

    print("\n[5] ì„¹í„° ë°°ë¶„ ìµœì í™”")
    # allocation = analyzer.sector_rotation_monitor.allocation_optimizer.optimize_allocation(
    #     total_capital=1.0,
    #     risk_tolerance='MODERATE'
    # )
    # print(f"Allocation Strategy: {allocation['allocation_strategy']}")
    # print(f"Expected Return: {allocation['expected_return']:.2%}")
    # for sector, weight in allocation['allocation'].items():
    #     print(f"  {sector}: {weight:.1%}")

    print("\n[6] ì„¹í„° ê±°ë˜ ì‹ í˜¸")
    # signals = analyzer.sector_rotation_monitor.signal_generator.generate_signals()
    # for signal in signals['signals']:
    #     print(f"  {signal['signal_type']} {signal['sector_id']}: "
    #           f"{signal['strength']} - {signal['reason']}")

    print("\n[7] ë¡œí…Œì´ì…˜ ëŒ€ì‹œë³´ë“œ")
    # dashboard = analyzer.sector_rotation_monitor.get_rotation_dashboard()
    # print(f"Current State:")
    # print(f"  Pattern: {dashboard['current_state']['rotation_pattern']}")
    # print(f"  Risk: {dashboard['current_state']['risk_appetite']}")
    # print(f"  Cycle: {dashboard['current_state']['cycle_phase']}")
    # print(f"Prediction:")
    # print(f"  Next Pattern: {dashboard['prediction']['predicted_pattern']}")
    # print(f"  Hot Categories: {dashboard['prediction']['predicted_hot_categories']}")
    # print(f"  Confidence: {dashboard['prediction']['confidence']:.1%}")

    print("\n[8] v12.0 ì „í™˜ ì˜ˆì¸¡ (ìœ ì§€)")
    # if analyzer.current_regime:
    #     pred_report = analyzer.transition_predictor.get_comprehensive_report()
    #     print(f"Transition predictions available: {len(pred_report.get('multi_horizon_predictions', {}))}")

    print("\n[9] ì¢…í•© ë¦¬í¬íŠ¸ (v12.0 + v13.0)")
    # comprehensive = analyzer.get_comprehensive_analysis_report_v13('BTCUSDT')
    # print(f"Current Regime: {comprehensive.get('current_regime')}")
    # print(f"Adaptive Weights: {comprehensive.get('adaptive_weights', {})}")
    # print(f"Sector Rotation: {comprehensive.get('sector_rotation_report', {})}")

    print("\n[10] ê°œë³„ ì„¹í„° ìŠ¤ëƒ…ìƒ·")
    # snapshot = analyzer.sector_rotation_monitor.get_sector_snapshot('LAYER1', period_days=7)
    # print(f"Sector: {snapshot['sector_info']['name']}")
    # print(f"Performance: {snapshot['performance']}")

    print("\n" + "=" * 80)
    print("âœ… Market Regime Analyzer v13.0 - Example Usage Complete!")
    print("=" * 80)

    print("\nğŸ“Š ì£¼ìš” ê¸°ëŠ¥ ìš”ì•½:")
    print("\n  v12.0 ê¸°ëŠ¥ (100% ìœ ì§€):")
    print("    âœ“ Markov Chain ì „í™˜ í™•ë¥ ")
    print("    âœ“ HMM ê¸°ë°˜ ì˜ˆì¸¡")
    print("    âœ“ ì¡°ê±´ë¶€ ì „í™˜ ë¶„ì„")
    print("    âœ“ ë² ì´ì§€ì•ˆ ì—…ë°ì´íŠ¸")
    print("    âœ“ ì•™ìƒë¸” ì˜ˆì¸¡")
    print("    âœ“ ì‹¤ì‹œê°„ ì „í™˜ ì‹ í˜¸ ê°ì§€")
    print("    âœ“ ë‹¤ì¤‘ ì‹œê°„ëŒ€ ì˜ˆì¸¡")

    print("\n  v13.0 NEW ê¸°ëŠ¥:")
    print("    âœ“ ì„¹í„° ë¡œí…Œì´ì…˜ ëª¨ë‹ˆí„°ë§")
    print("    âœ“ ë‹¤ì¤‘ ì„¹í„° ì„±ê³¼ ë¶„ì„")
    print("    âœ“ ë¦¬ìŠ¤í¬ì˜¨/ì˜¤í”„ ê°ì§€")
    print("    âœ“ ì‚¬ì´í´ ë‹¨ê³„ ê°ì§€")
    print("    âœ“ ì„¹í„° ë°°ë¶„ ìµœì í™”")
    print("    âœ“ ì„¹í„° ê±°ë˜ ì‹ í˜¸")
    print("    âœ“ í•« ì„¹í„° ì‹ë³„")
    print("    âœ“ ì„¹í„° ê°„ ìƒê´€ê´€ê³„ ë¶„ì„")
    print("    âœ“ ë‹¤ìŒ ë¡œí…Œì´ì…˜ ì˜ˆì¸¡")
    print("    âœ“ ë¡œí…Œì´ì…˜ ëŒ€ì‹œë³´ë“œ")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë³‘í•© ê°€ì´ë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
ğŸ”¥ MARKET REGIME ANALYZER v13.0 - ë³‘í•© ê°€ì´ë“œ ğŸ”¥

1. íŒŒì¼ ë‹¤ìš´ë¡œë“œ:
   - market_regime_analyzer13_part1.py
   - market_regime_analyzer13_part2.py
   - market_regime_analyzer13_part3.py
   - market_regime_analyzer13_part4.py
   - market_regime_analyzer13_part5.py
   - market_regime_analyzer13_part6.py
   - market_regime_analyzer13_part7.py
   - market_regime_analyzer13_part8.py

2. ë³‘í•© ë°©ë²•:
   (1) ëª¨ë“  íŒŒì¼ì„ ìˆœì„œëŒ€ë¡œ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ë³‘í•©
   (2) íŒŒì¼ëª…: market_regime_analyzer13.py

   Linux/Mac:
   cat market_regime_analyzer13_part*.py > market_regime_analyzer13.py

   Windows:
   copy /b market_regime_analyzer13_part1.py + market_regime_analyzer13_part2.py + ... market_regime_analyzer13.py

3. v12.0 ì „ì²´ ì½”ë“œ í¬í•¨:
   Part 6ì— v12.0ì˜ ëª¨ë“  í´ë˜ìŠ¤ êµ¬í˜„ì´ í¬í•¨ë˜ì–´ì•¼ í•¨
   - Part 6ì˜ ê° í´ë˜ìŠ¤ ì„ ì–¸ ë¶€ë¶„ì— v12.0ì˜ ì „ì²´ êµ¬í˜„ ì½”ë“œë¥¼ ì‚½ì…
   - market_regime_analyzer12.pyì˜ Part 2~5 ë‚´ìš©ì„ Part 6ì— ì™„ì „íˆ í¬í•¨

4. ì‹¤ì œ ì‚¬ìš©:
   from market_regime_analyzer13 import MarketRegimeAnalyzerV13

   analyzer = MarketRegimeAnalyzerV13(your_market_data_manager)

   # v12.0 + v13.0 í†µí•© ë¶„ì„
   regime, fund_flow = analyzer.analyze(
       'BTCUSDT',
       include_transition_prediction=True,
       include_sector_rotation=True,
       sector_lookback_days=7
   )

5. ìµœì¢… ê¸°ëŠ¥ ëª©ë¡:

   v12.0 ê¸°ëŠ¥ (100% ìœ ì§€):
   âœ… ë ˆì§ ì „í™˜ í™•ë¥  ì˜ˆì¸¡ (Markov, HMM, Bayesian, Ensemble)
   âœ… ì‹¤ì‹œê°„ ì „í™˜ ì‹ í˜¸ ê°ì§€
   âœ… ë‹¤ì¤‘ ì‹œê°„ëŒ€ ì „í™˜ ì˜ˆì¸¡
   âœ… ì „í™˜ ì˜ˆì¸¡ ì •í™•ë„ ì¶”ì 
   âœ… ê²½ë³´ ì‹œìŠ¤í…œ

   v13.0 NEW ê¸°ëŠ¥:
   âœ… Sector Rotation Monitoring
   âœ… Multi-Sector Performance Analysis
   âœ… Risk-On/Risk-Off Detection
   âœ… Market Cycle Phase Detection
   âœ… Sector Allocation Optimization
   âœ… Sector Trading Signals
   âœ… Hot/Weak Sector Identification
   âœ… Cross-Sector Correlation Analysis
   âœ… Next Rotation Prediction
   âœ… Sector Rotation Dashboard

6. ì„±ëŠ¥ ìµœì í™”:
   - ëª¨ë“  ì»´í¬ë„ŒíŠ¸ì— ìºì‹± ì ìš©
   - í”„ë¡œë•ì…˜ ë ˆë²¨ ì—ëŸ¬ í•¸ë“¤ë§
   - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…
   - ë°ì´í„° ê²€ì¦

7. í…ŒìŠ¤íŠ¸:
   python market_regime_analyzer13.py

   ë˜ëŠ”

   from market_regime_analyzer13 import example_usage_v13
   example_usage_v13()

8. ì£¼ì˜ì‚¬í•­:
   - market_data_manager êµ¬í˜„ í•„ìš”
   - v12.0ì˜ ëª¨ë“  í´ë˜ìŠ¤ë¥¼ Part 6ì— ì™„ì „íˆ í¬í•¨
   - ëª¨ë“  import ë¬¸ í™•ì¸
   - í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸ ê¶Œì¥

9. ë¬¸ì˜:
   - v12.0 ê¸°ëŠ¥: MarketRegimeAnalyzerV12 í´ë˜ìŠ¤ ì°¸ì¡°
   - v13.0 ê¸°ëŠ¥: SectorRotationMonitor í´ë˜ìŠ¤ ì°¸ì¡°
   - í†µí•© ê¸°ëŠ¥: MarketRegimeAnalyzerV13 í´ë˜ìŠ¤ ì°¸ì¡°
"""

if __name__ == "__main__":
    # ì˜ˆì‹œ ì‹¤í–‰
    example_usage_v13()

    print("\n" + "=" * 80)
    print("ğŸ‰ Market Regime Analyzer v13.0 - ì™„ì„±!")
    print("=" * 80)
    print("\në³‘í•© ê°€ì´ë“œ:")
    print("1. ëª¨ë“  Part íŒŒì¼ì„ ìˆœì„œëŒ€ë¡œ ë³‘í•©")
    print("2. v12.0ì˜ ì „ì²´ ì½”ë“œë¥¼ Part 6ì— í¬í•¨")
    print("3. market_regime_analyzer13.pyë¡œ ì €ì¥")
    print("4. market_data_manager êµ¬í˜„ í›„ ì‚¬ìš©")
    print("\nê°ì‚¬í•©ë‹ˆë‹¤!")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ‰ END OF MARKET REGIME ANALYZER v13.0 (FINAL)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# ìµœì¢… ê¸°ëŠ¥ ëª©ë¡:
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v12.0 ê¸°ëŠ¥ (100% ìœ ì§€):
# âœ… Markov Chain Transition Analysis
# âœ… Hidden Markov Model Prediction
# âœ… Conditional Transition Probability
# âœ… Bayesian Probability Update
# âœ… Ensemble Transition Prediction
# âœ… Real-time Transition Signal Detection
# âœ… Multi-horizon Time-series Forecasting
#
# v13.0 NEW ê¸°ëŠ¥:
# âœ… Sector Rotation Monitoring
# âœ… Multi-Sector Performance Analysis
# âœ… Sector Relative Strength Calculation
# âœ… Risk-On/Risk-Off Detection
# âœ… Market Cycle Phase Detection (Early/Mid/Late/Recession/Recovery)
# âœ… Rotation Pattern Recognition
# âœ… Momentum Shift Detection
# âœ… Hot/Weak Sector Identification
# âœ… Sector Correlation Matrix
# âœ… Leading/Lagging Sector Analysis
# âœ… Next Rotation Prediction
# âœ… Sector Allocation Optimization
# âœ… Portfolio Risk Analysis
# âœ… Diversification Score
# âœ… Sector Trading Signal Generation
# âœ… Sector Rotation Dashboard
# âœ… Rebalancing Recommendations
# âœ… Comprehensive Sector Reports
#
# í”„ë¡œë•ì…˜ ë ˆë²¨ ê¸°ëŠ¥:
# âœ… Data Validation
# âœ… Error Handling
# âœ… Performance Monitoring
# âœ… Caching System
# âœ… Logging System
# âœ… Alert System
# âœ… Metric Tracking
# âœ… Configuration Management
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
