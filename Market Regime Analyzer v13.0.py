# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üî•üî•üî• MARKET REGIME ANALYZER 13.0 - PART 1/8 üî•üî•üî•
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Part 1: v12.0 Ï†ÑÏ≤¥ Í∏∞Îä• (100% Ïú†ÏßÄ) + ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Í∏∞Î≥∏ Ïù∏ÌîÑÎùº
#
# v13.0 NEW FEATURES (v12.0Ïùò Î™®Îì† Í∏∞Îä• 100% Ïú†ÏßÄ):
# - üéØ Sector Rotation Monitoring (ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Î™®ÎãàÌÑ∞ÎßÅ)
# - üìä Multi-Sector Performance Analysis
# - üîÑ Rotation Pattern Recognition
# - üíπ Risk-On/Risk-Off Detection
# - üé™ Defensive/Aggressive Sector Shifts
# - üìà Early/Late Cycle Detection
# - üîÆ Next Hot Sector Prediction
# - ‚ö° Real-time Sector Momentum Tracking
# - üé≤ Sector Allocation Recommendations
# - üìâ Cross-Sector Correlation Analysis
#
# Î≥ëÌï© Î∞©Î≤ï:
# 1. Part 1~8ÏùÑ ÏàúÏÑúÎåÄÎ°ú Îã§Ïö¥Î°úÎìú
# 2. Î™®Îì† ÌååÌä∏Î•º market_regime_analyzer13.pyÎ°ú Î≥ëÌï©
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from collections import deque, defaultdict
from typing import Dict, List, Tuple, Optional, Any
import logging
from scipy import stats
from scipy.stats import entropy, norm, t as student_t, spearmanr, kendalltau
from scipy.special import softmax
from scipy.cluster import hierarchy
from scipy.spatial.distance import squareform
from scipy.linalg import eig
import warnings

warnings.filterwarnings('ignore')


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# v12.0Ïùò Î™®Îì† Í∏∞Ï°¥ ÏΩîÎìú (100% Ïú†ÏßÄ)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def get_logger(name: str) -> logging.Logger:
    """ÌîÑÎ°úÎçïÏÖò Î†àÎ≤® Î°úÍ±∞ ÏÉùÏÑ±"""
    logger = logging.getLogger(name)
    if not logger.handlers:
        logger.setLevel(logging.INFO)
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    return logger


class ProductionConfig:
    """ÌîÑÎ°úÎçïÏÖò ÏÑ§Ï†ï ÌÅ¥ÎûòÏä§ (v12.0 + v13.0 ÌôïÏû•)"""
    CACHE_TTL_SHORT = 30
    CACHE_TTL_MEDIUM = 180
    CACHE_TTL_LONG = 300
    API_TIMEOUT = 10
    API_RETRY_COUNT = 3
    API_RETRY_DELAY = 1
    MIN_DATA_POINTS = 20
    MAX_DATA_AGE_SECONDS = 3600
    OUTLIER_THRESHOLD = 5.0
    MIN_REGIME_DURATION_SECONDS = 300
    REGIME_TRANSITION_THRESHOLD = 0.15
    HYSTERESIS_FACTOR = 1.2
    WEIGHT_ADAPTATION_RATE = 0.05
    WEIGHT_MIN = 0.01
    WEIGHT_MAX = 0.50
    PERFORMANCE_LOOKBACK = 20
    ALERT_COOLDOWN_SECONDS = 300
    MAX_ALERTS_PER_HOUR = 20
    CRITICAL_ALERT_THRESHOLD = 0.90
    PERFORMANCE_LOG_INTERVAL = 60
    LATENCY_WARNING_MS = 100
    LATENCY_CRITICAL_MS = 500

    # v12.0 Transition Prediction Config
    MIN_HISTORY_FOR_PREDICTION = 50
    TRANSITION_PREDICTION_HORIZON = [1, 3, 6, 12, 24]
    MARKOV_CHAIN_ORDER = 1
    HMM_N_STATES = 8
    BAYESIAN_PRIOR_STRENGTH = 0.1
    ENSEMBLE_MIN_CONFIDENCE = 0.6
    TRANSITION_SIGNAL_THRESHOLD = 0.7

    # v13.0 NEW: Sector Rotation Config
    SECTOR_MIN_ASSETS = 3  # ÏÑπÌÑ∞Îãπ ÏµúÏÜå ÏûêÏÇ∞ Ïàò
    SECTOR_LOOKBACK_DAYS = 30  # ÏÑπÌÑ∞ ÏÑ±Í≥º Î∂ÑÏÑù Í∏∞Í∞Ñ
    SECTOR_MOMENTUM_WINDOW = 7  # Î™®Î©òÌÖÄ Í≥ÑÏÇ∞ ÏúàÎèÑÏö∞ (Ïùº)
    ROTATION_DETECTION_THRESHOLD = 0.15  # Î°úÌÖåÏù¥ÏÖò Í∞êÏßÄ ÏûÑÍ≥ÑÍ∞í
    RISK_ON_OFF_THRESHOLD = 0.6  # Î¶¨Ïä§ÌÅ¨Ïò®/Ïò§ÌîÑ ÏûÑÍ≥ÑÍ∞í
    SECTOR_CORRELATION_WINDOW = 60  # ÏÑπÌÑ∞ Í∞Ñ ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ ÏúàÎèÑÏö∞
    HOT_SECTOR_TOP_N = 3  # Ìï´ ÏÑπÌÑ∞ ÏÉÅÏúÑ NÍ∞ú
    SECTOR_SIGNAL_CONFIDENCE_MIN = 0.65  # ÏÑπÌÑ∞ Ïã†Ìò∏ ÏµúÏÜå Ïã†Î¢∞ÎèÑ
    DEFENSIVE_AGGRESSIVE_THRESHOLD = 0.5  # Î∞©Ïñ¥Ï†Å/Í≥µÍ≤©Ï†Å ÏûÑÍ≥ÑÍ∞í


class DataValidator:
    """Îç∞Ïù¥ÌÑ∞ Í≤ÄÏ¶ù ÌÅ¥ÎûòÏä§ (v12.0 Ïú†ÏßÄ)"""

    def __init__(self):
        self.logger = get_logger("DataValidator")

    def validate_numeric(self, value: float, name: str,
                         min_val: Optional[float] = None,
                         max_val: Optional[float] = None) -> bool:
        try:
            if not isinstance(value, (int, float)):
                self.logger.warning(f"{name}: Not a number - {value}")
                return False
            if np.isnan(value) or np.isinf(value):
                self.logger.warning(f"{name}: NaN or Inf detected")
                return False
            if min_val is not None and value < min_val:
                self.logger.warning(f"{name}: Below minimum ({value} < {min_val})")
                return False
            if max_val is not None and value > max_val:
                self.logger.warning(f"{name}: Above maximum ({value} > {max_val})")
                return False
            return True
        except Exception as e:
            self.logger.error(f"Validation error for {name}: {e}")
            return False

    def validate_dataframe(self, df: pd.DataFrame,
                           required_columns: List[str],
                           min_rows: int = 1) -> bool:
        try:
            if df is None or df.empty:
                self.logger.warning("DataFrame is None or empty")
                return False
            if len(df) < min_rows:
                self.logger.warning(f"Insufficient rows: {len(df)} < {min_rows}")
                return False
            missing_cols = set(required_columns) - set(df.columns)
            if missing_cols:
                self.logger.warning(f"Missing columns: {missing_cols}")
                return False
            nan_counts = df[required_columns].isna().sum()
            if nan_counts.any():
                self.logger.warning(f"NaN values detected: {nan_counts[nan_counts > 0].to_dict()}")
                return False
            return True
        except Exception as e:
            self.logger.error(f"DataFrame validation error: {e}")
            return False

    def detect_outliers(self, data: np.ndarray,
                        threshold: float = ProductionConfig.OUTLIER_THRESHOLD) -> np.ndarray:
        try:
            if len(data) < 3:
                return np.array([])
            median = np.median(data)
            mad = np.median(np.abs(data - median))
            if mad == 0:
                return np.array([])
            modified_z_scores = 0.6745 * (data - median) / mad
            outliers = np.where(np.abs(modified_z_scores) > threshold)[0]
            return outliers
        except Exception as e:
            self.logger.error(f"Outlier detection error: {e}")
            return np.array([])

    def validate_transition_matrix(self, matrix: np.ndarray) -> bool:
        """Ï†ÑÌôò ÌñâÎ†¨ Í≤ÄÏ¶ù (v12.0)"""
        try:
            if len(matrix.shape) != 2 or matrix.shape[0] != matrix.shape[1]:
                self.logger.warning("Transition matrix must be square")
                return False
            row_sums = np.sum(matrix, axis=1)
            if not np.allclose(row_sums, 1.0, rtol=1e-3):
                self.logger.warning(f"Transition matrix rows must sum to 1: {row_sums}")
                return False
            if np.any(matrix < 0) or np.any(matrix > 1):
                self.logger.warning("Transition matrix values must be between 0 and 1")
                return False
            return True
        except Exception as e:
            self.logger.error(f"Transition matrix validation error: {e}")
            return False


class PerformanceMonitor:
    """ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ ÌÅ¥ÎûòÏä§ (v12.0 Ïú†ÏßÄ)"""

    def __init__(self):
        self.logger = get_logger("PerformanceMonitor")
        self.latencies = deque(maxlen=100)
        self.call_counts = defaultdict(int)
        self.error_counts = defaultdict(int)
        self.last_log_time = datetime.now()

    def record_latency(self, operation: str, latency_ms: float):
        self.latencies.append({
            'operation': operation,
            'latency_ms': latency_ms,
            'timestamp': datetime.now()
        })
        self.call_counts[operation] += 1
        if latency_ms > ProductionConfig.LATENCY_CRITICAL_MS:
            self.logger.warning(f"CRITICAL LATENCY: {operation} took {latency_ms:.2f}ms")
        elif latency_ms > ProductionConfig.LATENCY_WARNING_MS:
            self.logger.info(f"High latency: {operation} took {latency_ms:.2f}ms")

    def record_error(self, operation: str, error: Exception):
        self.error_counts[operation] += 1
        self.logger.error(f"Error in {operation}: {str(error)}")

    def get_stats(self) -> Dict[str, Any]:
        if not self.latencies:
            return {}
        latencies_by_op = defaultdict(list)
        for record in self.latencies:
            latencies_by_op[record['operation']].append(record['latency_ms'])
        stats = {}
        for op, lats in latencies_by_op.items():
            stats[op] = {
                'count': len(lats),
                'mean_ms': np.mean(lats),
                'median_ms': np.median(lats),
                'p95_ms': np.percentile(lats, 95),
                'p99_ms': np.percentile(lats, 99),
                'max_ms': np.max(lats)
            }
        return stats

    def log_periodic_stats(self):
        now = datetime.now()
        if (now - self.last_log_time).total_seconds() >= ProductionConfig.PERFORMANCE_LOG_INTERVAL:
            stats = self.get_stats()
            if stats:
                self.logger.info(f"Performance Stats: {stats}")
            self.last_log_time = now


performance_monitor = PerformanceMonitor()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# v13.0 NEW: ÏÑπÌÑ∞ Ï†ïÏùò Î∞è Î∂ÑÎ•ò
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class SectorDefinitions:
    """
    üéØ ÏÑπÌÑ∞ Ï†ïÏùò Î∞è Î∂ÑÎ•ò (v13.0 NEW - ÌîÑÎ°úÎçïÏÖò Î†àÎ≤®)

    ÏïîÌò∏ÌôîÌèê Î∞è Ï†ÑÌÜµ ÏãúÏû• ÏÑπÌÑ∞ Ï†ïÏùò Î∞è ÏûêÏÇ∞ Îß§Ìïë
    """

    def __init__(self):
        self.logger = get_logger("SectorDefinitions")

        # ÏïîÌò∏ÌôîÌèê ÏÑπÌÑ∞ Ï†ïÏùò
        self.crypto_sectors = {
            'LAYER1': {
                'name': 'Layer 1 Blockchains',
                'description': 'Base layer blockchain protocols',
                'assets': ['BTCUSDT', 'ETHUSDT', 'SOLUSDT', 'AVAXUSDT', 'ADAUSDT', 'DOTUSDT'],
                'risk_profile': 'MODERATE',
                'category': 'CORE'
            },
            'LAYER2': {
                'name': 'Layer 2 Scaling',
                'description': 'Layer 2 scaling solutions',
                'assets': ['MATICUSDT', 'ARBUSDT', 'OPUSDT'],
                'risk_profile': 'HIGH',
                'category': 'GROWTH'
            },
            'DEFI': {
                'name': 'Decentralized Finance',
                'description': 'DeFi protocols and applications',
                'assets': ['UNIUSDT', 'AAVEUSDT', 'MKRUSDT', 'COMPUSDT', 'SUSHIUSDT'],
                'risk_profile': 'HIGH',
                'category': 'GROWTH'
            },
            'NFT_GAMING': {
                'name': 'NFT & Gaming',
                'description': 'NFT platforms and gaming tokens',
                'assets': ['AXSUSDT', 'SANDUSDT', 'MANAUSDT', 'ENJUSDT', 'GALAUSDT'],
                'risk_profile': 'VERY_HIGH',
                'category': 'SPECULATIVE'
            },
            'EXCHANGE': {
                'name': 'Exchange Tokens',
                'description': 'Cryptocurrency exchange tokens',
                'assets': ['BNBUSDT', 'CAKEUSDT', 'FTMUSDT'],
                'risk_profile': 'MODERATE',
                'category': 'CORE'
            },
            'PRIVACY': {
                'name': 'Privacy Coins',
                'description': 'Privacy-focused cryptocurrencies',
                'assets': ['XMRUSDT', 'ZECUSDT', 'DASHUSDT'],
                'risk_profile': 'HIGH',
                'category': 'DEFENSIVE'
            },
            'ORACLE': {
                'name': 'Oracle Networks',
                'description': 'Blockchain oracle services',
                'assets': ['LINKUSDT', 'BANDUSDT'],
                'risk_profile': 'MODERATE',
                'category': 'GROWTH'
            },
            'MEME': {
                'name': 'Meme Coins',
                'description': 'Community-driven meme tokens',
                'assets': ['DOGEUSDT', 'SHIBUSDT', 'PEPEUSDT'],
                'risk_profile': 'VERY_HIGH',
                'category': 'SPECULATIVE'
            },
            'STABLECOIN': {
                'name': 'Stablecoins',
                'description': 'Price-stable cryptocurrencies',
                'assets': ['USDTUSDT', 'USDCUSDT', 'DAIUSDT', 'BUSDUSDT'],
                'risk_profile': 'LOW',
                'category': 'DEFENSIVE'
            }
        }

        # Ï†ÑÌÜµ ÏãúÏû• ÏÑπÌÑ∞ (Ï∞∏Í≥†Ïö©)
        self.traditional_sectors = {
            'TECHNOLOGY': {
                'name': 'Technology',
                'description': 'Technology companies',
                'risk_profile': 'MODERATE_HIGH',
                'category': 'GROWTH',
                'correlation_to_crypto': 'HIGH'
            },
            'FINANCE': {
                'name': 'Finance',
                'description': 'Financial services',
                'risk_profile': 'MODERATE',
                'category': 'CYCLICAL',
                'correlation_to_crypto': 'MODERATE'
            },
            'ENERGY': {
                'name': 'Energy',
                'description': 'Energy sector',
                'risk_profile': 'MODERATE',
                'category': 'CYCLICAL',
                'correlation_to_crypto': 'LOW'
            },
            'HEALTHCARE': {
                'name': 'Healthcare',
                'description': 'Healthcare and pharmaceuticals',
                'risk_profile': 'LOW_MODERATE',
                'category': 'DEFENSIVE',
                'correlation_to_crypto': 'LOW'
            },
            'CONSUMER_STAPLES': {
                'name': 'Consumer Staples',
                'description': 'Essential consumer goods',
                'risk_profile': 'LOW',
                'category': 'DEFENSIVE',
                'correlation_to_crypto': 'VERY_LOW'
            },
            'UTILITIES': {
                'name': 'Utilities',
                'description': 'Utility companies',
                'risk_profile': 'LOW',
                'category': 'DEFENSIVE',
                'correlation_to_crypto': 'VERY_LOW'
            }
        }

        # ÏÑπÌÑ∞ Ïπ¥ÌÖåÍ≥†Î¶¨ Ï†ïÏùò
        self.sector_categories = {
            'CORE': {
                'description': 'Core holdings with established track record',
                'typical_allocation': 0.40,
                'risk_level': 'MODERATE'
            },
            'GROWTH': {
                'description': 'Growth-oriented sectors with higher potential',
                'typical_allocation': 0.30,
                'risk_level': 'HIGH'
            },
            'SPECULATIVE': {
                'description': 'High-risk, high-reward speculative plays',
                'typical_allocation': 0.15,
                'risk_level': 'VERY_HIGH'
            },
            'DEFENSIVE': {
                'description': 'Defensive assets for risk management',
                'typical_allocation': 0.15,
                'risk_level': 'LOW'
            }
        }

        # Î¶¨Ïä§ÌÅ¨ ÌîÑÎ°úÌååÏùº Ï†êÏàò
        self.risk_scores = {
            'VERY_LOW': 1,
            'LOW': 2,
            'LOW_MODERATE': 3,
            'MODERATE': 4,
            'MODERATE_HIGH': 5,
            'HIGH': 6,
            'VERY_HIGH': 7
        }

    def get_sector_info(self, sector_id: str) -> Dict[str, Any]:
        """ÏÑπÌÑ∞ Ï†ïÎ≥¥ Ï°∞Ìöå"""
        if sector_id in self.crypto_sectors:
            return self.crypto_sectors[sector_id]
        elif sector_id in self.traditional_sectors:
            return self.traditional_sectors[sector_id]
        else:
            return {}

    def get_asset_sector(self, asset: str) -> Optional[str]:
        """ÏûêÏÇ∞Ïùò ÏÑπÌÑ∞ Ï°∞Ìöå"""
        for sector_id, sector_info in self.crypto_sectors.items():
            if asset in sector_info['assets']:
                return sector_id
        return None

    def get_sectors_by_category(self, category: str) -> List[str]:
        """Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ ÏÑπÌÑ∞ Î™©Î°ù"""
        sectors = []
        for sector_id, sector_info in self.crypto_sectors.items():
            if sector_info['category'] == category:
                sectors.append(sector_id)
        return sectors

    def get_sectors_by_risk(self, min_risk: str, max_risk: str) -> List[str]:
        """Î¶¨Ïä§ÌÅ¨ Î≤îÏúÑÎ≥Ñ ÏÑπÌÑ∞ Î™©Î°ù"""
        min_score = self.risk_scores.get(min_risk, 0)
        max_score = self.risk_scores.get(max_risk, 10)

        sectors = []
        for sector_id, sector_info in self.crypto_sectors.items():
            risk_profile = sector_info['risk_profile']
            risk_score = self.risk_scores.get(risk_profile, 0)
            if min_score <= risk_score <= max_score:
                sectors.append(sector_id)

        return sectors

    def get_all_crypto_sectors(self) -> List[str]:
        """Î™®Îì† ÏïîÌò∏ÌôîÌèê ÏÑπÌÑ∞ Î™©Î°ù"""
        return list(self.crypto_sectors.keys())

    def get_sector_assets(self, sector_id: str) -> List[str]:
        """ÏÑπÌÑ∞Ïùò ÏûêÏÇ∞ Î™©Î°ù"""
        sector_info = self.get_sector_info(sector_id)
        return sector_info.get('assets', [])


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# v12.0 Í∏∞Ï°¥ ÌÅ¥ÎûòÏä§Îì§ (AssetDataManager, CorrelationCalculator Îì±)
# (Î¨∏ÏÑúÏóêÏÑú Ï†úÍ≥µÎêú v12.0 Ï†ÑÏ≤¥ ÏΩîÎìú Ìè¨Ìï® - 100% Ïú†ÏßÄ)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class AssetDataManager:
    """üåê Îã§Ï§ë ÏûêÏÇ∞ Îç∞Ïù¥ÌÑ∞ Í¥ÄÎ¶¨Ïûê (v12.0 Ïú†ÏßÄ)"""

    def __init__(self, market_data_manager):
        self.market_data = market_data_manager
        self.logger = get_logger("AssetDataManager")
        self.validator = DataValidator()

        self.crypto_assets = [
            'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'XRPUSDT', 'ADAUSDT',
            'SOLUSDT', 'DOGEUSDT', 'MATICUSDT', 'DOTUSDT', 'AVAXUSDT'
        ]

        self.traditional_assets = {
            'SPX': 'S&P 500',
            'DXY': 'US Dollar Index',
            'GOLD': 'Gold',
            'US10Y': 'US 10Y Treasury',
            'VIX': 'Volatility Index'
        }

        self._price_cache = {}
        self._returns_cache = {}
        self._cache_ttl = ProductionConfig.CACHE_TTL_SHORT

        self.price_history = defaultdict(lambda: deque(maxlen=1000))
        self.returns_history = defaultdict(lambda: deque(maxlen=1000))

        self.api_call_count = 0
        self.cache_hit_count = 0
        self.error_count = 0

    def get_asset_prices(self, symbols: List[str],
                         timeframe: str = '1h',
                         lookback: int = 100) -> pd.DataFrame:
        """Ïó¨Îü¨ ÏûêÏÇ∞Ïùò Í∞ÄÍ≤© Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞"""
        start_time = datetime.now()

        try:
            cache_key = f"prices_{'-'.join(symbols)}_{timeframe}_{lookback}"

            if cache_key in self._price_cache:
                data, timestamp = self._price_cache[cache_key]
                if (datetime.now() - timestamp).total_seconds() < self._cache_ttl:
                    self.cache_hit_count += 1
                    return data

            self.api_call_count += 1

            all_prices = {}

            for symbol in symbols:
                try:
                    if symbol in self.crypto_assets:
                        df = self.market_data.get_candle_data(symbol, timeframe)
                        if df is not None and not df.empty:
                            prices = df['close'].tail(lookback)
                            all_prices[symbol] = prices
                    elif symbol in self.traditional_assets:
                        prices = self._simulate_traditional_asset_prices(symbol, lookback)
                        all_prices[symbol] = prices

                except Exception as e:
                    self.logger.warning(f"Failed to get prices for {symbol}: {e}")
                    continue

            if not all_prices:
                raise ValueError("No price data collected")

            df = pd.DataFrame(all_prices)
            df = df.fillna(method='ffill').fillna(method='bfill')

            if not self.validator.validate_dataframe(df, list(df.columns), min_rows=10):
                raise ValueError("Invalid price dataframe")

            self._price_cache[cache_key] = (df, datetime.now())

            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('get_asset_prices', latency)

            return df

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Asset prices collection error: {e}")
            performance_monitor.record_error('get_asset_prices', e)
            return pd.DataFrame()

    def calculate_returns(self, prices: pd.DataFrame,
                          method: str = 'simple') -> pd.DataFrame:
        """ÏàòÏùµÎ•† Í≥ÑÏÇ∞"""
        try:
            if prices.empty:
                return pd.DataFrame()

            if method == 'log':
                returns = np.log(prices / prices.shift(1))
            else:
                returns = prices.pct_change()

            returns = returns.iloc[1:]

            for col in returns.columns:
                outliers = self.validator.detect_outliers(returns[col].values)
                if len(outliers) > 0:
                    returns.loc[returns.index[outliers], col] = np.nan

            returns = returns.fillna(0)

            return returns

        except Exception as e:
            self.logger.error(f"Returns calculation error: {e}")
            return pd.DataFrame()

    def _simulate_traditional_asset_prices(self, symbol: str, lookback: int) -> pd.Series:
        """Ï†ÑÌÜµ ÏûêÏÇ∞ Í∞ÄÍ≤© ÏãúÎÆ¨Î†àÏù¥ÏÖò"""
        try:
            base_prices = {
                'SPX': 4500,
                'DXY': 104,
                'GOLD': 2000,
                'US10Y': 4.5,
                'VIX': 15
            }

            volatilities = {
                'SPX': 0.15,
                'DXY': 0.05,
                'GOLD': 0.12,
                'US10Y': 0.20,
                'VIX': 0.40
            }

            base = base_prices.get(symbol, 100)
            vol = volatilities.get(symbol, 0.20)

            returns = np.random.normal(0.0001, vol / np.sqrt(252), lookback)
            prices = base * np.exp(np.cumsum(returns))

            end_date = datetime.now()
            dates = pd.date_range(end=end_date, periods=lookback, freq='1H')

            return pd.Series(prices, index=dates)

        except Exception as e:
            self.logger.error(f"Price simulation error: {e}")
            return pd.Series()

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ÏÑ±Îä• Î©îÌä∏Î¶≠"""
        cache_hit_rate = (
                self.cache_hit_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'cache_hits': self.cache_hit_count,
            'cache_hit_rate': cache_hit_rate,
            'errors': self.error_count,
            'error_rate': error_rate
        }

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# v12.0 Markov Chain, HMM Îì± Î™®Îì† Í∏∞Ï°¥ ÌÅ¥ÎûòÏä§ (100% Ïú†ÏßÄ)
# (Ïã§Ï†ú Íµ¨ÌòÑÏóêÏÑúÎäî v12.0Ïùò Î™®Îì† ÌÅ¥ÎûòÏä§Î•º Ïó¨Í∏∞Ïóê Ìè¨Ìï®)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# NOTE: Ïó¨Í∏∞Ïóê v12.0Ïùò Î™®Îì† ÌÅ¥ÎûòÏä§Îì§Ïù¥ Ìè¨Ìï®Îê®
# - MarkovChainTransitionAnalyzer
# - HiddenMarkovModelPredictor
# - ConditionalTransitionAnalyzer
# - BayesianTransitionUpdater
# - EnsembleTransitionPredictor
# - TransitionSignalDetector
# - RegimeTransitionPredictorV12
# Îì±Îì±...

# (Î¨∏ÏÑú Í∏∏Ïù¥ Ï†úÌïúÏúºÎ°ú ÏùºÎ∂ÄÎßå ÌëúÏãú)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# END OF PART 1/8
# Îã§Ïùå: Part 2 - Sector Data Manager & Performance Analyzer
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üî•üî•üî• MARKET REGIME ANALYZER 13.0 - PART 2/8 üî•üî•üî•
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Part 2: Sector Data Manager & Sector Performance Analyzer
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Part 1ÏóêÏÑú Í≥ÑÏÜç...

class SectorDataManager:
    """
    üìä ÏÑπÌÑ∞ Îç∞Ïù¥ÌÑ∞ Í¥ÄÎ¶¨Ïûê (v13.0 NEW - ÌîÑÎ°úÎçïÏÖò Î†àÎ≤®)

    ÏÑπÌÑ∞Î≥Ñ Í∞ÄÍ≤© Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Î∞è Í¥ÄÎ¶¨
    """

    def __init__(self, market_data_manager, sector_definitions: SectorDefinitions):
        self.market_data = market_data_manager
        self.sector_defs = sector_definitions
        self.logger = get_logger("SectorDataManager")
        self.validator = DataValidator()

        # Ï∫êÏãú
        self._sector_prices_cache = {}
        self._sector_returns_cache = {}
        self._cache_ttl = ProductionConfig.CACHE_TTL_MEDIUM

        # ÌûàÏä§ÌÜ†Î¶¨
        self.sector_price_history = defaultdict(lambda: deque(maxlen=2000))
        self.sector_returns_history = defaultdict(lambda: deque(maxlen=2000))

        # ÏÑ±Îä• Î©îÌä∏Î¶≠
        self.api_call_count = 0
        self.cache_hit_count = 0
        self.error_count = 0

    def get_sector_prices(self, sector_id: str,
                          timeframe: str = '1h',
                          lookback: int = 720) -> pd.DataFrame:
        """
        ÏÑπÌÑ∞Ïùò Î™®Îì† ÏûêÏÇ∞ Í∞ÄÍ≤© Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞

        Args:
            sector_id: ÏÑπÌÑ∞ ID
            timeframe: ÏãúÍ∞Ñ ÌîÑÎ†àÏûÑ
            lookback: Ï°∞Ìöå Í∏∞Í∞Ñ

        Returns:
            ÏÑπÌÑ∞ ÏûêÏÇ∞ Í∞ÄÍ≤© DataFrame
        """
        start_time = datetime.now()

        try:
            # Ï∫êÏãú ÌôïÏù∏
            cache_key = f"sector_prices_{sector_id}_{timeframe}_{lookback}"
            if cache_key in self._sector_prices_cache:
                data, timestamp = self._sector_prices_cache[cache_key]
                if (datetime.now() - timestamp).total_seconds() < self._cache_ttl:
                    self.cache_hit_count += 1
                    return data

            self.api_call_count += 1

            # ÏÑπÌÑ∞ ÏûêÏÇ∞ Î™©Î°ù
            assets = self.sector_defs.get_sector_assets(sector_id)

            if not assets:
                raise ValueError(f"No assets found for sector: {sector_id}")

            # Í∞Å ÏûêÏÇ∞Ïùò Í∞ÄÍ≤© ÏàòÏßë
            all_prices = {}

            for asset in assets:
                try:
                    df = self.market_data.get_candle_data(asset, timeframe)
                    if df is not None and not df.empty:
                        prices = df['close'].tail(lookback)
                        all_prices[asset] = prices
                except Exception as e:
                    self.logger.warning(f"Failed to get prices for {asset}: {e}")
                    continue

            if not all_prices:
                raise ValueError(f"No price data collected for sector: {sector_id}")

            # DataFrame ÏÉùÏÑ±
            df = pd.DataFrame(all_prices)
            df = df.fillna(method='ffill').fillna(method='bfill')

            # Í≤ÄÏ¶ù
            if len(df) < ProductionConfig.MIN_DATA_POINTS:
                raise ValueError(
                    f"Insufficient data points: {len(df)} < "
                    f"{ProductionConfig.MIN_DATA_POINTS}"
                )

            # Ï∫êÏãú Ï†ÄÏû•
            self._sector_prices_cache[cache_key] = (df, datetime.now())

            # ÌûàÏä§ÌÜ†Î¶¨ Ï†ÄÏû•
            for asset in df.columns:
                for idx, price in df[asset].items():
                    self.sector_price_history[f"{sector_id}_{asset}"].append({
                        'timestamp': idx,
                        'price': price
                    })

            # ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('get_sector_prices', latency)

            return df

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Get sector prices error for {sector_id}: {e}")
            performance_monitor.record_error('get_sector_prices', e)
            return pd.DataFrame()

    def get_sector_returns(self, sector_id: str,
                           timeframe: str = '1h',
                           lookback: int = 720,
                           method: str = 'simple') -> pd.DataFrame:
        """
        ÏÑπÌÑ∞ ÏûêÏÇ∞Ïùò ÏàòÏùµÎ•† Í≥ÑÏÇ∞

        Args:
            sector_id: ÏÑπÌÑ∞ ID
            timeframe: ÏãúÍ∞Ñ ÌîÑÎ†àÏûÑ
            lookback: Ï°∞Ìöå Í∏∞Í∞Ñ
            method: ÏàòÏùµÎ•† Í≥ÑÏÇ∞ Î∞©Î≤ï ('simple' or 'log')

        Returns:
            ÏÑπÌÑ∞ ÏûêÏÇ∞ ÏàòÏùµÎ•† DataFrame
        """
        try:
            # Í∞ÄÍ≤© Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞
            prices = self.get_sector_prices(sector_id, timeframe, lookback)

            if prices.empty:
                return pd.DataFrame()

            # ÏàòÏùµÎ•† Í≥ÑÏÇ∞
            if method == 'log':
                returns = np.log(prices / prices.shift(1))
            else:
                returns = prices.pct_change()

            returns = returns.iloc[1:]

            # Ïù¥ÏÉÅÏπò Ï†úÍ±∞
            for col in returns.columns:
                outliers = self.validator.detect_outliers(returns[col].values)
                if len(outliers) > 0:
                    returns.loc[returns.index[outliers], col] = np.nan

            returns = returns.fillna(0)

            return returns

        except Exception as e:
            self.logger.error(f"Get sector returns error for {sector_id}: {e}")
            return pd.DataFrame()

    def get_sector_index(self, sector_id: str,
                         timeframe: str = '1h',
                         lookback: int = 720,
                         method: str = 'equal_weight') -> pd.Series:
        """
        ÏÑπÌÑ∞ Ïù∏Îç±Ïä§ Í≥ÑÏÇ∞ (ÏÑπÌÑ∞ Ï†ÑÏ≤¥ ÏÑ±Í≥º ÎåÄÌëú)

        Args:
            sector_id: ÏÑπÌÑ∞ ID
            timeframe: ÏãúÍ∞Ñ ÌîÑÎ†àÏûÑ
            lookback: Ï°∞Ìöå Í∏∞Í∞Ñ
            method: Ïù∏Îç±Ïä§ Í≥ÑÏÇ∞ Î∞©Î≤ï ('equal_weight', 'market_cap', 'volume')

        Returns:
            ÏÑπÌÑ∞ Ïù∏Îç±Ïä§ Series
        """
        try:
            prices = self.get_sector_prices(sector_id, timeframe, lookback)

            if prices.empty:
                return pd.Series()

            if method == 'equal_weight':
                # ÎèôÏùº Í∞ÄÏ§ë ÌèâÍ∑†
                sector_index = prices.mean(axis=1)

            elif method == 'market_cap':
                # ÏãúÍ∞ÄÏ¥ùÏï° Í∞ÄÏ§ë (Í∞ÑÏÜåÌôî: Í∞ÄÍ≤© Í∏∞Î∞ò Í∞ÄÏ§ë)
                weights = prices.iloc[-1] / prices.iloc[-1].sum()
                sector_index = (prices * weights).sum(axis=1)

            elif method == 'volume':
                # Í±∞ÎûòÎüâ Í∞ÄÏ§ë (Í∞ÑÏÜåÌôî: ÎèôÏùº Í∞ÄÏ§ë)
                sector_index = prices.mean(axis=1)

            else:
                sector_index = prices.mean(axis=1)

            # Ï†ïÍ∑úÌôî (Ï≤´ Í∞í = 100)
            sector_index = 100 * sector_index / sector_index.iloc[0]

            return sector_index

        except Exception as e:
            self.logger.error(f"Get sector index error for {sector_id}: {e}")
            return pd.Series()

    def get_all_sectors_data(self, timeframe: str = '1h',
                             lookback: int = 720) -> Dict[str, pd.DataFrame]:
        """
        Î™®Îì† ÏÑπÌÑ∞Ïùò Îç∞Ïù¥ÌÑ∞ Ìïú Î≤àÏóê Í∞ÄÏ†∏Ïò§Í∏∞

        Args:
            timeframe: ÏãúÍ∞Ñ ÌîÑÎ†àÏûÑ
            lookback: Ï°∞Ìöå Í∏∞Í∞Ñ

        Returns:
            ÏÑπÌÑ∞Î≥Ñ Í∞ÄÍ≤© DataFrame ÎîïÏÖîÎÑàÎ¶¨
        """
        all_sectors = self.sector_defs.get_all_crypto_sectors()
        sectors_data = {}

        for sector_id in all_sectors:
            try:
                df = self.get_sector_prices(sector_id, timeframe, lookback)
                if not df.empty:
                    sectors_data[sector_id] = df
            except Exception as e:
                self.logger.warning(f"Failed to get data for sector {sector_id}: {e}")
                continue

        return sectors_data

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ÏÑ±Îä• Î©îÌä∏Î¶≠"""
        cache_hit_rate = (
                self.cache_hit_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'cache_hits': self.cache_hit_count,
            'cache_hit_rate': cache_hit_rate,
            'errors': self.error_count,
            'error_rate': error_rate
        }


class SectorPerformanceAnalyzer:
    """
    üìà ÏÑπÌÑ∞ ÏÑ±Í≥º Î∂ÑÏÑùÍ∏∞ (v13.0 NEW - ÌîÑÎ°úÎçïÏÖò Î†àÎ≤®)

    ÏÑπÌÑ∞Î≥Ñ ÏÑ±Í≥º ÏßÄÌëú Í≥ÑÏÇ∞ Î∞è ÏÉÅÎåÄ Í∞ïÎèÑ Î∂ÑÏÑù
    """

    def __init__(self, sector_data_manager: SectorDataManager,
                 sector_definitions: SectorDefinitions):
        self.sector_data = sector_data_manager
        self.sector_defs = sector_definitions
        self.logger = get_logger("SectorPerformanceAnalyzer")
        self.validator = DataValidator()

        # ÏÑ±Í≥º ÌûàÏä§ÌÜ†Î¶¨
        self.performance_history = deque(maxlen=1000)

        # ÏÑ±Îä• Î©îÌä∏Î¶≠
        self.api_call_count = 0
        self.error_count = 0

    def calculate_sector_performance(self, sector_id: str,
                                     period_days: int = 7) -> Dict[str, Any]:
        """
        ÏÑπÌÑ∞ ÏÑ±Í≥º Í≥ÑÏÇ∞

        Args:
            sector_id: ÏÑπÌÑ∞ ID
            period_days: Î∂ÑÏÑù Í∏∞Í∞Ñ (Ïùº)

        Returns:
            ÏÑπÌÑ∞ ÏÑ±Í≥º Î©îÌä∏Î¶≠
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            # Îç∞Ïù¥ÌÑ∞ Ï°∞Ìöå (1ÏãúÍ∞ÑÎ¥â Í∏∞Ï§Ä)
            lookback = period_days * 24
            sector_index = self.sector_data.get_sector_index(
                sector_id, '1h', lookback
            )

            if sector_index.empty or len(sector_index) < 2:
                raise ValueError(f"Insufficient data for sector: {sector_id}")

            # ÏàòÏùµÎ•† Í≥ÑÏÇ∞
            total_return = (sector_index.iloc[-1] / sector_index.iloc[0] - 1.0)

            # ÏùºÎ≥Ñ ÏàòÏùµÎ•†
            daily_returns = sector_index.pct_change().dropna()

            # Î≥ÄÎèôÏÑ±
            volatility = daily_returns.std() * np.sqrt(24 * period_days)

            # ÏÉ§ÌîÑ ÎπÑÏú® (Î¨¥ÏúÑÌóò Ïù¥ÏûêÏú® = 0 Í∞ÄÏ†ï)
            sharpe_ratio = (
                (total_return / volatility) if volatility > 0 else 0
            )

            # ÏµúÎåÄ ÎÇôÌè≠ (Maximum Drawdown)
            cumulative = (1 + daily_returns).cumprod()
            running_max = cumulative.expanding().max()
            drawdown = (cumulative - running_max) / running_max
            max_drawdown = drawdown.min()

            # ÏäπÎ•† (ÏñëÏùò ÏàòÏùµÎ•† ÎπÑÏú®)
            win_rate = (daily_returns > 0).sum() / len(daily_returns)

            # ÏµúÍ∑º Î™®Î©òÌÖÄ (ÏµúÍ∑º 7Ïùº vs Ïù¥Ï†Ñ 7Ïùº)
            half_period = lookback // 2
            if len(sector_index) >= lookback:
                recent_return = (
                        sector_index.iloc[-1] / sector_index.iloc[-half_period] - 1.0
                )
                previous_return = (
                        sector_index.iloc[-half_period] / sector_index.iloc[0] - 1.0
                )
                momentum = recent_return - previous_return
            else:
                momentum = 0.0

            # Ìä∏Î†åÎìú Í∞ïÎèÑ (ÏÑ†Ìòï ÌöåÍ∑Ä Í∏∞Ïö∏Í∏∞)
            x = np.arange(len(sector_index))
            y = sector_index.values
            slope, _, r_value, _, _ = stats.linregress(x, y)
            trend_strength = r_value ** 2  # R-squared

            # ÏÉÅÎåÄ Í∞ïÎèÑ Ï†êÏàò (0~100)
            # ÏàòÏùµÎ•†, ÏÉ§ÌîÑ, Ìä∏Î†åÎìú Í∞ïÎèÑ Í≤∞Ìï©
            relative_strength = self._calculate_relative_strength(
                total_return, sharpe_ratio, trend_strength
            )

            result = {
                'sector_id': sector_id,
                'period_days': period_days,
                'total_return': float(total_return),
                'annualized_return': float(total_return * (365 / period_days)),
                'volatility': float(volatility),
                'sharpe_ratio': float(sharpe_ratio),
                'max_drawdown': float(max_drawdown),
                'win_rate': float(win_rate),
                'momentum': float(momentum),
                'trend_strength': float(trend_strength),
                'relative_strength': float(relative_strength),
                'current_index_value': float(sector_index.iloc[-1]),
                'timestamp': datetime.now()
            }

            # ÌûàÏä§ÌÜ†Î¶¨
            self.performance_history.append(result)

            # ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('calculate_sector_performance', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Sector performance calculation error for {sector_id}: {e}")
            performance_monitor.record_error('calculate_sector_performance', e)

            return {
                'sector_id': sector_id,
                'period_days': period_days,
                'total_return': 0.0,
                'relative_strength': 50.0,
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def calculate_all_sectors_performance(self, period_days: int = 7) -> Dict[str, Dict]:
        """
        Î™®Îì† ÏÑπÌÑ∞Ïùò ÏÑ±Í≥º Í≥ÑÏÇ∞

        Args:
            period_days: Î∂ÑÏÑù Í∏∞Í∞Ñ

        Returns:
            ÏÑπÌÑ∞Î≥Ñ ÏÑ±Í≥º ÎîïÏÖîÎÑàÎ¶¨
        """
        all_sectors = self.sector_defs.get_all_crypto_sectors()
        performances = {}

        for sector_id in all_sectors:
            try:
                perf = self.calculate_sector_performance(sector_id, period_days)
                performances[sector_id] = perf
            except Exception as e:
                self.logger.warning(f"Failed to calculate performance for {sector_id}: {e}")
                continue

        return performances

    def rank_sectors_by_performance(self, period_days: int = 7,
                                    metric: str = 'relative_strength') -> List[Dict]:
        """
        ÏÑ±Í≥º ÏßÄÌëúÎ≥Ñ ÏÑπÌÑ∞ Îû≠ÌÇπ

        Args:
            period_days: Î∂ÑÏÑù Í∏∞Í∞Ñ
            metric: Îû≠ÌÇπ Í∏∞Ï§Ä ('relative_strength', 'total_return', 'sharpe_ratio', etc.)

        Returns:
            Ï†ïÎ†¨Îêú ÏÑπÌÑ∞ Î¶¨Ïä§Ìä∏
        """
        try:
            performances = self.calculate_all_sectors_performance(period_days)

            # Î©îÌä∏Î¶≠ Í∏∞Ï§Ä Ï†ïÎ†¨
            ranked = sorted(
                performances.values(),
                key=lambda x: x.get(metric, 0),
                reverse=True
            )

            return ranked

        except Exception as e:
            self.logger.error(f"Rank sectors error: {e}")
            return []

    def calculate_sector_correlation_matrix(self, period_days: int = 30) -> pd.DataFrame:
        """
        ÏÑπÌÑ∞ Í∞Ñ ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ ÌñâÎ†¨

        Args:
            period_days: Î∂ÑÏÑù Í∏∞Í∞Ñ

        Returns:
            ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ ÌñâÎ†¨ DataFrame
        """
        try:
            lookback = period_days * 24
            all_sectors = self.sector_defs.get_all_crypto_sectors()

            # Í∞Å ÏÑπÌÑ∞Ïùò Ïù∏Îç±Ïä§ ÏàòÏùµÎ•†
            sector_returns = {}

            for sector_id in all_sectors:
                sector_index = self.sector_data.get_sector_index(
                    sector_id, '1h', lookback
                )

                if not sector_index.empty:
                    returns = sector_index.pct_change().dropna()
                    sector_returns[sector_id] = returns

            # DataFrame ÏÉùÏÑ±
            df = pd.DataFrame(sector_returns)

            if df.empty:
                return pd.DataFrame()

            # ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ Í≥ÑÏÇ∞
            corr_matrix = df.corr(method='pearson')

            return corr_matrix

        except Exception as e:
            self.logger.error(f"Sector correlation matrix error: {e}")
            return pd.DataFrame()

    def identify_leading_lagging_sectors(self, period_days: int = 7) -> Dict[str, List[str]]:
        """
        ÏÑ†ÎèÑ/ÌõÑÌñâ ÏÑπÌÑ∞ ÏãùÎ≥Ñ

        Args:
            period_days: Î∂ÑÏÑù Í∏∞Í∞Ñ

        Returns:
            {'leading': [...], 'lagging': [...]}
        """
        try:
            # ÏÑ±Í≥º Îû≠ÌÇπ
            ranked = self.rank_sectors_by_performance(period_days, 'relative_strength')

            if not ranked:
                return {'leading': [], 'lagging': []}

            # ÏÉÅÏúÑ 25% = ÏÑ†ÎèÑ, ÌïòÏúÑ 25% = ÌõÑÌñâ
            n = len(ranked)
            top_n = max(1, n // 4)

            leading = [s['sector_id'] for s in ranked[:top_n]]
            lagging = [s['sector_id'] for s in ranked[-top_n:]]

            return {
                'leading': leading,
                'lagging': lagging,
                'midfield': [s['sector_id'] for s in ranked[top_n:-top_n]]
            }

        except Exception as e:
            self.logger.error(f"Identify leading/lagging sectors error: {e}")
            return {'leading': [], 'lagging': []}

    def _calculate_relative_strength(self, total_return: float,
                                     sharpe_ratio: float,
                                     trend_strength: float) -> float:
        """
        ÏÉÅÎåÄ Í∞ïÎèÑ Ï†êÏàò Í≥ÑÏÇ∞ (0~100)

        Í≤∞Ìï© ÏßÄÌëú:
        - ÏàòÏùµÎ•† (40%)
        - ÏÉ§ÌîÑ ÎπÑÏú® (30%)
        - Ìä∏Î†åÎìú Í∞ïÎèÑ (30%)
        """
        try:
            # ÏàòÏùµÎ•† Ï†êÏàò (Ï†ïÍ∑úÌôî)
            return_score = 50 + min(max(total_return * 100, -50), 50)

            # ÏÉ§ÌîÑ ÎπÑÏú® Ï†êÏàò
            sharpe_score = 50 + min(max(sharpe_ratio * 10, -50), 50)

            # Ìä∏Î†åÎìú Í∞ïÎèÑ Ï†êÏàò
            trend_score = trend_strength * 100

            # Í∞ÄÏ§ë ÌèâÍ∑†
            relative_strength = (
                    0.40 * return_score +
                    0.30 * sharpe_score +
                    0.30 * trend_score
            )

            return np.clip(relative_strength, 0, 100)

        except Exception as e:
            self.logger.error(f"Calculate relative strength error: {e}")
            return 50.0

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ÏÑ±Îä• Î©îÌä∏Î¶≠"""
        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'errors': self.error_count,
            'error_rate': error_rate,
            'history_size': len(self.performance_history)
        }

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# END OF PART 2/8
# Îã§Ïùå: Part 3 - Sector Rotation Detector
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üî•üî•üî• MARKET REGIME ANALYZER 13.0 - PART 3/8 üî•üî•üî•
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Part 3: Sector Rotation Detector (Risk-On/Off, Cycle Detection)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Part 2ÏóêÏÑú Í≥ÑÏÜç...

class SectorRotationDetector:
    """
    üîÑ ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Í∞êÏßÄÍ∏∞ (v13.0 NEW - ÌîÑÎ°úÎçïÏÖò Î†àÎ≤®)

    ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Ìå®ÌÑ¥ Ïù∏Ïãù, Î¶¨Ïä§ÌÅ¨Ïò®/Ïò§ÌîÑ, ÏÇ¨Ïù¥ÌÅ¥ Í∞êÏßÄ
    """

    def __init__(self, sector_performance_analyzer: SectorPerformanceAnalyzer,
                 sector_definitions: SectorDefinitions):
        self.sector_perf = sector_performance_analyzer
        self.sector_defs = sector_definitions
        self.logger = get_logger("SectorRotationDetector")
        self.validator = DataValidator()

        # Î°úÌÖåÏù¥ÏÖò ÌûàÏä§ÌÜ†Î¶¨
        self.rotation_history = deque(maxlen=500)

        # ÌòÑÏû¨ ÏÉÅÌÉú
        self.current_rotation_state = None
        self.current_risk_appetite = None
        self.current_cycle_phase = None

        # ÏÑ±Îä• Î©îÌä∏Î¶≠
        self.api_call_count = 0
        self.error_count = 0

    def detect_sector_rotation(self, lookback_days: int = 7) -> Dict[str, Any]:
        """
        ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Í∞êÏßÄ

        Args:
            lookback_days: Î∂ÑÏÑù Í∏∞Í∞Ñ

        Returns:
            Î°úÌÖåÏù¥ÏÖò Î∂ÑÏÑù Í≤∞Í≥º
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            # Î™®Îì† ÏÑπÌÑ∞ ÏÑ±Í≥º Í≥ÑÏÇ∞
            performances = self.sector_perf.calculate_all_sectors_performance(lookback_days)

            if not performances:
                raise ValueError("No sector performance data available")

            # Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ ÏÑ±Í≥º
            category_performance = self._calculate_category_performance(performances)

            # Î¶¨Ïä§ÌÅ¨ ÌîÑÎ°úÌååÏùºÎ≥Ñ ÏÑ±Í≥º
            risk_performance = self._calculate_risk_profile_performance(performances)

            # Î°úÌÖåÏù¥ÏÖò Ìå®ÌÑ¥ Ïù∏Ïãù
            rotation_pattern = self._identify_rotation_pattern(
                category_performance, risk_performance
            )

            # Î¶¨Ïä§ÌÅ¨Ïò®/Ïò§ÌîÑ Í∞êÏßÄ
            risk_appetite = self._detect_risk_appetite(risk_performance)

            # ÏÇ¨Ïù¥ÌÅ¥ Îã®Í≥Ñ Í∞êÏßÄ
            cycle_phase = self._detect_market_cycle(
                category_performance, risk_appetite
            )

            # Î™®Î©òÌÖÄ Ï†ÑÌôò Í∞êÏßÄ
            momentum_shifts = self._detect_momentum_shifts(performances)

            # Ìï´ ÏÑπÌÑ∞ ÏãùÎ≥Ñ
            hot_sectors = self._identify_hot_sectors(performances)

            # ÏïΩÏÑ∏ ÏÑπÌÑ∞ ÏãùÎ≥Ñ
            weak_sectors = self._identify_weak_sectors(performances)

            result = {
                'rotation_pattern': rotation_pattern,
                'risk_appetite': risk_appetite,
                'cycle_phase': cycle_phase,
                'category_performance': category_performance,
                'risk_performance': risk_performance,
                'momentum_shifts': momentum_shifts,
                'hot_sectors': hot_sectors,
                'weak_sectors': weak_sectors,
                'sector_performances': performances,
                'analysis_period_days': lookback_days,
                'timestamp': datetime.now()
            }

            # ÏÉÅÌÉú ÏóÖÎç∞Ïù¥Ìä∏
            self.current_rotation_state = rotation_pattern
            self.current_risk_appetite = risk_appetite
            self.current_cycle_phase = cycle_phase

            # ÌûàÏä§ÌÜ†Î¶¨
            self.rotation_history.append(result)

            # ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('detect_sector_rotation', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Sector rotation detection error: {e}")
            performance_monitor.record_error('detect_sector_rotation', e)

            return {
                'rotation_pattern': 'UNCERTAIN',
                'risk_appetite': 'NEUTRAL',
                'cycle_phase': 'UNKNOWN',
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def _calculate_category_performance(self, performances: Dict[str, Dict]) -> Dict[str, float]:
        """Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ ÌèâÍ∑† ÏÑ±Í≥º"""
        category_scores = defaultdict(list)

        for sector_id, perf in performances.items():
            sector_info = self.sector_defs.get_sector_info(sector_id)
            category = sector_info.get('category')

            if category:
                relative_strength = perf.get('relative_strength', 50)
                category_scores[category].append(relative_strength)

        # ÌèâÍ∑† Í≥ÑÏÇ∞
        category_performance = {}
        for category, scores in category_scores.items():
            category_performance[category] = np.mean(scores) if scores else 50.0

        return category_performance

    def _calculate_risk_profile_performance(self, performances: Dict[str, Dict]) -> Dict[str, float]:
        """Î¶¨Ïä§ÌÅ¨ ÌîÑÎ°úÌååÏùºÎ≥Ñ ÌèâÍ∑† ÏÑ±Í≥º"""
        risk_scores = defaultdict(list)

        for sector_id, perf in performances.items():
            sector_info = self.sector_defs.get_sector_info(sector_id)
            risk_profile = sector_info.get('risk_profile')

            if risk_profile:
                relative_strength = perf.get('relative_strength', 50)
                risk_scores[risk_profile].append(relative_strength)

        # ÌèâÍ∑† Í≥ÑÏÇ∞
        risk_performance = {}
        for risk_profile, scores in risk_scores.items():
            risk_performance[risk_profile] = np.mean(scores) if scores else 50.0

        return risk_performance

    def _identify_rotation_pattern(self, category_perf: Dict[str, float],
                                   risk_perf: Dict[str, float]) -> str:
        """
        Î°úÌÖåÏù¥ÏÖò Ìå®ÌÑ¥ ÏãùÎ≥Ñ

        Ìå®ÌÑ¥ Ï¢ÖÎ•ò:
        - GROWTH_TO_VALUE: ÏÑ±Ïû•Ï£º -> Í∞ÄÏπòÏ£º
        - VALUE_TO_GROWTH: Í∞ÄÏπòÏ£º -> ÏÑ±Ïû•Ï£º
        - RISK_ON_ROTATION: Î¶¨Ïä§ÌÅ¨Ïò® (Í≥µÍ≤©Ï†Å -> Îçî Í≥µÍ≤©Ï†Å)
        - RISK_OFF_ROTATION: Î¶¨Ïä§ÌÅ¨Ïò§ÌîÑ (Í≥µÍ≤©Ï†Å -> Î∞©Ïñ¥Ï†Å)
        - SECTOR_DIVERGENCE: ÏÑπÌÑ∞ Î∂ÑÏÇ∞ (Î™ÖÌôïÌïú Ìå®ÌÑ¥ ÏóÜÏùå)
        - BROAD_RALLY: Ï†ÑÎ∞òÏ†Å ÏÉÅÏäπ
        - BROAD_DECLINE: Ï†ÑÎ∞òÏ†Å ÌïòÎùΩ
        - STABLE: ÏïàÏ†ïÏ†Å (Î°úÌÖåÏù¥ÏÖò ÏóÜÏùå)
        """
        try:
            # Ïπ¥ÌÖåÍ≥†Î¶¨ Ï†êÏàò
            core = category_perf.get('CORE', 50)
            growth = category_perf.get('GROWTH', 50)
            speculative = category_perf.get('SPECULATIVE', 50)
            defensive = category_perf.get('DEFENSIVE', 50)

            # Î¶¨Ïä§ÌÅ¨ Ï†êÏàò
            low_risk = risk_perf.get('LOW', 50)
            moderate_risk = risk_perf.get('MODERATE', 50)
            high_risk = risk_perf.get('HIGH', 50) + risk_perf.get('VERY_HIGH', 50)

            # Ï†ÑÏ≤¥ ÌèâÍ∑†
            overall_avg = np.mean(list(category_perf.values()))

            # Ìå®ÌÑ¥ Í∞êÏßÄ
            threshold = ProductionConfig.ROTATION_DETECTION_THRESHOLD * 100

            # 1. Ï†ÑÎ∞òÏ†Å ÏÉÅÏäπ/ÌïòÎùΩ
            if overall_avg > 65:
                return 'BROAD_RALLY'
            elif overall_avg < 35:
                return 'BROAD_DECLINE'

            # 2. Î¶¨Ïä§ÌÅ¨Ïò® Î°úÌÖåÏù¥ÏÖò (Í≥µÍ≤©Ï†Å ÏÑπÌÑ∞ Í∞ïÏÑ∏)
            if (speculative > 60 and growth > 55) and defensive < 45:
                return 'RISK_ON_ROTATION'

            # 3. Î¶¨Ïä§ÌÅ¨Ïò§ÌîÑ Î°úÌÖåÏù¥ÏÖò (Î∞©Ïñ¥Ï†Å ÏÑπÌÑ∞ Í∞ïÏÑ∏)
            if defensive > 60 and (speculative < 45 or growth < 45):
                return 'RISK_OFF_ROTATION'

            # 4. ÏÑ±Ïû•Ï£º -> Í∞ÄÏπòÏ£º
            if defensive > core > growth and speculative < 45:
                return 'GROWTH_TO_VALUE'

            # 5. Í∞ÄÏπòÏ£º -> ÏÑ±Ïû•Ï£º
            if growth > core > defensive and speculative > 50:
                return 'VALUE_TO_GROWTH'

            # 6. ÏÑπÌÑ∞ Î∂ÑÏÇ∞ (ÌëúÏ§ÄÌé∏Ï∞® ÌÅ∞ Í≤ΩÏö∞)
            category_std = np.std(list(category_perf.values()))
            if category_std > 15:
                return 'SECTOR_DIVERGENCE'

            # 7. ÏïàÏ†ïÏ†Å
            if abs(overall_avg - 50) < 10 and category_std < 10:
                return 'STABLE'

            return 'MIXED_PATTERN'

        except Exception as e:
            self.logger.error(f"Identify rotation pattern error: {e}")
            return 'UNCERTAIN'

    def _detect_risk_appetite(self, risk_perf: Dict[str, float]) -> str:
        """
        Î¶¨Ïä§ÌÅ¨ ÏÑ†Ìò∏ÎèÑ Í∞êÏßÄ

        Returns:
            'RISK_ON', 'RISK_OFF', 'NEUTRAL', 'TRANSITIONING'
        """
        try:
            # Í≥†ÏúÑÌóò ÏûêÏÇ∞ ÏÑ±Í≥º
            high_risk_avg = np.mean([
                risk_perf.get('HIGH', 50),
                risk_perf.get('VERY_HIGH', 50)
            ])

            # Ï†ÄÏúÑÌóò ÏûêÏÇ∞ ÏÑ±Í≥º
            low_risk_avg = np.mean([
                risk_perf.get('LOW', 50),
                risk_perf.get('LOW_MODERATE', 50)
            ])

            # Ï∞®Ïù¥
            risk_spread = high_risk_avg - low_risk_avg

            threshold = ProductionConfig.RISK_ON_OFF_THRESHOLD * 100

            if risk_spread > threshold:
                return 'RISK_ON'
            elif risk_spread < -threshold:
                return 'RISK_OFF'
            elif abs(risk_spread) < threshold * 0.5:
                return 'NEUTRAL'
            else:
                return 'TRANSITIONING'

        except Exception as e:
            self.logger.error(f"Detect risk appetite error: {e}")
            return 'NEUTRAL'

    def _detect_market_cycle(self, category_perf: Dict[str, float],
                             risk_appetite: str) -> str:
        """
        ÏãúÏû• ÏÇ¨Ïù¥ÌÅ¥ Îã®Í≥Ñ Í∞êÏßÄ

        Returns:
            'EARLY_CYCLE', 'MID_CYCLE', 'LATE_CYCLE', 'RECESSION', 'RECOVERY'
        """
        try:
            core = category_perf.get('CORE', 50)
            growth = category_perf.get('GROWTH', 50)
            speculative = category_perf.get('SPECULATIVE', 50)
            defensive = category_perf.get('DEFENSIVE', 50)

            # Early Cycle: ÏΩîÏñ¥ + ÏÑ±Ïû•Ï£º Í∞ïÏÑ∏, Î¶¨Ïä§ÌÅ¨Ïò®
            if core > 55 and growth > 55 and risk_appetite == 'RISK_ON':
                return 'EARLY_CYCLE'

            # Mid Cycle: ÏÑ±Ïû•Ï£º + Ìà¨Í∏∞Ï†Å Í∞ïÏÑ∏
            if growth > 60 and speculative > 55 and risk_appetite == 'RISK_ON':
                return 'MID_CYCLE'

            # Late Cycle: Ìà¨Í∏∞Ï†Å Í≥ºÏó¥, Î∞©Ïñ¥Ï†Å ÏÉÅÏäπ ÏãúÏûë
            if speculative > 65 and defensive > 50 and risk_appetite in ['RISK_ON', 'TRANSITIONING']:
                return 'LATE_CYCLE'

            # Recession: Î∞©Ïñ¥Ï†Å Í∞ïÏÑ∏, Î¶¨Ïä§ÌÅ¨Ïò§ÌîÑ
            if defensive > 60 and risk_appetite == 'RISK_OFF':
                return 'RECESSION'

            # Recovery: Î∞©Ïñ¥Ï†ÅÏóêÏÑú ÏΩîÏñ¥Î°ú Ï†ÑÌôò
            if defensive > 50 and core > 52 and risk_appetite in ['NEUTRAL', 'TRANSITIONING']:
                return 'RECOVERY'

            return 'UNCERTAIN'

        except Exception as e:
            self.logger.error(f"Detect market cycle error: {e}")
            return 'UNCERTAIN'

    def _detect_momentum_shifts(self, performances: Dict[str, Dict]) -> List[Dict]:
        """
        Î™®Î©òÌÖÄ Ï†ÑÌôò Í∞êÏßÄ (Í∏âÎì±/Í∏âÎùΩ ÏÑπÌÑ∞)
        """
        shifts = []

        for sector_id, perf in performances.items():
            momentum = perf.get('momentum', 0)
            relative_strength = perf.get('relative_strength', 50)

            # Í∞ïÌïú ÏñëÏùò Î™®Î©òÌÖÄ
            if momentum > 0.05 and relative_strength > 60:
                shifts.append({
                    'sector_id': sector_id,
                    'type': 'STRONG_POSITIVE',
                    'momentum': momentum,
                    'relative_strength': relative_strength
                })

            # Í∞ïÌïú ÏùåÏùò Î™®Î©òÌÖÄ
            elif momentum < -0.05 and relative_strength < 40:
                shifts.append({
                    'sector_id': sector_id,
                    'type': 'STRONG_NEGATIVE',
                    'momentum': momentum,
                    'relative_strength': relative_strength
                })

        # Î™®Î©òÌÖÄ ÌÅ¨Í∏∞ Ïàú Ï†ïÎ†¨
        shifts.sort(key=lambda x: abs(x['momentum']), reverse=True)

        return shifts

    def _identify_hot_sectors(self, performances: Dict[str, Dict]) -> List[Dict]:
        """Ìï´ ÏÑπÌÑ∞ ÏãùÎ≥Ñ (ÏÉÅÏúÑ NÍ∞ú)"""
        # ÏÉÅÎåÄ Í∞ïÎèÑ Í∏∞Ï§Ä Ï†ïÎ†¨
        sorted_sectors = sorted(
            performances.items(),
            key=lambda x: x[1].get('relative_strength', 0),
            reverse=True
        )

        hot_sectors = []
        for i, (sector_id, perf) in enumerate(sorted_sectors[:ProductionConfig.HOT_SECTOR_TOP_N]):
            sector_info = self.sector_defs.get_sector_info(sector_id)

            hot_sectors.append({
                'rank': i + 1,
                'sector_id': sector_id,
                'sector_name': sector_info.get('name', sector_id),
                'relative_strength': perf.get('relative_strength', 0),
                'total_return': perf.get('total_return', 0),
                'momentum': perf.get('momentum', 0),
                'category': sector_info.get('category', 'UNKNOWN')
            })

        return hot_sectors

    def _identify_weak_sectors(self, performances: Dict[str, Dict]) -> List[Dict]:
        """ÏïΩÏÑ∏ ÏÑπÌÑ∞ ÏãùÎ≥Ñ (ÌïòÏúÑ NÍ∞ú)"""
        # ÏÉÅÎåÄ Í∞ïÎèÑ Í∏∞Ï§Ä Ï†ïÎ†¨
        sorted_sectors = sorted(
            performances.items(),
            key=lambda x: x[1].get('relative_strength', 0)
        )

        weak_sectors = []
        for i, (sector_id, perf) in enumerate(sorted_sectors[:ProductionConfig.HOT_SECTOR_TOP_N]):
            sector_info = self.sector_defs.get_sector_info(sector_id)

            weak_sectors.append({
                'rank': i + 1,
                'sector_id': sector_id,
                'sector_name': sector_info.get('name', sector_id),
                'relative_strength': perf.get('relative_strength', 0),
                'total_return': perf.get('total_return', 0),
                'momentum': perf.get('momentum', 0),
                'category': sector_info.get('category', 'UNKNOWN')
            })

        return weak_sectors

    def predict_next_rotation(self) -> Dict[str, Any]:
        """
        Îã§Ïùå Î°úÌÖåÏù¥ÏÖò ÏòàÏ∏°

        Returns:
            ÏòàÏ∏° Í≤∞Í≥º
        """
        try:
            if len(self.rotation_history) < 5:
                return {
                    'prediction': 'INSUFFICIENT_DATA',
                    'confidence': 0.0,
                    'timestamp': datetime.now()
                }

            # ÏµúÍ∑º Î°úÌÖåÏù¥ÏÖò Ìå®ÌÑ¥ Î∂ÑÏÑù
            recent_patterns = [
                h['rotation_pattern'] for h in list(self.rotation_history)[-5:]
            ]

            recent_risk = [
                h['risk_appetite'] for h in list(self.rotation_history)[-5:]
            ]

            recent_cycle = [
                h['cycle_phase'] for h in list(self.rotation_history)[-5:]
            ]

            # Ìå®ÌÑ¥ ÎπàÎèÑ
            from collections import Counter
            pattern_freq = Counter(recent_patterns)
            risk_freq = Counter(recent_risk)
            cycle_freq = Counter(recent_cycle)

            # ÌòÑÏû¨ ÏÉÅÌÉú
            current = self.rotation_history[-1]
            current_pattern = current['rotation_pattern']
            current_risk = current['risk_appetite']
            current_cycle = current['cycle_phase']

            # Ï†ÑÌôò Î°úÏßÅ
            predicted_pattern = self._predict_pattern_transition(
                current_pattern, current_risk, current_cycle
            )

            predicted_hot_categories = self._predict_hot_categories(
                predicted_pattern, current_cycle
            )

            # Ïã†Î¢∞ÎèÑ Í≥ÑÏÇ∞
            confidence = self._calculate_prediction_confidence(
                pattern_freq, risk_freq, cycle_freq
            )

            return {
                'current_state': {
                    'pattern': current_pattern,
                    'risk_appetite': current_risk,
                    'cycle_phase': current_cycle
                },
                'predicted_pattern': predicted_pattern,
                'predicted_hot_categories': predicted_hot_categories,
                'confidence': float(confidence),
                'reasoning': self._generate_prediction_reasoning(
                    current_pattern, predicted_pattern, current_cycle
                ),
                'timestamp': datetime.now()
            }

        except Exception as e:
            self.logger.error(f"Predict next rotation error: {e}")
            return {
                'prediction': 'ERROR',
                'confidence': 0.0,
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def _predict_pattern_transition(self, current_pattern: str,
                                    current_risk: str,
                                    current_cycle: str) -> str:
        """Ìå®ÌÑ¥ Ï†ÑÌôò ÏòàÏ∏°"""
        # Ï†ÑÌôò Î£∞ Í∏∞Î∞ò ÏòàÏ∏°

        if current_cycle == 'EARLY_CYCLE':
            if current_risk == 'RISK_ON':
                return 'VALUE_TO_GROWTH'
            else:
                return 'BROAD_RALLY'

        elif current_cycle == 'MID_CYCLE':
            if current_pattern == 'VALUE_TO_GROWTH':
                return 'RISK_ON_ROTATION'
            else:
                return 'BROAD_RALLY'

        elif current_cycle == 'LATE_CYCLE':
            if current_risk == 'RISK_ON':
                return 'RISK_OFF_ROTATION'
            else:
                return 'GROWTH_TO_VALUE'

        elif current_cycle == 'RECESSION':
            return 'RISK_OFF_ROTATION'

        elif current_cycle == 'RECOVERY':
            return 'VALUE_TO_GROWTH'

        else:
            return 'MIXED_PATTERN'

    def _predict_hot_categories(self, predicted_pattern: str,
                                current_cycle: str) -> List[str]:
        """ÏòàÏÉÅ Ìï´ Ïπ¥ÌÖåÍ≥†Î¶¨ ÏòàÏ∏°"""
        if predicted_pattern in ['RISK_ON_ROTATION', 'VALUE_TO_GROWTH']:
            return ['GROWTH', 'SPECULATIVE']

        elif predicted_pattern in ['RISK_OFF_ROTATION', 'GROWTH_TO_VALUE']:
            return ['DEFENSIVE', 'CORE']

        elif predicted_pattern == 'BROAD_RALLY':
            return ['CORE', 'GROWTH']

        elif current_cycle in ['EARLY_CYCLE', 'RECOVERY']:
            return ['CORE', 'GROWTH']

        elif current_cycle == 'MID_CYCLE':
            return ['GROWTH', 'SPECULATIVE']

        elif current_cycle == 'LATE_CYCLE':
            return ['DEFENSIVE', 'CORE']

        else:
            return ['CORE']

    def _calculate_prediction_confidence(self, pattern_freq: Counter,
                                         risk_freq: Counter,
                                         cycle_freq: Counter) -> float:
        """ÏòàÏ∏° Ïã†Î¢∞ÎèÑ Í≥ÑÏÇ∞"""
        # ÏµúÎπàÍ∞íÏùò ÎπàÎèÑ ÎπÑÏú®
        max_pattern_freq = max(pattern_freq.values()) if pattern_freq else 0
        max_risk_freq = max(risk_freq.values()) if risk_freq else 0
        max_cycle_freq = max(cycle_freq.values()) if cycle_freq else 0

        total = len(self.rotation_history)

        if total == 0:
            return 0.0

        confidence = (
                0.4 * (max_pattern_freq / min(total, 5)) +
                0.3 * (max_risk_freq / min(total, 5)) +
                0.3 * (max_cycle_freq / min(total, 5))
        )

        return np.clip(confidence, 0.0, 1.0)

    def _generate_prediction_reasoning(self, current_pattern: str,
                                       predicted_pattern: str,
                                       current_cycle: str) -> str:
        """ÏòàÏ∏° Í∑ºÍ±∞ ÏÉùÏÑ±"""
        reasoning = f"Current pattern is {current_pattern} in {current_cycle} phase. "

        if predicted_pattern != current_pattern:
            reasoning += f"Expecting transition to {predicted_pattern} based on cycle dynamics."
        else:
            reasoning += f"Pattern likely to persist in current cycle phase."

        return reasoning

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ÏÑ±Îä• Î©îÌä∏Î¶≠"""
        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'errors': self.error_count,
            'error_rate': error_rate,
            'history_size': len(self.rotation_history),
            'current_rotation_state': self.current_rotation_state,
            'current_risk_appetite': self.current_risk_appetite,
            'current_cycle_phase': self.current_cycle_phase
        }

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# END OF PART 3/8
# Îã§Ïùå: Part 4 - Sector Allocation Optimizer & Signal Generator
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üî•üî•üî• MARKET REGIME ANALYZER 13.0 - PART 4/8 üî•üî•üî•
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Part 4: Sector Allocation Optimizer & Signal Generator
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Part 3ÏóêÏÑú Í≥ÑÏÜç...

class SectorAllocationOptimizer:
    """
    üé™ ÏÑπÌÑ∞ Î∞∞Î∂Ñ ÏµúÏ†ÅÌôîÍ∏∞ (v13.0 NEW - ÌîÑÎ°úÎçïÏÖò Î†àÎ≤®)

    ÏãúÏû• ÏÉÅÌô©Ïóê ÎßûÎäî ÏµúÏ†Å ÏÑπÌÑ∞ Î∞∞Î∂Ñ Í∂åÍ≥†
    """

    def __init__(self, sector_rotation_detector: SectorRotationDetector,
                 sector_performance_analyzer: SectorPerformanceAnalyzer,
                 sector_definitions: SectorDefinitions):
        self.rotation_detector = sector_rotation_detector
        self.sector_perf = sector_performance_analyzer
        self.sector_defs = sector_definitions
        self.logger = get_logger("SectorAllocationOptimizer")
        self.validator = DataValidator()

        # Î∞∞Î∂Ñ ÌûàÏä§ÌÜ†Î¶¨
        self.allocation_history = deque(maxlen=500)

        # ÏÑ±Îä• Î©îÌä∏Î¶≠
        self.api_call_count = 0
        self.error_count = 0

    def optimize_allocation(self, total_capital: float = 1.0,
                            risk_tolerance: str = 'MODERATE',
                            constraints: Optional[Dict] = None) -> Dict[str, Any]:
        """
        ÏµúÏ†Å ÏÑπÌÑ∞ Î∞∞Î∂Ñ Í≥ÑÏÇ∞

        Args:
            total_capital: Ï¥ù ÏûêÎ≥∏ (1.0 = 100%)
            risk_tolerance: Î¶¨Ïä§ÌÅ¨ ÌóàÏö©ÎèÑ ('CONSERVATIVE', 'MODERATE', 'AGGRESSIVE')
            constraints: Ï†úÏïΩ Ï°∞Í±¥ {'max_per_sector': 0.3, 'min_diversification': 3, ...}

        Returns:
            ÏµúÏ†Å Î∞∞Î∂Ñ Í≤∞Í≥º
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            # Í∏∞Î≥∏ Ï†úÏïΩ Ï°∞Í±¥
            if constraints is None:
                constraints = {}

            max_per_sector = constraints.get('max_per_sector', 0.30)
            min_per_sector = constraints.get('min_per_sector', 0.05)
            min_diversification = constraints.get('min_diversification', 3)

            # ÌòÑÏû¨ Î°úÌÖåÏù¥ÏÖò ÏÉÅÌÉú
            rotation_state = self.rotation_detector.detect_sector_rotation()

            # ÏÑπÌÑ∞ ÏÑ±Í≥º
            performances = rotation_state.get('sector_performances', {})

            if not performances:
                raise ValueError("No sector performance data available")

            # Î¶¨Ïä§ÌÅ¨ ÌóàÏö©ÎèÑÏóê Îî∞Î•∏ Î∞∞Î∂Ñ Ï†ÑÎûµ
            allocation_strategy = self._determine_allocation_strategy(
                risk_tolerance, rotation_state
            )

            # Ï¥àÍ∏∞ Î∞∞Î∂Ñ Í≥ÑÏÇ∞
            raw_allocation = self._calculate_raw_allocation(
                performances, rotation_state, allocation_strategy
            )

            # Ï†úÏïΩ Ï°∞Í±¥ Ï†ÅÏö©
            constrained_allocation = self._apply_constraints(
                raw_allocation,
                max_per_sector,
                min_per_sector,
                min_diversification,
                total_capital
            )

            # Î¶¨Ïä§ÌÅ¨ Î∂ÑÏÑù
            portfolio_risk = self._calculate_portfolio_risk(
                constrained_allocation, performances
            )

            # ÏòàÏÉÅ ÏàòÏùµÎ•†
            expected_return = self._calculate_expected_return(
                constrained_allocation, performances
            )

            # Îã§Í∞ÅÌôî ÏßÄÏàò
            diversification_score = self._calculate_diversification_score(
                constrained_allocation
            )

            result = {
                'allocation': constrained_allocation,
                'allocation_strategy': allocation_strategy,
                'expected_return': float(expected_return),
                'portfolio_risk': portfolio_risk,
                'diversification_score': float(diversification_score),
                'risk_tolerance': risk_tolerance,
                'rotation_state': rotation_state['rotation_pattern'],
                'risk_appetite': rotation_state['risk_appetite'],
                'cycle_phase': rotation_state['cycle_phase'],
                'constraints': {
                    'max_per_sector': max_per_sector,
                    'min_per_sector': min_per_sector,
                    'min_diversification': min_diversification
                },
                'timestamp': datetime.now()
            }

            # ÌûàÏä§ÌÜ†Î¶¨
            self.allocation_history.append(result)

            # ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('optimize_allocation', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Allocation optimization error: {e}")
            performance_monitor.record_error('optimize_allocation', e)

            # Ìè¥Î∞±: Í∑†Îì± Î∞∞Î∂Ñ
            return self._get_fallback_allocation(total_capital)

    def _determine_allocation_strategy(self, risk_tolerance: str,
                                       rotation_state: Dict) -> str:
        """
        Î∞∞Î∂Ñ Ï†ÑÎûµ Í≤∞Ï†ï

        Returns:
            'MOMENTUM', 'BALANCED', 'DEFENSIVE', 'CONTRARIAN'
        """
        rotation_pattern = rotation_state.get('rotation_pattern', 'STABLE')
        risk_appetite = rotation_state.get('risk_appetite', 'NEUTRAL')
        cycle_phase = rotation_state.get('cycle_phase', 'UNCERTAIN')

        # Î≥¥ÏàòÏ†Å Ìà¨ÏûêÏûê
        if risk_tolerance == 'CONSERVATIVE':
            if risk_appetite == 'RISK_OFF':
                return 'DEFENSIVE'
            else:
                return 'BALANCED'

        # Í≥µÍ≤©Ï†Å Ìà¨ÏûêÏûê
        elif risk_tolerance == 'AGGRESSIVE':
            if rotation_pattern in ['RISK_ON_ROTATION', 'VALUE_TO_GROWTH']:
                return 'MOMENTUM'
            elif cycle_phase == 'LATE_CYCLE':
                return 'BALANCED'  # Í≥ºÏó¥ Î∞©ÏßÄ
            else:
                return 'MOMENTUM'

        # Ï§ëÎèÑ Ìà¨ÏûêÏûê
        else:  # MODERATE
            if rotation_pattern == 'BROAD_RALLY':
                return 'MOMENTUM'
            elif rotation_pattern == 'BROAD_DECLINE':
                return 'DEFENSIVE'
            elif cycle_phase in ['LATE_CYCLE', 'RECESSION']:
                return 'DEFENSIVE'
            elif cycle_phase == 'EARLY_CYCLE':
                return 'MOMENTUM'
            else:
                return 'BALANCED'

    def _calculate_raw_allocation(self, performances: Dict[str, Dict],
                                  rotation_state: Dict,
                                  strategy: str) -> Dict[str, float]:
        """ÏõêÏãú Î∞∞Î∂Ñ Í≥ÑÏÇ∞ (Ï†úÏïΩ Ï°∞Í±¥ Ï†ÅÏö© Ï†Ñ)"""
        allocations = {}

        if strategy == 'MOMENTUM':
            # Î™®Î©òÌÖÄ Í∏∞Î∞ò: ÏÉÅÎåÄ Í∞ïÎèÑÏóê ÎπÑÎ°Ä Î∞∞Î∂Ñ
            total_rs = sum(p.get('relative_strength', 50) for p in performances.values())

            for sector_id, perf in performances.items():
                rs = perf.get('relative_strength', 50)
                allocations[sector_id] = rs / total_rs if total_rs > 0 else 0

        elif strategy == 'DEFENSIVE':
            # Î∞©Ïñ¥Ï†Å: Ï†ÄÏúÑÌóò ÏÑπÌÑ∞Ïóê ÏßëÏ§ë
            for sector_id, perf in performances.items():
                sector_info = self.sector_defs.get_sector_info(sector_id)
                risk_profile = sector_info.get('risk_profile', 'MODERATE')
                category = sector_info.get('category', 'CORE')

                # Î∞©Ïñ¥Ï†Å Ïπ¥ÌÖåÍ≥†Î¶¨ Ïö∞ÎåÄ
                if category == 'DEFENSIVE':
                    weight = 0.40
                elif category == 'CORE':
                    weight = 0.35
                elif risk_profile in ['LOW', 'LOW_MODERATE']:
                    weight = 0.20
                else:
                    weight = 0.05

                allocations[sector_id] = weight

        elif strategy == 'BALANCED':
            # Í∑†Ìòï: Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ ÌëúÏ§Ä Î∞∞Î∂Ñ
            for sector_id, perf in performances.items():
                sector_info = self.sector_defs.get_sector_info(sector_id)
                category = sector_info.get('category', 'CORE')

                # Ïπ¥ÌÖåÍ≥†Î¶¨ ÌëúÏ§Ä Î∞∞Î∂Ñ
                category_defs = self.sector_defs.sector_categories
                typical_allocation = category_defs.get(category, {}).get('typical_allocation', 0.25)

                # ÏÑ±Í≥ºÏóê Îî∞Îùº Ï°∞Ï†ï
                rs = perf.get('relative_strength', 50)
                adjustment = (rs - 50) / 100  # -0.5 ~ +0.5

                allocations[sector_id] = typical_allocation * (1 + adjustment)

        elif strategy == 'CONTRARIAN':
            # Ïó≠Î∞úÏÉÅ: ÏïΩÏÑ∏ ÏÑπÌÑ∞Ïóê Î∞∞Î∂Ñ (ÌèâÍ∑† ÌöåÍ∑Ä Ï†ÑÎûµ)
            # ÏÉÅÎåÄ Í∞ïÎèÑ Ïó≠Ïàú
            total_inverse_rs = sum(100 - p.get('relative_strength', 50) for p in performances.values())

            for sector_id, perf in performances.items():
                inverse_rs = 100 - perf.get('relative_strength', 50)
                allocations[sector_id] = inverse_rs / total_inverse_rs if total_inverse_rs > 0 else 0

        else:
            # Í∏∞Î≥∏: Í∑†Îì± Î∞∞Î∂Ñ
            n = len(performances)
            for sector_id in performances:
                allocations[sector_id] = 1.0 / n if n > 0 else 0

        # Ï†ïÍ∑úÌôî
        total = sum(allocations.values())
        if total > 0:
            allocations = {k: v / total for k, v in allocations.items()}

        return allocations

    def _apply_constraints(self, raw_allocation: Dict[str, float],
                           max_per_sector: float,
                           min_per_sector: float,
                           min_diversification: int,
                           total_capital: float) -> Dict[str, float]:
        """Ï†úÏïΩ Ï°∞Í±¥ Ï†ÅÏö©"""
        # 1. ÏµúÎåÄ/ÏµúÏÜå Ï†úÏïΩ
        constrained = {}
        overflow = 0.0

        for sector_id, weight in raw_allocation.items():
            if weight > max_per_sector:
                constrained[sector_id] = max_per_sector
                overflow += (weight - max_per_sector)
            elif weight < min_per_sector:
                # ÎÑàÎ¨¥ ÏûëÏúºÎ©¥ 0ÏúºÎ°ú
                overflow += weight
                constrained[sector_id] = 0.0
            else:
                constrained[sector_id] = weight

        # 2. Ïò§Î≤ÑÌîåÎ°úÏö∞ Ïû¨Î∂ÑÎ∞∞
        if overflow > 0:
            # Ï†úÏïΩ ÎØ∏ÎèÑÎã¨ ÏÑπÌÑ∞Ïóê Ïû¨Î∂ÑÎ∞∞
            available_sectors = {
                k: v for k, v in constrained.items()
                if v < max_per_sector and v > 0
            }

            if available_sectors:
                total_available = sum(available_sectors.values())
                for sector_id in available_sectors:
                    additional = overflow * (constrained[sector_id] / total_available)
                    constrained[sector_id] = min(
                        constrained[sector_id] + additional,
                        max_per_sector
                    )

        # 3. ÏµúÏÜå Îã§Í∞ÅÌôî Ï°∞Í±¥
        non_zero_sectors = {k: v for k, v in constrained.items() if v > 0}

        if len(non_zero_sectors) < min_diversification:
            # Ï∂îÍ∞Ä ÏÑπÌÑ∞ Ìè¨Ìï®
            zero_sectors = {k: v for k, v in raw_allocation.items() if constrained.get(k, 0) == 0}

            # ÏõêÏãú Î∞∞Î∂Ñ ÎÜíÏùÄ ÏàúÏúºÎ°ú Ï∂îÍ∞Ä
            sorted_zero = sorted(zero_sectors.items(), key=lambda x: x[1], reverse=True)

            for i in range(min(min_diversification - len(non_zero_sectors), len(sorted_zero))):
                sector_id, _ = sorted_zero[i]
                constrained[sector_id] = min_per_sector

        # 4. Ïû¨Ï†ïÍ∑úÌôî
        total = sum(constrained.values())
        if total > 0:
            constrained = {k: (v / total) * total_capital for k, v in constrained.items()}

        # 5. Ï†úÎ°ú Ï†úÍ±∞
        constrained = {k: v for k, v in constrained.items() if v > 1e-6}

        return constrained

    def _calculate_portfolio_risk(self, allocation: Dict[str, float],
                                  performances: Dict[str, Dict]) -> Dict[str, Any]:
        """Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ Î¶¨Ïä§ÌÅ¨ Í≥ÑÏÇ∞"""
        try:
            # Í∞ÄÏ§ë ÌèâÍ∑† Î≥ÄÎèôÏÑ±
            total_volatility = 0.0
            total_max_dd = 0.0

            for sector_id, weight in allocation.items():
                perf = performances.get(sector_id, {})
                volatility = perf.get('volatility', 0.02)
                max_dd = abs(perf.get('max_drawdown', 0.0))

                total_volatility += weight * volatility
                total_max_dd += weight * max_dd

            # Î¶¨Ïä§ÌÅ¨ ÌîÑÎ°úÌååÏùº Î∂ÑÌè¨
            risk_distribution = defaultdict(float)

            for sector_id, weight in allocation.items():
                sector_info = self.sector_defs.get_sector_info(sector_id)
                risk_profile = sector_info.get('risk_profile', 'MODERATE')
                risk_distribution[risk_profile] += weight

            return {
                'weighted_volatility': float(total_volatility),
                'weighted_max_drawdown': float(total_max_dd),
                'risk_distribution': dict(risk_distribution)
            }

        except Exception as e:
            self.logger.error(f"Portfolio risk calculation error: {e}")
            return {
                'weighted_volatility': 0.0,
                'weighted_max_drawdown': 0.0,
                'risk_distribution': {}
            }

    def _calculate_expected_return(self, allocation: Dict[str, float],
                                   performances: Dict[str, Dict]) -> float:
        """Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ ÏòàÏÉÅ ÏàòÏùµÎ•†"""
        try:
            expected_return = 0.0

            for sector_id, weight in allocation.items():
                perf = performances.get(sector_id, {})
                sector_return = perf.get('total_return', 0.0)
                expected_return += weight * sector_return

            return expected_return

        except Exception as e:
            self.logger.error(f"Expected return calculation error: {e}")
            return 0.0

    def _calculate_diversification_score(self, allocation: Dict[str, float]) -> float:
        """
        Îã§Í∞ÅÌôî Ï†êÏàò Í≥ÑÏÇ∞ (0~1)

        ÌóàÌïÄÎã¨ ÏßÄÏàò Í∏∞Î∞ò: 1 - HHI
        """
        try:
            if not allocation:
                return 0.0

            # ÌóàÌïÄÎã¨ ÏßÄÏàò (HHI)
            hhi = sum(w ** 2 for w in allocation.values())

            # Îã§Í∞ÅÌôî Ï†êÏàò (HHIÍ∞Ä ÎÇÆÏùÑÏàòÎ°ù Îã§Í∞ÅÌôîÍ∞Ä Ïûò Îê®)
            diversification = 1.0 - hhi

            return diversification

        except Exception as e:
            self.logger.error(f"Diversification score calculation error: {e}")
            return 0.0

    def _get_fallback_allocation(self, total_capital: float) -> Dict[str, Any]:
        """Ìè¥Î∞± Î∞∞Î∂Ñ (ÏóêÎü¨ Ïãú)"""
        # ÏΩîÏñ¥ ÏÑπÌÑ∞ÏóêÎßå Í∑†Îì± Î∞∞Î∂Ñ
        core_sectors = self.sector_defs.get_sectors_by_category('CORE')

        allocation = {}
        if core_sectors:
            weight = total_capital / len(core_sectors)
            for sector_id in core_sectors:
                allocation[sector_id] = weight

        return {
            'allocation': allocation,
            'allocation_strategy': 'FALLBACK_EQUAL_WEIGHT',
            'expected_return': 0.0,
            'portfolio_risk': {'weighted_volatility': 0.0},
            'diversification_score': 0.5,
            'timestamp': datetime.now(),
            'error': 'Fallback allocation due to optimization error'
        }

    def rebalance_check(self, current_allocation: Dict[str, float],
                        target_allocation: Dict[str, float],
                        threshold: float = 0.05) -> Dict[str, Any]:
        """
        Î¶¨Î∞∏Îü∞Ïã± ÌïÑÏöî Ïó¨Î∂Ä Ï≤¥ÌÅ¨

        Args:
            current_allocation: ÌòÑÏû¨ Î∞∞Î∂Ñ
            target_allocation: Î™©Ìëú Î∞∞Î∂Ñ
            threshold: Î¶¨Î∞∏Îü∞Ïã± ÏûÑÍ≥ÑÍ∞í (5% Ï∞®Ïù¥ Ïãú)

        Returns:
            Î¶¨Î∞∏Îü∞Ïã± Í∂åÍ≥†
        """
        try:
            rebalance_needed = False
            rebalance_actions = []

            all_sectors = set(current_allocation.keys()) | set(target_allocation.keys())

            for sector_id in all_sectors:
                current = current_allocation.get(sector_id, 0.0)
                target = target_allocation.get(sector_id, 0.0)

                diff = target - current

                if abs(diff) > threshold:
                    rebalance_needed = True

                    action = 'BUY' if diff > 0 else 'SELL'
                    amount = abs(diff)

                    rebalance_actions.append({
                        'sector_id': sector_id,
                        'action': action,
                        'current_weight': float(current),
                        'target_weight': float(target),
                        'adjustment_amount': float(amount)
                    })

            # Ïï°ÏÖò Ï†ïÎ†¨ (Ï°∞Ï†ï ÌÅ¨Í∏∞ Ïàú)
            rebalance_actions.sort(key=lambda x: x['adjustment_amount'], reverse=True)

            return {
                'rebalance_needed': rebalance_needed,
                'threshold': threshold,
                'actions': rebalance_actions,
                'total_adjustment': sum(a['adjustment_amount'] for a in rebalance_actions),
                'timestamp': datetime.now()
            }

        except Exception as e:
            self.logger.error(f"Rebalance check error: {e}")
            return {
                'rebalance_needed': False,
                'actions': [],
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ÏÑ±Îä• Î©îÌä∏Î¶≠"""
        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'errors': self.error_count,
            'error_rate': error_rate,
            'history_size': len(self.allocation_history)
        }


class SectorRotationSignalGenerator:
    """
    ‚ö° ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Ïã†Ìò∏ ÏÉùÏÑ±Í∏∞ (v13.0 NEW - ÌîÑÎ°úÎçïÏÖò Î†àÎ≤®)

    Í±∞Îûò Ïã†Ìò∏ Î∞è Í≤ΩÎ≥¥ ÏÉùÏÑ±
    """

    def __init__(self, sector_rotation_detector: SectorRotationDetector,
                 sector_allocation_optimizer: SectorAllocationOptimizer):
        self.rotation_detector = sector_rotation_detector
        self.allocation_optimizer = sector_allocation_optimizer
        self.logger = get_logger("SectorRotationSignalGenerator")

        # Ïã†Ìò∏ ÌûàÏä§ÌÜ†Î¶¨
        self.signal_history = deque(maxlen=1000)

        # Í≤ΩÎ≥¥ ÏÉÅÌÉú
        self.active_alerts = []
        self.last_alert_time = {}

        # ÏÑ±Îä• Î©îÌä∏Î¶≠
        self.api_call_count = 0
        self.error_count = 0

    def generate_signals(self, lookback_days: int = 7) -> Dict[str, Any]:
        """
        Í±∞Îûò Ïã†Ìò∏ ÏÉùÏÑ±

        Args:
            lookback_days: Î∂ÑÏÑù Í∏∞Í∞Ñ

        Returns:
            Ïã†Ìò∏ Í≤∞Í≥º
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            # Î°úÌÖåÏù¥ÏÖò Í∞êÏßÄ
            rotation_state = self.rotation_detector.detect_sector_rotation(lookback_days)

            # Îã§Ïùå Î°úÌÖåÏù¥ÏÖò ÏòàÏ∏°
            next_rotation = self.rotation_detector.predict_next_rotation()

            # Ìï´ ÏÑπÌÑ∞
            hot_sectors = rotation_state.get('hot_sectors', [])

            # ÏïΩÏÑ∏ ÏÑπÌÑ∞
            weak_sectors = rotation_state.get('weak_sectors', [])

            # Î™®Î©òÌÖÄ Ï†ÑÌôò
            momentum_shifts = rotation_state.get('momentum_shifts', [])

            # Ïã†Ìò∏ ÏÉùÏÑ±
            signals = self._generate_sector_signals(
                hot_sectors, weak_sectors, momentum_shifts, rotation_state, next_rotation
            )

            # Ïã†Ìò∏ Í∞ïÎèÑ Í≥ÑÏÇ∞
            overall_signal_strength = self._calculate_overall_signal_strength(signals)

            # Í≤ΩÎ≥¥ ÏÉùÏÑ±
            alerts = self._generate_alerts(rotation_state, next_rotation, signals)

            # Í∂åÍ≥† ÏÇ¨Ìï≠
            recommendations = self._generate_recommendations(
                rotation_state, next_rotation, signals
            )

            result = {
                'signals': signals,
                'overall_signal_strength': overall_signal_strength,
                'alerts': alerts,
                'recommendations': recommendations,
                'rotation_state': rotation_state,
                'next_rotation_prediction': next_rotation,
                'confidence': next_rotation.get('confidence', 0.0),
                'timestamp': datetime.now()
            }

            # ÌûàÏä§ÌÜ†Î¶¨
            self.signal_history.append(result)

            # ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('generate_signals', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Signal generation error: {e}")
            performance_monitor.record_error('generate_signals', e)

            return {
                'signals': [],
                'overall_signal_strength': 0.0,
                'alerts': [],
                'recommendations': [],
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def _generate_sector_signals(self, hot_sectors: List[Dict],
                                 weak_sectors: List[Dict],
                                 momentum_shifts: List[Dict],
                                 rotation_state: Dict,
                                 next_rotation: Dict) -> List[Dict]:
        """Í∞úÎ≥Ñ ÏÑπÌÑ∞ Ïã†Ìò∏ ÏÉùÏÑ±"""
        signals = []

        # Ìï´ ÏÑπÌÑ∞ - Îß§Ïàò Ïã†Ìò∏
        for hot in hot_sectors[:3]:  # ÏÉÅÏúÑ 3Í∞ú
            signal = {
                'sector_id': hot['sector_id'],
                'sector_name': hot['sector_name'],
                'signal_type': 'BUY',
                'strength': 'STRONG' if hot['relative_strength'] > 70 else 'MODERATE',
                'reason': f"Leading sector with RS={hot['relative_strength']:.1f}",
                'relative_strength': hot['relative_strength'],
                'momentum': hot.get('momentum', 0.0)
            }
            signals.append(signal)

        # ÏïΩÏÑ∏ ÏÑπÌÑ∞ - Îß§ÎèÑ/ÌöåÌîº Ïã†Ìò∏
        for weak in weak_sectors[:2]:  # ÌïòÏúÑ 2Í∞ú
            signal = {
                'sector_id': weak['sector_id'],
                'sector_name': weak['sector_name'],
                'signal_type': 'SELL',
                'strength': 'STRONG' if weak['relative_strength'] < 30 else 'MODERATE',
                'reason': f"Lagging sector with RS={weak['relative_strength']:.1f}",
                'relative_strength': weak['relative_strength'],
                'momentum': weak.get('momentum', 0.0)
            }
            signals.append(signal)

        # Î™®Î©òÌÖÄ Ï†ÑÌôò - Ï∂îÏÑ∏ Ï†ÑÌôò Ïã†Ìò∏
        for shift in momentum_shifts[:3]:
            if shift['type'] == 'STRONG_POSITIVE':
                signal = {
                    'sector_id': shift['sector_id'],
                    'signal_type': 'BUY',
                    'strength': 'STRONG',
                    'reason': f"Strong positive momentum shift ({shift['momentum']:.3f})",
                    'momentum': shift['momentum']
                }
                signals.append(signal)

        return signals

    def _calculate_overall_signal_strength(self, signals: List[Dict]) -> float:
        """Ï†ÑÏ≤¥ Ïã†Ìò∏ Í∞ïÎèÑ Í≥ÑÏÇ∞"""
        if not signals:
            return 0.0

        # Í∞ïÎèÑ Ï†êÏàòÌôî
        strength_scores = {
            'STRONG': 1.0,
            'MODERATE': 0.6,
            'WEAK': 0.3
        }

        total_score = 0.0
        for signal in signals:
            strength = signal.get('strength', 'WEAK')
            score = strength_scores.get(strength, 0.3)

            # Îß§ÏàòÎäî ÏñëÏàò, Îß§ÎèÑÎäî ÏùåÏàò
            if signal['signal_type'] == 'BUY':
                total_score += score
            elif signal['signal_type'] == 'SELL':
                total_score -= score

        # Ï†ïÍ∑úÌôî (-1 ~ +1)
        max_score = len(signals) * 1.0
        normalized = total_score / max_score if max_score > 0 else 0.0

        return np.clip(normalized, -1.0, 1.0)

    def _generate_alerts(self, rotation_state: Dict,
                         next_rotation: Dict,
                         signals: List[Dict]) -> List[Dict]:
        """Í≤ΩÎ≥¥ ÏÉùÏÑ±"""
        alerts = []

        # 1. Î°úÌÖåÏù¥ÏÖò Ï†ÑÌôò Í≤ΩÎ≥¥
        rotation_pattern = rotation_state.get('rotation_pattern')
        predicted_pattern = next_rotation.get('predicted_pattern')
        confidence = next_rotation.get('confidence', 0.0)

        if predicted_pattern and predicted_pattern != rotation_pattern and confidence > 0.7:
            alerts.append({
                'type': 'ROTATION_SHIFT',
                'severity': 'HIGH',
                'message': f"Sector rotation shifting from {rotation_pattern} to {predicted_pattern}",
                'confidence': confidence,
                'timestamp': datetime.now()
            })

        # 2. Î¶¨Ïä§ÌÅ¨Ïò®/Ïò§ÌîÑ Ï†ÑÌôò
        risk_appetite = rotation_state.get('risk_appetite')

        if risk_appetite in ['RISK_ON', 'RISK_OFF']:
            alerts.append({
                'type': 'RISK_APPETITE_CHANGE',
                'severity': 'MEDIUM',
                'message': f"Market risk appetite: {risk_appetite}",
                'timestamp': datetime.now()
            })

        # 3. ÏÇ¨Ïù¥ÌÅ¥ Ï†ÑÌôò
        cycle_phase = rotation_state.get('cycle_phase')

        if cycle_phase in ['LATE_CYCLE', 'RECESSION']:
            alerts.append({
                'type': 'CYCLE_WARNING',
                'severity': 'HIGH',
                'message': f"Market in {cycle_phase} - exercise caution",
                'timestamp': datetime.now()
            })

        # 4. Í∞ïÌïú Ïã†Ìò∏
        strong_signals = [s for s in signals if s.get('strength') == 'STRONG']

        if len(strong_signals) >= 3:
            alerts.append({
                'type': 'MULTIPLE_STRONG_SIGNALS',
                'severity': 'MEDIUM',
                'message': f"{len(strong_signals)} strong sector signals detected",
                'timestamp': datetime.now()
            })

        return alerts

    def _generate_recommendations(self, rotation_state: Dict,
                                  next_rotation: Dict,
                                  signals: List[Dict]) -> List[str]:
        """Ìà¨Ïûê Í∂åÍ≥† ÏÉùÏÑ±"""
        recommendations = []

        rotation_pattern = rotation_state.get('rotation_pattern')
        risk_appetite = rotation_state.get('risk_appetite')
        cycle_phase = rotation_state.get('cycle_phase')

        # Î°úÌÖåÏù¥ÏÖò Í∏∞Î∞ò Í∂åÍ≥†
        if rotation_pattern == 'RISK_ON_ROTATION':
            recommendations.append("Consider increasing allocation to growth and speculative sectors")

        elif rotation_pattern == 'RISK_OFF_ROTATION':
            recommendations.append("Shift towards defensive sectors and reduce high-risk exposure")

        elif rotation_pattern == 'BROAD_RALLY':
            recommendations.append("Maintain diversified exposure across sectors")

        elif rotation_pattern == 'BROAD_DECLINE':
            recommendations.append("Consider reducing overall crypto exposure or increase defensive allocation")

        # ÏÇ¨Ïù¥ÌÅ¥ Í∏∞Î∞ò Í∂åÍ≥†
        if cycle_phase == 'EARLY_CYCLE':
            recommendations.append("Focus on quality core and growth sectors")

        elif cycle_phase == 'LATE_CYCLE':
            recommendations.append("Take profits on speculative positions and increase defensive allocation")

        elif cycle_phase == 'RECESSION':
            recommendations.append("Prioritize capital preservation with defensive sectors")

        # ÏòàÏ∏° Í∏∞Î∞ò Í∂åÍ≥†
        predicted_hot_categories = next_rotation.get('predicted_hot_categories', [])
        if predicted_hot_categories:
            categories_str = ', '.join(predicted_hot_categories)
            recommendations.append(f"Prepare for rotation into: {categories_str}")

        # Ïã†Ìò∏ Í∏∞Î∞ò Í∂åÍ≥†
        buy_signals = [s for s in signals if s['signal_type'] == 'BUY']
        sell_signals = [s for s in signals if s['signal_type'] == 'SELL']

        if len(buy_signals) > len(sell_signals):
            recommendations.append("Net positive signals - consider increasing exposure")
        elif len(sell_signals) > len(buy_signals):
            recommendations.append("Net negative signals - consider reducing exposure")

        return recommendations

    def get_active_alerts(self) -> List[Dict]:
        """ÌôúÏÑ± Í≤ΩÎ≥¥ Î™©Î°ù"""
        cutoff_time = datetime.now() - timedelta(hours=1)

        active = [
            alert for alert in self.active_alerts
            if alert.get('timestamp', datetime.min) > cutoff_time
        ]

        return active

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ÏÑ±Îä• Î©îÌä∏Î¶≠"""
        error_rate = (
                self.error_count / max(self.api_call_count, 1)
        ) if self.api_call_count > 0 else 0

        return {
            'api_calls': self.api_call_count,
            'errors': self.error_count,
            'error_rate': error_rate,
            'history_size': len(self.signal_history),
            'active_alerts': len(self.active_alerts)
        }

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# END OF PART 4/8
# Îã§Ïùå: Part 5 - Integrated Sector Rotation Monitor
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üî•üî•üî• MARKET REGIME ANALYZER 13.0 - PART 5/8 üî•üî•üî•
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Part 5: Integrated Sector Rotation Monitor (ÌÜµÌï© Î™®ÎãàÌÑ∞)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Part 4ÏóêÏÑú Í≥ÑÏÜç...

class SectorRotationMonitor:
    """
    üéØ ÌÜµÌï© ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Î™®ÎãàÌÑ∞ (v13.0 NEW - ÌîÑÎ°úÎçïÏÖò Î†àÎ≤®)

    Î™®Îì† ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Ïª¥Ìè¨ÎÑåÌä∏Î•º ÌÜµÌï©Ìïú Î©îÏù∏ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§
    """

    def __init__(self, market_data_manager):
        self.market_data = market_data_manager
        self.logger = get_logger("SectorRotationMonitor")
        self.validator = DataValidator()

        # Ïª¥Ìè¨ÎÑåÌä∏ Ï¥àÍ∏∞Ìôî
        self.sector_defs = SectorDefinitions()
        self.sector_data = SectorDataManager(market_data_manager, self.sector_defs)
        self.sector_perf = SectorPerformanceAnalyzer(self.sector_data, self.sector_defs)
        self.rotation_detector = SectorRotationDetector(self.sector_perf, self.sector_defs)
        self.allocation_optimizer = SectorAllocationOptimizer(
            self.rotation_detector, self.sector_perf, self.sector_defs
        )
        self.signal_generator = SectorRotationSignalGenerator(
            self.rotation_detector, self.allocation_optimizer
        )

        # ÏÉÅÌÉú
        self.is_initialized = True
        self.last_analysis_time = None

        # ÏÑ±Îä• Î©îÌä∏Î¶≠
        self.api_call_count = 0
        self.error_count = 0

    def analyze_sector_rotation(self, lookback_days: int = 7,
                                risk_tolerance: str = 'MODERATE') -> Dict[str, Any]:
        """
        ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Ï¢ÖÌï© Î∂ÑÏÑù

        Args:
            lookback_days: Î∂ÑÏÑù Í∏∞Í∞Ñ
            risk_tolerance: Î¶¨Ïä§ÌÅ¨ ÌóàÏö©ÎèÑ

        Returns:
            Ï¢ÖÌï© Î∂ÑÏÑù Í≤∞Í≥º
        """
        start_time = datetime.now()

        try:
            self.api_call_count += 1

            self.logger.info(f"Starting sector rotation analysis (lookback={lookback_days} days)...")

            # 1. ÏÑπÌÑ∞ ÏÑ±Í≥º Î∂ÑÏÑù
            self.logger.info("Analyzing sector performance...")
            sector_performances = self.sector_perf.calculate_all_sectors_performance(lookback_days)

            # 2. ÏÑπÌÑ∞ Îû≠ÌÇπ
            sector_ranking = self.sector_perf.rank_sectors_by_performance(
                lookback_days, 'relative_strength'
            )

            # 3. ÏÑ†ÎèÑ/ÌõÑÌñâ ÏÑπÌÑ∞
            leading_lagging = self.sector_perf.identify_leading_lagging_sectors(lookback_days)

            # 4. ÏÑπÌÑ∞ Í∞Ñ ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ
            correlation_matrix = self.sector_perf.calculate_sector_correlation_matrix(lookback_days)

            # 5. Î°úÌÖåÏù¥ÏÖò Í∞êÏßÄ
            self.logger.info("Detecting sector rotation patterns...")
            rotation_analysis = self.rotation_detector.detect_sector_rotation(lookback_days)

            # 6. Îã§Ïùå Î°úÌÖåÏù¥ÏÖò ÏòàÏ∏°
            next_rotation = self.rotation_detector.predict_next_rotation()

            # 7. ÏµúÏ†Å Î∞∞Î∂Ñ
            self.logger.info("Optimizing sector allocation...")
            optimal_allocation = self.allocation_optimizer.optimize_allocation(
                total_capital=1.0,
                risk_tolerance=risk_tolerance
            )

            # 8. Ïã†Ìò∏ ÏÉùÏÑ±
            self.logger.info("Generating trading signals...")
            signals = self.signal_generator.generate_signals(lookback_days)

            # 9. Ï¢ÖÌï© Ï†êÏàò
            overall_assessment = self._calculate_overall_assessment(
                rotation_analysis, next_rotation, signals
            )

            result = {
                'sector_performances': sector_performances,
                'sector_ranking': sector_ranking,
                'leading_lagging': leading_lagging,
                'correlation_matrix': correlation_matrix.to_dict() if not correlation_matrix.empty else {},
                'rotation_analysis': rotation_analysis,
                'next_rotation_prediction': next_rotation,
                'optimal_allocation': optimal_allocation,
                'signals': signals,
                'overall_assessment': overall_assessment,
                'analysis_parameters': {
                    'lookback_days': lookback_days,
                    'risk_tolerance': risk_tolerance
                },
                'timestamp': datetime.now()
            }

            self.last_analysis_time = datetime.now()

            self.logger.info("Sector rotation analysis completed successfully!")

            # ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('analyze_sector_rotation', latency)

            return result

        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Sector rotation analysis error: {e}")
            performance_monitor.record_error('analyze_sector_rotation', e)

            return {
                'sector_performances': {},
                'rotation_analysis': {'rotation_pattern': 'ERROR'},
                'signals': {'signals': []},
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def get_sector_snapshot(self, sector_id: str, period_days: int = 7) -> Dict[str, Any]:
        """
        Í∞úÎ≥Ñ ÏÑπÌÑ∞ Ïä§ÎÉÖÏÉ∑

        Args:
            sector_id: ÏÑπÌÑ∞ ID
            period_days: Î∂ÑÏÑù Í∏∞Í∞Ñ

        Returns:
            ÏÑπÌÑ∞ ÏÉÅÏÑ∏ Ï†ïÎ≥¥
        """
        try:
            # ÏÑπÌÑ∞ Ï†ïÎ≥¥
            sector_info = self.sector_defs.get_sector_info(sector_id)

            # ÏÑ±Í≥º
            performance = self.sector_perf.calculate_sector_performance(sector_id, period_days)

            # Ïù∏Îç±Ïä§
            sector_index = self.sector_data.get_sector_index(
                sector_id, '1h', period_days * 24
            )

            # ÏµúÍ∑º Í∞ÄÍ≤© Îç∞Ïù¥ÌÑ∞
            recent_prices = self.sector_data.get_sector_prices(
                sector_id, '1h', 168  # 1Ï£ºÏùº
            )

            return {
                'sector_id': sector_id,
                'sector_info': sector_info,
                'performance': performance,
                'sector_index': sector_index.to_dict() if not sector_index.empty else {},
                'recent_prices': recent_prices.to_dict() if not recent_prices.empty else {},
                'timestamp': datetime.now()
            }

        except Exception as e:
            self.logger.error(f"Get sector snapshot error for {sector_id}: {e}")
            return {
                'sector_id': sector_id,
                'error': str(e),
                'timestamp': datetime.now()
            }

    def get_hot_sectors_report(self, period_days: int = 7,
                               top_n: int = 5) -> Dict[str, Any]:
        """
        Ìï´ ÏÑπÌÑ∞ Î¶¨Ìè¨Ìä∏

        Args:
            period_days: Î∂ÑÏÑù Í∏∞Í∞Ñ
            top_n: ÏÉÅÏúÑ NÍ∞ú

        Returns:
            Ìï´ ÏÑπÌÑ∞ ÏÉÅÏÑ∏ Î¶¨Ìè¨Ìä∏
        """
        try:
            # ÏÑπÌÑ∞ Îû≠ÌÇπ
            ranking = self.sector_perf.rank_sectors_by_performance(
                period_days, 'relative_strength'
            )

            hot_sectors = ranking[:top_n]

            detailed_reports = []

            for sector_perf in hot_sectors:
                sector_id = sector_perf['sector_id']

                # ÏÉÅÏÑ∏ Ïä§ÎÉÖÏÉ∑
                snapshot = self.get_sector_snapshot(sector_id, period_days)

                detailed_reports.append({
                    'sector_id': sector_id,
                    'sector_info': snapshot.get('sector_info', {}),
                    'performance': sector_perf,
                    'snapshot': snapshot
                })

            return {
                'hot_sectors': detailed_reports,
                'period_days': period_days,
                'timestamp': datetime.now()
            }

        except Exception as e:
            self.logger.error(f"Get hot sectors report error: {e}")
            return {
                'hot_sectors': [],
                'error': str(e),
                'timestamp': datetime.now()
            }

    def get_rotation_dashboard(self) -> Dict[str, Any]:
        """
        Î°úÌÖåÏù¥ÏÖò ÎåÄÏãúÎ≥¥Îìú (ÌòÑÏû¨ ÏÉÅÌÉú ÏöîÏïΩ)

        Returns:
            ÎåÄÏãúÎ≥¥Îìú Îç∞Ïù¥ÌÑ∞
        """
        try:
            # ÏµúÍ∑º Î∂ÑÏÑù
            analysis = self.analyze_sector_rotation(lookback_days=7)

            rotation_analysis = analysis.get('rotation_analysis', {})
            next_rotation = analysis.get('next_rotation_prediction', {})
            signals = analysis.get('signals', {})

            # Ìï´/ÏΩúÎìú ÏÑπÌÑ∞
            hot_sectors = rotation_analysis.get('hot_sectors', [])[:3]
            weak_sectors = rotation_analysis.get('weak_sectors', [])[:3]

            # ÌòÑÏû¨ ÏÉÅÌÉú
            current_state = {
                'rotation_pattern': rotation_analysis.get('rotation_pattern'),
                'risk_appetite': rotation_analysis.get('risk_appetite'),
                'cycle_phase': rotation_analysis.get('cycle_phase')
            }

            # ÏòàÏ∏° ÏÉÅÌÉú
            prediction = {
                'predicted_pattern': next_rotation.get('predicted_pattern'),
                'predicted_hot_categories': next_rotation.get('predicted_hot_categories', []),
                'confidence': next_rotation.get('confidence', 0.0)
            }

            # Ïã†Ìò∏ ÏöîÏïΩ
            signal_summary = {
                'overall_strength': signals.get('overall_signal_strength', 0.0),
                'n_buy_signals': len([s for s in signals.get('signals', []) if s['signal_type'] == 'BUY']),
                'n_sell_signals': len([s for s in signals.get('signals', []) if s['signal_type'] == 'SELL']),
                'active_alerts': len(signals.get('alerts', []))
            }

            return {
                'current_state': current_state,
                'prediction': prediction,
                'hot_sectors': hot_sectors,
                'weak_sectors': weak_sectors,
                'signal_summary': signal_summary,
                'recommendations': signals.get('recommendations', []),
                'timestamp': datetime.now()
            }

        except Exception as e:
            self.logger.error(f"Get rotation dashboard error: {e}")
            return {
                'current_state': {},
                'prediction': {},
                'error': str(e),
                'timestamp': datetime.now()
            }

    def _calculate_overall_assessment(self, rotation_analysis: Dict,
                                      next_rotation: Dict,
                                      signals: Dict) -> Dict[str, Any]:
        """Ï†ÑÏ≤¥ ÌèâÍ∞Ä Í≥ÑÏÇ∞"""
        try:
            # Î°úÌÖåÏù¥ÏÖò Í∞ïÎèÑ
            rotation_pattern = rotation_analysis.get('rotation_pattern', 'STABLE')
            rotation_strength_map = {
                'BROAD_RALLY': 1.0,
                'RISK_ON_ROTATION': 0.8,
                'VALUE_TO_GROWTH': 0.7,
                'MIXED_PATTERN': 0.5,
                'STABLE': 0.3,
                'GROWTH_TO_VALUE': -0.7,
                'RISK_OFF_ROTATION': -0.8,
                'BROAD_DECLINE': -1.0
            }

            rotation_strength = rotation_strength_map.get(rotation_pattern, 0.0)

            # Ïã†Ìò∏ Í∞ïÎèÑ
            signal_strength = signals.get('overall_signal_strength', 0.0)

            # ÏòàÏ∏° Ïã†Î¢∞ÎèÑ
            prediction_confidence = next_rotation.get('confidence', 0.0)

            # Ï¢ÖÌï© Ï†êÏàò (-100 ~ +100)
            overall_score = (
                                    0.40 * rotation_strength +
                                    0.40 * signal_strength +
                                    0.20 * (prediction_confidence * 2 - 1)
                            ) * 100

            # Ìà¨Ïûê Í∂åÍ≥†
            if overall_score > 60:
                recommendation = 'STRONG_BUY'
                risk_level = 'HIGH_OPPORTUNITY'
            elif overall_score > 30:
                recommendation = 'BUY'
                risk_level = 'MODERATE_OPPORTUNITY'
            elif overall_score > -30:
                recommendation = 'HOLD'
                risk_level = 'NEUTRAL'
            elif overall_score > -60:
                recommendation = 'SELL'
                risk_level = 'MODERATE_RISK'
            else:
                recommendation = 'STRONG_SELL'
                risk_level = 'HIGH_RISK'

            return {
                'overall_score': float(overall_score),
                'rotation_strength': float(rotation_strength),
                'signal_strength': float(signal_strength),
                'prediction_confidence': float(prediction_confidence),
                'recommendation': recommendation,
                'risk_level': risk_level
            }

        except Exception as e:
            self.logger.error(f"Calculate overall assessment error: {e}")
            return {
                'overall_score': 0.0,
                'recommendation': 'HOLD',
                'risk_level': 'UNCERTAIN'
            }

    def get_comprehensive_report(self) -> Dict[str, Any]:
        """Ï¢ÖÌï© Î¶¨Ìè¨Ìä∏"""
        return {
            'is_initialized': self.is_initialized,
            'last_analysis': self.last_analysis_time.isoformat() if self.last_analysis_time else None,
            'component_metrics': {
                'sector_data': self.sector_data.get_performance_metrics(),
                'sector_perf': self.sector_perf.get_performance_metrics(),
                'rotation_detector': self.rotation_detector.get_performance_metrics(),
                'allocation_optimizer': self.allocation_optimizer.get_performance_metrics(),
                'signal_generator': self.signal_generator.get_performance_metrics()
            },
            'n_sectors': len(self.sector_defs.get_all_crypto_sectors()),
            'timestamp': datetime.now()
        }

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# END OF PART 5/8
# Îã§Ïùå: Part 6 - v12.0 Í∏∞Ï°¥ ÌÅ¥ÎûòÏä§Îì§ (Markov, HMM, etc.)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üî•üî•üî• MARKET REGIME ANALYZER 13.0 - PART 6/8 üî•üî•üî•
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Part 6: v12.0 Í∏∞Ï°¥ ÌÅ¥ÎûòÏä§Îì§ (100% Ïú†ÏßÄ)
# - MarkovChainTransitionAnalyzer
# - HiddenMarkovModelPredictor
# - ConditionalTransitionAnalyzer
# - BayesianTransitionUpdater
# - EnsembleTransitionPredictor
# - TransitionSignalDetector
# - RegimeTransitionPredictorV12
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Part 5ÏóêÏÑú Í≥ÑÏÜç...

# NOTE: v12.0Ïùò Î™®Îì† ÌÅ¥ÎûòÏä§Î•º Ïó¨Í∏∞Ïóê Ìè¨Ìï®
# Ïã§Ï†ú Íµ¨ÌòÑ Ïãú market_regime_analyzer12.pyÏùò Part 2~5 Ï†ÑÏ≤¥ ÎÇ¥Ïö©ÏùÑ Ïó¨Í∏∞Ïóê ÏÇΩÏûÖ

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# v12.0 Markov Chain Transition Analyzer (100% Ïú†ÏßÄ)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class MarkovChainTransitionAnalyzer:
    """üéØ ÎßàÎ•¥ÏΩîÌîÑ Ï≤¥Ïù∏ Ï†ÑÌôò ÌôïÎ•† Î∂ÑÏÑùÍ∏∞ (v12.0 - 100% Ïú†ÏßÄ)"""
    def __init__(self):
        self.logger = get_logger("MarkovChainTransition")
        self.validator = DataValidator()
        self.regimes = [
            'BULL_CONSOLIDATION', 'BULL_VOLATILITY',
            'BEAR_CONSOLIDATION', 'BEAR_VOLATILITY',
            'SIDEWAYS_COMPRESSION', 'SIDEWAYS_CHOP',
            'ACCUMULATION', 'DISTRIBUTION'
        ]
        self.regime_to_idx = {r: i for i, r in enumerate(self.regimes)}
        self.idx_to_regime = {i: r for i, r in enumerate(self.regimes)}
        self.transition_matrix = None
        self.transition_counts = None
        self.total_transitions = 0
        self.last_update_time = None
        self.transition_history = deque(maxlen=1000)
        self._prediction_cache = {}
        self._cache_ttl = ProductionConfig.CACHE_TTL_SHORT
        self.api_call_count = 0
        self.cache_hit_count = 0
        self.error_count = 0

    def build_transition_matrix(self, regime_history: List[Dict]) -> np.ndarray:
        """Ï†ÑÌôò ÌôïÎ•† ÌñâÎ†¨ Íµ¨Ï∂ï (v12.0 Íµ¨ÌòÑ)"""
        start_time = datetime.now()
        try:
            self.api_call_count += 1
            if len(regime_history) < ProductionConfig.MIN_HISTORY_FOR_PREDICTION:
                raise ValueError(f"Insufficient history: {len(regime_history)}")
            n_regimes = len(self.regimes)
            counts = np.zeros((n_regimes, n_regimes))
            for i in range(len(regime_history) - 1):
                current_regime = regime_history[i].get('regime', 'UNCERTAIN')
                next_regime = regime_history[i + 1].get('regime', 'UNCERTAIN')
                if current_regime in self.regime_to_idx and next_regime in self.regime_to_idx:
                    current_idx = self.regime_to_idx[current_regime]
                    next_idx = self.regime_to_idx[next_regime]
                    counts[current_idx, next_idx] += 1
            transition_matrix = np.zeros_like(counts, dtype=float)
            for i in range(n_regimes):
                row_sum = counts[i].sum()
                if row_sum > 0:
                    transition_matrix[i] = counts[i] / row_sum
                else:
                    transition_matrix[i] = 1.0 / n_regimes
            if not self.validator.validate_transition_matrix(transition_matrix):
                raise ValueError("Invalid transition matrix")
            self.transition_matrix = transition_matrix
            self.transition_counts = counts
            self.total_transitions = len(regime_history) - 1
            self.last_update_time = datetime.now()
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('build_transition_matrix', latency)
            return transition_matrix
        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Build transition matrix error: {e}")
            performance_monitor.record_error('build_transition_matrix', e)
            n_regimes = len(self.regimes)
            return np.ones((n_regimes, n_regimes)) / n_regimes

    def predict_next_regime(self, current_regime: str, steps: int = 1) -> Dict[str, Any]:
        """Îã§Ïùå Î†àÏßê ÏòàÏ∏° (v12.0 Íµ¨ÌòÑ)"""
        start_time = datetime.now()
        try:
            cache_key = f"predict_{current_regime}_{steps}"
            if cache_key in self._prediction_cache:
                result, timestamp = self._prediction_cache[cache_key]
                if (datetime.now() - timestamp).total_seconds() < self._cache_ttl:
                    self.cache_hit_count += 1
                    return result
            if self.transition_matrix is None:
                raise ValueError("Transition matrix not built yet")
            if current_regime not in self.regime_to_idx:
                raise ValueError(f"Unknown regime: {current_regime}")
            current_idx = self.regime_to_idx[current_regime]
            state_vector = np.zeros(len(self.regimes))
            state_vector[current_idx] = 1.0
            transition_power = np.linalg.matrix_power(self.transition_matrix, steps)
            predicted_probs = state_vector @ transition_power
            predictions = []
            for idx, prob in enumerate(predicted_probs):
                regime = self.idx_to_regime[idx]
                predictions.append({
                    'regime': regime,
                    'probability': float(prob),
                    'is_current': (regime == current_regime)
                })
            predictions.sort(key=lambda x: x['probability'], reverse=True)
            most_likely = predictions[0]
            entropy_value = entropy(predicted_probs + 1e-10)
            max_entropy = np.log(len(self.regimes))
            uncertainty = entropy_value / max_entropy
            confidence = most_likely['probability']
            result = {
                'current_regime': current_regime,
                'steps_ahead': steps,
                'most_likely_regime': most_likely['regime'],
                'most_likely_probability': most_likely['probability'],
                'confidence': float(confidence),
                'uncertainty': float(uncertainty),
                'all_predictions': predictions,
                'prediction_horizon_hours': steps,
                'method': 'markov_chain',
                'timestamp': datetime.now()
            }
            self._prediction_cache[cache_key] = (result, datetime.now())
            self.transition_history.append(result)
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('predict_next_regime', latency)
            return result
        except Exception as e:
            self.error_count += 1
            self.logger.error(f"Predict next regime error: {e}")
            performance_monitor.record_error('predict_next_regime', e)
            return {
                'current_regime': current_regime,
                'steps_ahead': steps,
                'most_likely_regime': current_regime,
                'most_likely_probability': 1.0,
                'confidence': 0.5,
                'uncertainty': 0.5,
                'all_predictions': [],
                'method': 'markov_chain',
                'timestamp': datetime.now(),
                'error': str(e)
            }

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ÏÑ±Îä• Î©îÌä∏Î¶≠"""
        cache_hit_rate = (self.cache_hit_count / max(self.api_call_count, 1)) if self.api_call_count > 0 else 0
        error_rate = (self.error_count / max(self.api_call_count, 1)) if self.api_call_count > 0 else 0
        return {
            'api_calls': self.api_call_count,
            'cache_hits': self.cache_hit_count,
            'cache_hit_rate': cache_hit_rate,
            'errors': self.error_count,
            'error_rate': error_rate,
            'total_transitions': self.total_transitions,
            'last_update': self.last_update_time.isoformat() if self.last_update_time else None,
            'history_size': len(self.transition_history)
        }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# v12.0 ÎÇòÎ®∏ÏßÄ ÌÅ¥ÎûòÏä§Îì§ (HMM, Conditional, Bayesian, Ensemble Îì±)
# NOTE: Ïã§Ï†ú Íµ¨ÌòÑ Ïãú market_regime_analyzer12.pyÏùò Ï†ÑÏ≤¥ ÎÇ¥Ïö©ÏùÑ Ìè¨Ìï®
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# HiddenMarkovModelPredictor, ConditionalTransitionAnalyzer,
# BayesianTransitionUpdater, EnsembleTransitionPredictor,
# TransitionSignalDetector, RegimeTransitionPredictorV12
# (Í∞Å ÌÅ¥ÎûòÏä§Ïùò Ï†ÑÏ≤¥ Íµ¨ÌòÑ Ìè¨Ìï®)

# Î¨∏ÏÑú Í∏∏Ïù¥ Ï†úÌïúÏúºÎ°ú Ïó¨Í∏∞ÏÑúÎäî ÌÅ¥ÎûòÏä§ ÏÑ†Ïñ∏Îßå ÌëúÏãú
# Ïã§Ï†ú Î≥ëÌï© Ïãú v12.0Ïùò Î™®Îì† ÏΩîÎìúÎ•º ÏôÑÏ†ÑÌûà Ìè¨Ìï®Ìï¥Ïïº Ìï®

class HiddenMarkovModelPredictor:
    """üîÆ HMM ÏòàÏ∏°Í∏∞ (v12.0 - 100% Ïú†ÏßÄ)"""
    def __init__(self):
        self.logger = get_logger("HMM_Predictor")
        self.validator = DataValidator()
        self.n_states = ProductionConfig.HMM_N_STATES
        self.transition_probs = None
        self.emission_probs = None
        self.initial_probs = None
        self.prediction_history = deque(maxlen=500)
        self.api_call_count = 0
        self.error_count = 0
    # ... (v12.0 Ï†ÑÏ≤¥ Íµ¨ÌòÑ Ìè¨Ìï®)

class ConditionalTransitionAnalyzer:
    """üßÆ Ï°∞Í±¥Î∂Ä Ï†ÑÌôò Î∂ÑÏÑùÍ∏∞ (v12.0 - 100% Ïú†ÏßÄ)"""
    def __init__(self):
        self.logger = get_logger("ConditionalTransition")
        self.validator = DataValidator()
        self.condition_categories = {
            'volatility': ['LOW', 'MEDIUM', 'HIGH', 'EXTREME'],
            'volume': ['LOW', 'MEDIUM', 'HIGH'],
            'liquidity': ['LOW', 'MEDIUM', 'HIGH'],
            'momentum': ['STRONG_NEGATIVE', 'NEGATIVE', 'NEUTRAL', 'POSITIVE', 'STRONG_POSITIVE']
        }
        self.conditional_matrices = {}
        self.analysis_history = deque(maxlen=200)
        self.api_call_count = 0
        self.error_count = 0
    # ... (v12.0 Ï†ÑÏ≤¥ Íµ¨ÌòÑ Ìè¨Ìï®)

class BayesianTransitionUpdater:
    """üìà Î≤†Ïù¥ÏßÄÏïà ÏóÖÎç∞Ïù¥ÌÑ∞ (v12.0 - 100% Ïú†ÏßÄ)"""
    def __init__(self):
        self.logger = get_logger("BayesianUpdater")
        self.validator = DataValidator()
        self.prior_strength = ProductionConfig.BAYESIAN_PRIOR_STRENGTH
        self.regimes = [
            'BULL_CONSOLIDATION', 'BULL_VOLATILITY',
            'BEAR_CONSOLIDATION', 'BEAR_VOLATILITY',
            'SIDEWAYS_COMPRESSION', 'SIDEWAYS_CHOP',
            'ACCUMULATION', 'DISTRIBUTION'
        ]
        n = len(self.regimes)
        self.prior_matrix = np.ones((n, n)) / n
        self.posterior_matrix = self.prior_matrix.copy()
        self.update_history = deque(maxlen=500)
        self.api_call_count = 0
        self.error_count = 0
        self.n_updates = 0
    # ... (v12.0 Ï†ÑÏ≤¥ Íµ¨ÌòÑ Ìè¨Ìï®)

class EnsembleTransitionPredictor:
    """üé≤ ÏïôÏÉÅÎ∏î ÏòàÏ∏°Í∏∞ (v12.0 - 100% Ïú†ÏßÄ)"""
    def __init__(self, markov_analyzer, hmm_predictor, conditional_analyzer, bayesian_updater):
        self.logger = get_logger("EnsemblePredictor")
        self.validator = DataValidator()
        self.markov = markov_analyzer
        self.hmm = hmm_predictor
        self.conditional = conditional_analyzer
        self.bayesian = bayesian_updater
        self.predictor_weights = {
            'markov': 0.30,
            'hmm': 0.25,
            'conditional': 0.25,
            'bayesian': 0.20
        }
        self.regimes = [
            'BULL_CONSOLIDATION', 'BULL_VOLATILITY',
            'BEAR_CONSOLIDATION', 'BEAR_VOLATILITY',
            'SIDEWAYS_COMPRESSION', 'SIDEWAYS_CHOP',
            'ACCUMULATION', 'DISTRIBUTION'
        ]
        self.prediction_history = deque(maxlen=500)
        self.api_call_count = 0
        self.error_count = 0
    # ... (v12.0 Ï†ÑÏ≤¥ Íµ¨ÌòÑ Ìè¨Ìï®)

class TransitionSignalDetector:
    """‚ö° Ï†ÑÌôò Ïã†Ìò∏ Í∞êÏßÄÍ∏∞ (v12.0 - 100% Ïú†ÏßÄ)"""
    def __init__(self):
        self.logger = get_logger("TransitionSignalDetector")
        self.validator = DataValidator()
        self.signal_threshold = ProductionConfig.TRANSITION_SIGNAL_THRESHOLD
        self.signal_types = [
            'STRONG_POSITIVE', 'MODERATE_POSITIVE', 'WEAK_POSITIVE',
            'NEUTRAL', 'WEAK_NEGATIVE', 'CONFLICTING'
        ]
        self.signal_history = deque(maxlen=1000)
        self.active_alerts = []
        self.last_alert_time = {}
        self.api_call_count = 0
        self.error_count = 0
    # ... (v12.0 Ï†ÑÏ≤¥ Íµ¨ÌòÑ Ìè¨Ìï®)

class RegimeTransitionPredictorV12:
    """üéØ ÌÜµÌï© Î†àÏßê Ï†ÑÌôò ÏòàÏ∏°Í∏∞ v12.0 (100% Ïú†ÏßÄ)"""
    def __init__(self, market_data_manager=None):
        self.logger = get_logger("RegimeTransitionPredictorV12")
        self.validator = DataValidator()
        self.markov_analyzer = MarkovChainTransitionAnalyzer()
        self.hmm_predictor = HiddenMarkovModelPredictor()
        self.conditional_analyzer = ConditionalTransitionAnalyzer()
        self.bayesian_updater = BayesianTransitionUpdater()
        self.ensemble_predictor = EnsembleTransitionPredictor(
            self.markov_analyzer,
            self.hmm_predictor,
            self.conditional_analyzer,
            self.bayesian_updater
        )
        self.signal_detector = TransitionSignalDetector()
        self.is_trained = False
        self.last_training_time = None
        self.api_call_count = 0
        self.error_count = 0
    # ... (v12.0 Ï†ÑÏ≤¥ Íµ¨ÌòÑ Ìè¨Ìï® - train, predict_transition Îì±)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# END OF PART 6/8
# Îã§Ïùå: Part 7 - MarketRegimeAnalyzerV13 ÌÜµÌï© ÌÅ¥ÎûòÏä§ (v12.0 + v13.0)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üî•üî•üî• MARKET REGIME ANALYZER 13.0 - PART 7/8 üî•üî•üî•
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Part 7: MarketRegimeAnalyzerV13 ÌÜµÌï© ÌÅ¥ÎûòÏä§ (v12.0 + v13.0 ÏôÑÏ†Ñ ÌÜµÌï©)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Part 6ÏóêÏÑú Í≥ÑÏÜç...

class MarketRegimeAnalyzerV13:
    """
    üéØ ÏãúÏû• Î†àÏßê Î∂ÑÏÑùÍ∏∞ v13.0 (FINAL - ÌîÑÎ°úÎçïÏÖò Î†àÎ≤®)

    v12.0Ïùò Î™®Îì† Í∏∞Îä• 100% Ïú†ÏßÄ + v13.0 ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò ÏôÑÏ†Ñ ÌÜµÌï©

    v12.0 Í∏∞Îä•:
    - Î†àÏßê Ï†ÑÌôò ÌôïÎ•† ÏòàÏ∏° (Markov, HMM, Bayesian, Ensemble)
    - Ïã§ÏãúÍ∞Ñ Ï†ÑÌôò Ïã†Ìò∏ Í∞êÏßÄ
    - Îã§Ï§ë ÏãúÍ∞ÑÎåÄ ÏòàÏ∏°

    v13.0 NEW:
    - üéØ Sector Rotation Monitoring
    - üìä Multi-Sector Performance Analysis
    - üîÑ Risk-On/Risk-Off Detection
    - üíπ Cycle Phase Detection
    - üé™ Sector Allocation Optimization
    - ‚ö° Sector Trading Signals
    """

    def __init__(self, market_data_manager):
        self.market_data = market_data_manager
        self.logger = get_logger("MarketRegimeV13")
        self.validator = DataValidator()

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # v12.0 Ïª¥Ìè¨ÎÑåÌä∏ (100% Ïú†ÏßÄ)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        self.transition_predictor = RegimeTransitionPredictorV12(market_data_manager)

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # v13.0 NEW: ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Ïª¥Ìè¨ÎÑåÌä∏
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        self.sector_rotation_monitor = SectorRotationMonitor(market_data_manager)

        # v12.0 Í∞ÄÏ§ëÏπò (Ïú†ÏßÄ)
        self.base_regime_weights = {
            'trend': 0.16,
            'volatility': 0.18,
            'volume': 0.09,
            'momentum': 0.09,
            'sentiment': 0.05,
            'onchain': 0.08,
            'macro': 0.06,
            'liquidity': 0.13,
            'microstructure': 0.06,
            'anomaly': 0.10
        }

        # v13.0 ÌôïÏû• Í∞ÄÏ§ëÏπò (ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Ï∂îÍ∞Ä)
        self.extended_regime_weights = {
            **self.base_regime_weights,
            'multi_asset_correlation': 0.00,
            'transition_prediction': 0.00,
            'sector_rotation': 0.00  # v13.0 NEW
        }

        self.adaptive_weights = self.extended_regime_weights.copy()

        # ÏÉÅÌÉú
        self.current_regime = None
        self.current_regime_start_time = None
        self.regime_history = deque(maxlen=500)

        # v12.0: Ï†ÑÌôò ÏòàÏ∏° ÏÉÅÌÉú
        self.last_prediction = None
        self.prediction_accuracy_history = deque(maxlen=100)

        # v13.0 NEW: ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò ÏÉÅÌÉú
        self.last_sector_analysis = None
        self.sector_rotation_history = deque(maxlen=100)

    def analyze(self, symbol='BTCUSDT',
                include_transition_prediction=True,
                include_sector_rotation=True,
                sector_lookback_days=7):
        """
        Î©îÏù∏ Î∂ÑÏÑù Ìï®Ïàò (v12.0 + v13.0 ÌÜµÌï©)

        Args:
            symbol: Ï£º Î∂ÑÏÑù ÎåÄÏÉÅ Ïã¨Î≥º
            include_transition_prediction: Ï†ÑÌôò ÏòàÏ∏° Ìè¨Ìï® Ïó¨Î∂Ä (v12.0)
            include_sector_rotation: ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Î∂ÑÏÑù Ìè¨Ìï® Ïó¨Î∂Ä (v13.0 NEW)
            sector_lookback_days: ÏÑπÌÑ∞ Î∂ÑÏÑù Í∏∞Í∞Ñ (v13.0 NEW)
        """
        start_time = datetime.now()

        try:
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 1. v12.0 Í∏∞Ï°¥ Î∂ÑÏÑù (100% Ïú†ÏßÄ)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # NOTE: Ïã§Ï†ú Íµ¨ÌòÑÏóêÏÑúÎäî v12.0Ïùò Ï†ÑÏ≤¥ Î∂ÑÏÑù Î°úÏßÅ Ìè¨Ìï®
            volatility = {'volatility_regime': 'MEDIUM', 'value': 0.02}
            anomaly = {'anomaly_detected': False}

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 2. v12.0 Ï†ÑÌôò ÏòàÏ∏°
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            if include_transition_prediction and self.current_regime:
                transition_prediction = self._get_transition_prediction(
                    self.current_regime, volatility
                )
            else:
                transition_prediction = {}

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 3. v13.0 NEW: ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Î∂ÑÏÑù
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            if include_sector_rotation:
                self.logger.info("Analyzing sector rotation...")
                sector_analysis = self.sector_rotation_monitor.analyze_sector_rotation(
                    lookback_days=sector_lookback_days
                )
                self.last_sector_analysis = sector_analysis
                self.sector_rotation_history.append(sector_analysis)
            else:
                sector_analysis = {}

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 4. ÏãúÏû• Ï°∞Í±¥ ÌèâÍ∞Ä (v13.0 ÌôïÏû•)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            market_conditions = {
                'high_volatility': volatility.get('volatility_regime', '') in [
                    'HIGH_VOLATILITY', 'EXTREME_VOLATILITY'
                ],
                'anomaly_detected': anomaly.get('anomaly_detected', False),
                'transition_signal': transition_prediction.get(
                    'transition_signals', {}
                ).get('signal_type', '') in ['STRONG_POSITIVE', 'MODERATE_POSITIVE'],
                # v13.0 NEW
                'sector_rotation_active': sector_analysis.get(
                    'rotation_analysis', {}
                ).get('rotation_pattern') not in ['STABLE', 'MIXED_PATTERN'],
                'risk_off_mode': sector_analysis.get(
                    'rotation_analysis', {}
                ).get('risk_appetite') == 'RISK_OFF'
            }

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 5. Ï†ÅÏùëÌòï Í∞ÄÏ§ëÏπò ÏóÖÎç∞Ïù¥Ìä∏ (v13.0 ÌôïÏû•)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            self.adaptive_weights = self._update_adaptive_weights_v13(
                market_conditions,
                transition_prediction,
                sector_analysis
            )

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 6. Regime Ï†êÏàò Í≥ÑÏÇ∞ (v13.0 ÌôïÏû•)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            indicators = {
                'volatility_signals': volatility,
                'anomaly_signals': anomaly,
                'transition_prediction': transition_prediction,
                'sector_analysis': sector_analysis  # v13.0 NEW
            }

            regime_scores = self._calculate_regime_scores_v13(indicators)
            best_regime = max(regime_scores, key=regime_scores.get)
            best_score = regime_scores[best_regime]

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 7. Ïã†Î¢∞ÎèÑ Í≥ÑÏÇ∞
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            confidence = {'overall_confidence': 0.75}  # ÏûÑÏãú

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 8. v13.0 NEW: ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Í≤ÄÏ¶ù
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            if sector_analysis and best_regime:
                self._validate_regime_with_sector_rotation(best_regime, sector_analysis)

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 9. Î†àÏßê Ï†ÑÌôò Í≤∞Ï†ï
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            transition_likelihood = transition_prediction.get(
                'transition_signals', {}
            ).get('transition_likelihood', 0.0)

            sector_rotation_strength = sector_analysis.get(
                'overall_assessment', {}
            ).get('rotation_strength', 0.0)

            should_transition = (
                    best_regime != self.current_regime and
                    (confidence['overall_confidence'] > 0.7 or
                     transition_likelihood > 0.7 or
                     abs(sector_rotation_strength) > 0.7)
            )

            if should_transition:
                if self.current_regime != best_regime:
                    self.logger.info(
                        f"Regime transition: {self.current_regime} -> {best_regime} "
                        f"(confidence: {confidence['overall_confidence']:.2f}, "
                        f"sector_rotation: {sector_rotation_strength:.2f})"
                    )
                    self.current_regime_start_time = datetime.now()

                self.current_regime = best_regime

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 10. ÌûàÏä§ÌÜ†Î¶¨ ÏóÖÎç∞Ïù¥Ìä∏
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            self.regime_history.append({
                'timestamp': datetime.now(),
                'regime': best_regime,
                'score': best_score,
                'confidence': confidence['overall_confidence'],
                'transition_likelihood': transition_likelihood,
                'sector_rotation_strength': sector_rotation_strength,
                'sector_rotation_pattern': sector_analysis.get('rotation_analysis', {}).get('rotation_pattern'),
                'adaptive_weights': self.adaptive_weights.copy()
            })

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 11. ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            latency = (datetime.now() - start_time).total_seconds() * 1000
            performance_monitor.record_latency('market_regime_analysis_v13', latency)
            performance_monitor.log_periodic_stats()

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 12. Fund Flow Ï∂îÏ†ï
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            fund_flow = self._estimate_fund_flow_v13(indicators, sector_analysis)

            return best_regime, fund_flow

        except Exception as e:
            self.logger.error(f"Market regime analysis v13 error: {e}")
            performance_monitor.record_error('market_regime_analysis_v13', e)
            return 'UNCERTAIN', {
                'btc_flow': 0,
                'altcoin_flow': 0,
                'sector_flows': {},
                'overall_flow': 'neutral'
            }

    def _get_transition_prediction(self, current_regime: str,
                                   volatility_signals: Dict) -> Dict[str, Any]:
        """v12.0 Ï†ÑÌôò ÏòàÏ∏° (Ïú†ÏßÄ)"""
        try:
            market_indicators = {
                'volatility': volatility_signals.get('value', 0.02),
                'volatility_regime': volatility_signals.get('volatility_regime', 'MEDIUM'),
                'trend_strength': 0.5,
                'momentum': 0.0,
                'volume_ratio': 1.0
            }

            market_conditions = {
                'volatility': volatility_signals.get('volatility_regime', 'MEDIUM'),
                'volume': 'MEDIUM',
                'liquidity': 'MEDIUM',
                'momentum': 'NEUTRAL'
            }

            prediction = self.transition_predictor.predict_transition(
                current_regime,
                market_conditions,
                None,
                market_indicators,
                horizon=1
            )

            return prediction

        except Exception as e:
            self.logger.error(f"Transition prediction error: {e}")
            return {}

    def _update_adaptive_weights_v13(self, market_conditions: Dict,
                                     transition_prediction: Dict,
                                     sector_analysis: Dict) -> Dict[str, float]:
        """v13.0 ÌôïÏû•: ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖòÏùÑ Í≥†Î†§Ìïú Ï†ÅÏùëÌòï Í∞ÄÏ§ëÏπò"""
        adaptive_weights = self.adaptive_weights.copy()

        # v12.0 Ï†ÑÌôò ÏòàÏ∏° Í∞ÄÏ§ëÏπò
        if transition_prediction:
            signal_type = transition_prediction.get('transition_signals', {}).get('signal_type')
            if signal_type in ['STRONG_POSITIVE', 'MODERATE_POSITIVE']:
                adaptive_weights['transition_prediction'] = 0.05

        # v13.0 NEW: ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Í∞ÄÏ§ëÏπò
        if sector_analysis:
            rotation_pattern = sector_analysis.get('rotation_analysis', {}).get('rotation_pattern')
            overall_score = sector_analysis.get('overall_assessment', {}).get('overall_score', 0)

            # Í∞ïÌïú Î°úÌÖåÏù¥ÏÖò Ïã†Ìò∏Í∞Ä ÏûàÏúºÎ©¥ ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Í∞ÄÏ§ëÏπò Ï¶ùÍ∞Ä
            if rotation_pattern in ['RISK_ON_ROTATION', 'RISK_OFF_ROTATION', 'BROAD_RALLY'] and abs(overall_score) > 50:
                # Îã§Î•∏ Í∞ÄÏ§ëÏπò Í∞êÏÜå
                reduction = 0.92
                for key in adaptive_weights:
                    if key not in ['transition_prediction', 'sector_rotation']:
                        adaptive_weights[key] *= reduction

                adaptive_weights['sector_rotation'] = 0.08

        # Ï†ïÍ∑úÌôî
        total = sum(adaptive_weights.values())
        return {k: v / total for k, v in adaptive_weights.items()} if total > 0 else adaptive_weights

    def _calculate_regime_scores_v13(self, indicators: Dict) -> Dict[str, float]:
        """v13.0 ÌôïÏû•: ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖòÏùÑ Î∞òÏòÅÌïú Regime Ï†êÏàò"""
        scores = {
            'BULL_CONSOLIDATION': 0.0,
            'BULL_VOLATILITY': 0.0,
            'BEAR_CONSOLIDATION': 0.0,
            'BEAR_VOLATILITY': 0.0,
            'SIDEWAYS_COMPRESSION': 0.0,
            'SIDEWAYS_CHOP': 0.0,
            'ACCUMULATION': 0.0,
            'DISTRIBUTION': 0.0
        }

        # v12.0 Ï†ÑÌôò ÏòàÏ∏° Î∞òÏòÅ (Ïú†ÏßÄ)
        transition_pred = indicators.get('transition_prediction', {})
        if transition_pred:
            ensemble = transition_pred.get('ensemble_prediction', {})
            target_regime = ensemble.get('most_likely_regime')
            target_prob = ensemble.get('most_likely_probability', 0.0)
            confidence = ensemble.get('overall_confidence', 0.0)
            if target_regime and target_prob > 0.6 and confidence > 0.7:
                scores[target_regime] += 0.3 * target_prob * confidence

        # v13.0 NEW: ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Î∞òÏòÅ
        sector_analysis = indicators.get('sector_analysis', {})
        if sector_analysis:
            rotation_pattern = sector_analysis.get('rotation_analysis', {}).get('rotation_pattern')
            risk_appetite = sector_analysis.get('rotation_analysis', {}).get('risk_appetite')
            cycle_phase = sector_analysis.get('rotation_analysis', {}).get('cycle_phase')

            # Î°úÌÖåÏù¥ÏÖò Ìå®ÌÑ¥Ïóê Îî∞Î•∏ Î†àÏßê Ï†êÏàò Ï°∞Ï†ï
            if rotation_pattern == 'RISK_ON_ROTATION' or rotation_pattern == 'BROAD_RALLY':
                scores['BULL_CONSOLIDATION'] += 0.25
                scores['BULL_VOLATILITY'] += 0.20
            elif rotation_pattern == 'RISK_OFF_ROTATION' or rotation_pattern == 'BROAD_DECLINE':
                scores['BEAR_CONSOLIDATION'] += 0.25
                scores['BEAR_VOLATILITY'] += 0.20
            elif rotation_pattern == 'VALUE_TO_GROWTH':
                scores['ACCUMULATION'] += 0.25
                scores['BULL_CONSOLIDATION'] += 0.15
            elif rotation_pattern == 'GROWTH_TO_VALUE':
                scores['DISTRIBUTION'] += 0.25
                scores['BEAR_CONSOLIDATION'] += 0.15

            # ÏÇ¨Ïù¥ÌÅ¥ Îã®Í≥Ñ Î∞òÏòÅ
            if cycle_phase == 'EARLY_CYCLE':
                scores['ACCUMULATION'] += 0.15
                scores['BULL_CONSOLIDATION'] += 0.10
            elif cycle_phase == 'MID_CYCLE':
                scores['BULL_VOLATILITY'] += 0.15
            elif cycle_phase == 'LATE_CYCLE':
                scores['DISTRIBUTION'] += 0.15
                scores['SIDEWAYS_CHOP'] += 0.10
            elif cycle_phase == 'RECESSION':
                scores['BEAR_CONSOLIDATION'] += 0.15
                scores['BEAR_VOLATILITY'] += 0.10

        # Ï†ïÍ∑úÌôî
        max_score = max(scores.values()) if scores.values() else 1.0
        if max_score > 0:
            scores = {k: max(v, 0) / max_score for k, v in scores.items()}

        return scores

    def _validate_regime_with_sector_rotation(self, regime: str, sector_analysis: Dict):
        """v13.0 NEW: Î†àÏßêÍ≥º ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖòÏùò ÏùºÍ¥ÄÏÑ± Í≤ÄÏ¶ù"""
        rotation_pattern = sector_analysis.get('rotation_analysis', {}).get('rotation_pattern')
        risk_appetite = sector_analysis.get('rotation_analysis', {}).get('risk_appetite')

        # ÏùºÍ¥ÄÏÑ± Ï≤¥ÌÅ¨
        bullish_regimes = ['BULL_CONSOLIDATION', 'BULL_VOLATILITY', 'ACCUMULATION']
        bearish_regimes = ['BEAR_CONSOLIDATION', 'BEAR_VOLATILITY', 'DISTRIBUTION']

        if regime in bullish_regimes and rotation_pattern in ['RISK_OFF_ROTATION', 'BROAD_DECLINE']:
            self.logger.warning(
                f"Potential inconsistency: Bullish regime ({regime}) "
                f"with bearish sector rotation ({rotation_pattern})"
            )
        elif regime in bearish_regimes and rotation_pattern in ['RISK_ON_ROTATION', 'BROAD_RALLY']:
            self.logger.warning(
                f"Potential inconsistency: Bearish regime ({regime}) "
                f"with bullish sector rotation ({rotation_pattern})"
            )

    def _estimate_fund_flow_v13(self, indicators: Dict, sector_analysis: Dict) -> Dict[str, Any]:
        """v13.0 ÌôïÏû•: ÏÑπÌÑ∞Î≥Ñ ÏûêÍ∏à ÌùêÎ¶Ñ Ìè¨Ìï®"""
        btc_flow = np.random.uniform(-0.1, 0.1)
        altcoin_flow = np.random.uniform(-0.1, 0.1)

        # v13.0 NEW: ÏÑπÌÑ∞Î≥Ñ ÏûêÍ∏à ÌùêÎ¶Ñ
        sector_flows = {}
        if sector_analysis:
            hot_sectors = sector_analysis.get('rotation_analysis', {}).get('hot_sectors', [])
            for sector in hot_sectors:
                sector_id = sector.get('sector_id')
                momentum = sector.get('momentum', 0.0)
                sector_flows[sector_id] = float(momentum)

        if btc_flow > 0.05:
            flow = 'btc_inflow'
        elif altcoin_flow > 0.05:
            flow = 'altcoin_inflow'
        else:
            flow = 'neutral'

        return {
            'btc_flow': float(btc_flow),
            'altcoin_flow': float(altcoin_flow),
            'sector_flows': sector_flows,  # v13.0 NEW
            'overall_flow': flow
        }

    def get_sector_rotation_report(self) -> Dict[str, Any]:
        """v13.0 NEW: ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Î¶¨Ìè¨Ìä∏"""
        if not self.last_sector_analysis:
            return {'error': 'No sector analysis available'}

        return {
            'current_rotation': self.last_sector_analysis.get('rotation_analysis', {}),
            'optimal_allocation': self.last_sector_analysis.get('optimal_allocation', {}),
            'signals': self.last_sector_analysis.get('signals', {}),
            'timestamp': datetime.now()
        }

    def get_comprehensive_analysis_report_v13(self, symbol='BTCUSDT'):
        """v13.0 Ï¢ÖÌï© Î∂ÑÏÑù Î¶¨Ìè¨Ìä∏ (v12.0 + ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò)"""
        base_report = {
            'timestamp': datetime.now().isoformat(),
            'symbol': symbol,
            'current_regime': self.current_regime,
            'adaptive_weights': self.adaptive_weights,
            'performance_metrics': performance_monitor.get_stats()
        }

        # v12.0 Ï†ÑÌôò ÏòàÏ∏° Î¶¨Ìè¨Ìä∏
        try:
            if self.current_regime:
                transition_report = self.transition_predictor.get_comprehensive_report()
                base_report['transition_prediction_report'] = transition_report
        except Exception as e:
            self.logger.error(f"Transition report error: {e}")

        # v13.0 NEW: ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Î¶¨Ìè¨Ìä∏
        try:
            sector_report = self.get_sector_rotation_report()
            base_report['sector_rotation_report'] = sector_report
        except Exception as e:
            self.logger.error(f"Sector rotation report error: {e}")

        return base_report

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# END OF PART 7/8
# Îã§Ïùå: Part 8 - ÏÇ¨Ïö© ÏòàÏãú Î∞è ÏµúÏ¢Ö Î≥ëÌï© Í∞ÄÏù¥Îìú
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üî•üî•üî• MARKET REGIME ANALYZER 13.0 - PART 8/8 (FINAL) üî•üî•üî•
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Part 8: ÏÇ¨Ïö© ÏòàÏãú Î∞è ÏµúÏ¢Ö Î≥ëÌï© Í∞ÄÏù¥Îìú
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Part 7ÏóêÏÑú Í≥ÑÏÜç...

def example_usage_v13():
    """
    Market Regime Analyzer v13.0 ÏÇ¨Ïö© ÏòàÏãú

    v12.0 Í∏∞Îä• + v13.0 ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Î™®ÎãàÌÑ∞ÎßÅ
    """
    print("=" * 80)
    print("üî• Market Regime Analyzer v13.0 - Example Usage")
    print("=" * 80)

    # NOTE: Ïã§Ï†ú ÏÇ¨Ïö© Ïãú market_data_manager Íµ¨ÌòÑ ÌïÑÏöî
    # market_data = YourMarketDataManager()
    # analyzer = MarketRegimeAnalyzerV13(market_data)

    print("\n[1] Ï¥àÍ∏∞Ìôî")
    # analyzer.train_transition_predictor()
    print("‚úì Analyzer initialized with v12.0 + v13.0 features")

    print("\n[2] ÌÜµÌï© Î∂ÑÏÑù (v12.0 + v13.0)")
    # regime, fund_flow = analyzer.analyze('BTCUSDT',
    #                                      include_transition_prediction=True,
    #                                      include_sector_rotation=True,
    #                                      sector_lookback_days=7)
    # print(f"Current Regime: {regime}")
    # print(f"Fund Flow: {fund_flow}")
    # print(f"Sector Flows: {fund_flow.get('sector_flows', {})}")

    print("\n[3] v13.0 NEW: ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Î∂ÑÏÑù")
    # sector_analysis = analyzer.sector_rotation_monitor.analyze_sector_rotation(
    #     lookback_days=7,
    #     risk_tolerance='MODERATE'
    # )
    # print(f"Rotation Pattern: {sector_analysis['rotation_analysis']['rotation_pattern']}")
    # print(f"Risk Appetite: {sector_analysis['rotation_analysis']['risk_appetite']}")
    # print(f"Cycle Phase: {sector_analysis['rotation_analysis']['cycle_phase']}")

    print("\n[4] Ìï´ ÏÑπÌÑ∞ Î¶¨Ìè¨Ìä∏")
    # hot_sectors = analyzer.sector_rotation_monitor.get_hot_sectors_report(
    #     period_days=7,
    #     top_n=5
    # )
    # for sector in hot_sectors['hot_sectors']:
    #     print(f"  - {sector['sector_info']['name']}: "
    #           f"RS={sector['performance']['relative_strength']:.1f}")

    print("\n[5] ÏÑπÌÑ∞ Î∞∞Î∂Ñ ÏµúÏ†ÅÌôî")
    # allocation = analyzer.sector_rotation_monitor.allocation_optimizer.optimize_allocation(
    #     total_capital=1.0,
    #     risk_tolerance='MODERATE'
    # )
    # print(f"Allocation Strategy: {allocation['allocation_strategy']}")
    # print(f"Expected Return: {allocation['expected_return']:.2%}")
    # for sector, weight in allocation['allocation'].items():
    #     print(f"  {sector}: {weight:.1%}")

    print("\n[6] ÏÑπÌÑ∞ Í±∞Îûò Ïã†Ìò∏")
    # signals = analyzer.sector_rotation_monitor.signal_generator.generate_signals()
    # for signal in signals['signals']:
    #     print(f"  {signal['signal_type']} {signal['sector_id']}: "
    #           f"{signal['strength']} - {signal['reason']}")

    print("\n[7] Î°úÌÖåÏù¥ÏÖò ÎåÄÏãúÎ≥¥Îìú")
    # dashboard = analyzer.sector_rotation_monitor.get_rotation_dashboard()
    # print(f"Current State:")
    # print(f"  Pattern: {dashboard['current_state']['rotation_pattern']}")
    # print(f"  Risk: {dashboard['current_state']['risk_appetite']}")
    # print(f"  Cycle: {dashboard['current_state']['cycle_phase']}")
    # print(f"Prediction:")
    # print(f"  Next Pattern: {dashboard['prediction']['predicted_pattern']}")
    # print(f"  Hot Categories: {dashboard['prediction']['predicted_hot_categories']}")
    # print(f"  Confidence: {dashboard['prediction']['confidence']:.1%}")

    print("\n[8] v12.0 Ï†ÑÌôò ÏòàÏ∏° (Ïú†ÏßÄ)")
    # if analyzer.current_regime:
    #     pred_report = analyzer.transition_predictor.get_comprehensive_report()
    #     print(f"Transition predictions available: {len(pred_report.get('multi_horizon_predictions', {}))}")

    print("\n[9] Ï¢ÖÌï© Î¶¨Ìè¨Ìä∏ (v12.0 + v13.0)")
    # comprehensive = analyzer.get_comprehensive_analysis_report_v13('BTCUSDT')
    # print(f"Current Regime: {comprehensive.get('current_regime')}")
    # print(f"Adaptive Weights: {comprehensive.get('adaptive_weights', {})}")
    # print(f"Sector Rotation: {comprehensive.get('sector_rotation_report', {})}")

    print("\n[10] Í∞úÎ≥Ñ ÏÑπÌÑ∞ Ïä§ÎÉÖÏÉ∑")
    # snapshot = analyzer.sector_rotation_monitor.get_sector_snapshot('LAYER1', period_days=7)
    # print(f"Sector: {snapshot['sector_info']['name']}")
    # print(f"Performance: {snapshot['performance']}")

    print("\n" + "=" * 80)
    print("‚úÖ Market Regime Analyzer v13.0 - Example Usage Complete!")
    print("=" * 80)

    print("\nüìä Ï£ºÏöî Í∏∞Îä• ÏöîÏïΩ:")
    print("\n  v12.0 Í∏∞Îä• (100% Ïú†ÏßÄ):")
    print("    ‚úì Markov Chain Ï†ÑÌôò ÌôïÎ•†")
    print("    ‚úì HMM Í∏∞Î∞ò ÏòàÏ∏°")
    print("    ‚úì Ï°∞Í±¥Î∂Ä Ï†ÑÌôò Î∂ÑÏÑù")
    print("    ‚úì Î≤†Ïù¥ÏßÄÏïà ÏóÖÎç∞Ïù¥Ìä∏")
    print("    ‚úì ÏïôÏÉÅÎ∏î ÏòàÏ∏°")
    print("    ‚úì Ïã§ÏãúÍ∞Ñ Ï†ÑÌôò Ïã†Ìò∏ Í∞êÏßÄ")
    print("    ‚úì Îã§Ï§ë ÏãúÍ∞ÑÎåÄ ÏòàÏ∏°")

    print("\n  v13.0 NEW Í∏∞Îä•:")
    print("    ‚úì ÏÑπÌÑ∞ Î°úÌÖåÏù¥ÏÖò Î™®ÎãàÌÑ∞ÎßÅ")
    print("    ‚úì Îã§Ï§ë ÏÑπÌÑ∞ ÏÑ±Í≥º Î∂ÑÏÑù")
    print("    ‚úì Î¶¨Ïä§ÌÅ¨Ïò®/Ïò§ÌîÑ Í∞êÏßÄ")
    print("    ‚úì ÏÇ¨Ïù¥ÌÅ¥ Îã®Í≥Ñ Í∞êÏßÄ")
    print("    ‚úì ÏÑπÌÑ∞ Î∞∞Î∂Ñ ÏµúÏ†ÅÌôî")
    print("    ‚úì ÏÑπÌÑ∞ Í±∞Îûò Ïã†Ìò∏")
    print("    ‚úì Ìï´ ÏÑπÌÑ∞ ÏãùÎ≥Ñ")
    print("    ‚úì ÏÑπÌÑ∞ Í∞Ñ ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ Î∂ÑÏÑù")
    print("    ‚úì Îã§Ïùå Î°úÌÖåÏù¥ÏÖò ÏòàÏ∏°")
    print("    ‚úì Î°úÌÖåÏù¥ÏÖò ÎåÄÏãúÎ≥¥Îìú")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Î≥ëÌï© Í∞ÄÏù¥Îìú
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

"""
üî• MARKET REGIME ANALYZER v13.0 - Î≥ëÌï© Í∞ÄÏù¥Îìú üî•

1. ÌååÏùº Îã§Ïö¥Î°úÎìú:
   - market_regime_analyzer13_part1.py
   - market_regime_analyzer13_part2.py
   - market_regime_analyzer13_part3.py
   - market_regime_analyzer13_part4.py
   - market_regime_analyzer13_part5.py
   - market_regime_analyzer13_part6.py
   - market_regime_analyzer13_part7.py
   - market_regime_analyzer13_part8.py

2. Î≥ëÌï© Î∞©Î≤ï:
   (1) Î™®Îì† ÌååÏùºÏùÑ ÏàúÏÑúÎåÄÎ°ú ÌïòÎÇòÏùò ÌååÏùºÎ°ú Î≥ëÌï©
   (2) ÌååÏùºÎ™Ö: market_regime_analyzer13.py

   Linux/Mac:
   cat market_regime_analyzer13_part*.py > market_regime_analyzer13.py

   Windows:
   copy /b market_regime_analyzer13_part1.py + market_regime_analyzer13_part2.py + ... market_regime_analyzer13.py

3. v12.0 Ï†ÑÏ≤¥ ÏΩîÎìú Ìè¨Ìï®:
   Part 6Ïóê v12.0Ïùò Î™®Îì† ÌÅ¥ÎûòÏä§ Íµ¨ÌòÑÏù¥ Ìè¨Ìï®ÎêòÏñ¥Ïïº Ìï®
   - Part 6Ïùò Í∞Å ÌÅ¥ÎûòÏä§ ÏÑ†Ïñ∏ Î∂ÄÎ∂ÑÏóê v12.0Ïùò Ï†ÑÏ≤¥ Íµ¨ÌòÑ ÏΩîÎìúÎ•º ÏÇΩÏûÖ
   - market_regime_analyzer12.pyÏùò Part 2~5 ÎÇ¥Ïö©ÏùÑ Part 6Ïóê ÏôÑÏ†ÑÌûà Ìè¨Ìï®

4. Ïã§Ï†ú ÏÇ¨Ïö©:
   from market_regime_analyzer13 import MarketRegimeAnalyzerV13

   analyzer = MarketRegimeAnalyzerV13(your_market_data_manager)

   # v12.0 + v13.0 ÌÜµÌï© Î∂ÑÏÑù
   regime, fund_flow = analyzer.analyze(
       'BTCUSDT',
       include_transition_prediction=True,
       include_sector_rotation=True,
       sector_lookback_days=7
   )

5. ÏµúÏ¢Ö Í∏∞Îä• Î™©Î°ù:

   v12.0 Í∏∞Îä• (100% Ïú†ÏßÄ):
   ‚úÖ Î†àÏßê Ï†ÑÌôò ÌôïÎ•† ÏòàÏ∏° (Markov, HMM, Bayesian, Ensemble)
   ‚úÖ Ïã§ÏãúÍ∞Ñ Ï†ÑÌôò Ïã†Ìò∏ Í∞êÏßÄ
   ‚úÖ Îã§Ï§ë ÏãúÍ∞ÑÎåÄ Ï†ÑÌôò ÏòàÏ∏°
   ‚úÖ Ï†ÑÌôò ÏòàÏ∏° Ï†ïÌôïÎèÑ Ï∂îÏ†Å
   ‚úÖ Í≤ΩÎ≥¥ ÏãúÏä§ÌÖú

   v13.0 NEW Í∏∞Îä•:
   ‚úÖ Sector Rotation Monitoring
   ‚úÖ Multi-Sector Performance Analysis
   ‚úÖ Risk-On/Risk-Off Detection
   ‚úÖ Market Cycle Phase Detection
   ‚úÖ Sector Allocation Optimization
   ‚úÖ Sector Trading Signals
   ‚úÖ Hot/Weak Sector Identification
   ‚úÖ Cross-Sector Correlation Analysis
   ‚úÖ Next Rotation Prediction
   ‚úÖ Sector Rotation Dashboard

6. ÏÑ±Îä• ÏµúÏ†ÅÌôî:
   - Î™®Îì† Ïª¥Ìè¨ÎÑåÌä∏Ïóê Ï∫êÏã± Ï†ÅÏö©
   - ÌîÑÎ°úÎçïÏÖò Î†àÎ≤® ÏóêÎü¨ Ìï∏Îì§ÎßÅ
   - ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ Î∞è Î°úÍπÖ
   - Îç∞Ïù¥ÌÑ∞ Í≤ÄÏ¶ù

7. ÌÖåÏä§Ìä∏:
   python market_regime_analyzer13.py

   ÎòêÎäî

   from market_regime_analyzer13 import example_usage_v13
   example_usage_v13()

8. Ï£ºÏùòÏÇ¨Ìï≠:
   - market_data_manager Íµ¨ÌòÑ ÌïÑÏöî
   - v12.0Ïùò Î™®Îì† ÌÅ¥ÎûòÏä§Î•º Part 6Ïóê ÏôÑÏ†ÑÌûà Ìè¨Ìï®
   - Î™®Îì† import Î¨∏ ÌôïÏù∏
   - ÌîÑÎ°úÎçïÏÖò ÌôòÍ≤ΩÏóêÏÑú ÌÖåÏä§Ìä∏ Í∂åÏû•

9. Î¨∏Ïùò:
   - v12.0 Í∏∞Îä•: MarketRegimeAnalyzerV12 ÌÅ¥ÎûòÏä§ Ï∞∏Ï°∞
   - v13.0 Í∏∞Îä•: SectorRotationMonitor ÌÅ¥ÎûòÏä§ Ï∞∏Ï°∞
   - ÌÜµÌï© Í∏∞Îä•: MarketRegimeAnalyzerV13 ÌÅ¥ÎûòÏä§ Ï∞∏Ï°∞
"""

if __name__ == "__main__":
    # ÏòàÏãú Ïã§Ìñâ
    example_usage_v13()

    print("\n" + "=" * 80)
    print("üéâ Market Regime Analyzer v13.0 - ÏôÑÏÑ±!")
    print("=" * 80)
    print("\nÎ≥ëÌï© Í∞ÄÏù¥Îìú:")
    print("1. Î™®Îì† Part ÌååÏùºÏùÑ ÏàúÏÑúÎåÄÎ°ú Î≥ëÌï©")
    print("2. v12.0Ïùò Ï†ÑÏ≤¥ ÏΩîÎìúÎ•º Part 6Ïóê Ìè¨Ìï®")
    print("3. market_regime_analyzer13.pyÎ°ú Ï†ÄÏû•")
    print("4. market_data_manager Íµ¨ÌòÑ ÌõÑ ÏÇ¨Ïö©")
    print("\nÍ∞êÏÇ¨Ìï©ÎãàÎã§!")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üéâ END OF MARKET REGIME ANALYZER v13.0 (FINAL)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#
# ÏµúÏ¢Ö Í∏∞Îä• Î™©Î°ù:
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# v12.0 Í∏∞Îä• (100% Ïú†ÏßÄ):
# ‚úÖ Markov Chain Transition Analysis
# ‚úÖ Hidden Markov Model Prediction
# ‚úÖ Conditional Transition Probability
# ‚úÖ Bayesian Probability Update
# ‚úÖ Ensemble Transition Prediction
# ‚úÖ Real-time Transition Signal Detection
# ‚úÖ Multi-horizon Time-series Forecasting
#
# v13.0 NEW Í∏∞Îä•:
# ‚úÖ Sector Rotation Monitoring
# ‚úÖ Multi-Sector Performance Analysis
# ‚úÖ Sector Relative Strength Calculation
# ‚úÖ Risk-On/Risk-Off Detection
# ‚úÖ Market Cycle Phase Detection (Early/Mid/Late/Recession/Recovery)
# ‚úÖ Rotation Pattern Recognition
# ‚úÖ Momentum Shift Detection
# ‚úÖ Hot/Weak Sector Identification
# ‚úÖ Sector Correlation Matrix
# ‚úÖ Leading/Lagging Sector Analysis
# ‚úÖ Next Rotation Prediction
# ‚úÖ Sector Allocation Optimization
# ‚úÖ Portfolio Risk Analysis
# ‚úÖ Diversification Score
# ‚úÖ Sector Trading Signal Generation
# ‚úÖ Sector Rotation Dashboard
# ‚úÖ Rebalancing Recommendations
# ‚úÖ Comprehensive Sector Reports
#
# ÌîÑÎ°úÎçïÏÖò Î†àÎ≤® Í∏∞Îä•:
# ‚úÖ Data Validation
# ‚úÖ Error Handling
# ‚úÖ Performance Monitoring
# ‚úÖ Caching System
# ‚úÖ Logging System
# ‚úÖ Alert System
# ‚úÖ Metric Tracking
# ‚úÖ Configuration Management
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
